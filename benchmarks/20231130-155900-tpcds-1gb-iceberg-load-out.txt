Listening for transport dt_socket at address: 41387
23/11/30 16:00:02 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:00:02 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:00:02 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:00:02 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:00:03 INFO SignalUtils: Registering signal handler for INT
23/11/30 16:00:03 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:00:03 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:00:07 INFO HiveConf: Found configuration file file:/var/lib/fk-pf-spark3/conf/hive-site.xml
23/11/30 16:00:07 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:00:07 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:00:07 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:00:07 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:00:07 INFO SparkContext: Running Spark version 3.1.2
23/11/30 16:00:07 INFO ResourceUtils: ==============================================================
23/11/30 16:00:07 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/30 16:00:07 INFO ResourceUtils: ==============================================================
23/11/30 16:00:07 INFO SparkContext: Submitted application: Spark shell
23/11/30 16:00:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 4096, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 10240, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/30 16:00:07 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
23/11/30 16:00:07 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/30 16:00:07 INFO SecurityManager: Changing view acls to: vanshika.yadav
23/11/30 16:00:07 INFO SecurityManager: Changing modify acls to: vanshika.yadav
23/11/30 16:00:07 INFO SecurityManager: Changing view acls groups to: 
23/11/30 16:00:07 INFO SecurityManager: Changing modify acls groups to: 
23/11/30 16:00:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vanshika.yadav); groups with view permissions: Set(); users  with modify permissions: Set(vanshika.yadav); groups with modify permissions: Set()
23/11/30 16:00:08 INFO Utils: Successfully started service 'sparkDriver' on port 34105.
23/11/30 16:00:08 INFO SparkEnv: Registering MapOutputTracker
23/11/30 16:00:08 INFO SparkEnv: Registering BlockManagerMaster
23/11/30 16:00:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/30 16:00:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/30 16:00:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/30 16:00:08 INFO DiskBlockManager: Created local directory at /grid/1/spark3/tmp/blockmgr-5c6379e9-19f1-4377-a37e-0f9602987b4d
23/11/30 16:00:08 INFO MemoryStore: MemoryStore started with capacity 2.5 GiB
23/11/30 16:00:08 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/30 16:00:08 INFO log: Logging initialized @6449ms to org.sparkproject.jetty.util.log.Slf4jLog
23/11/30 16:00:08 INFO Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_172-b11
23/11/30 16:00:08 INFO Server: Started @6553ms
23/11/30 16:00:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/11/30 16:00:08 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/11/30 16:00:08 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/11/30 16:00:08 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/11/30 16:00:08 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
23/11/30 16:00:08 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
23/11/30 16:00:08 INFO AbstractConnector: Started ServerConnector@3a36da5e{HTTP/1.1, (http/1.1)}{0.0.0.0:4046}
23/11/30 16:00:08 INFO Utils: Successfully started service 'SparkUI' on port 4046.
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@28f6a008{/jobs,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6e475994{/jobs/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1a99744a{/jobs/job,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@75d9b73c{/jobs/job/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5a08d301{/stages,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5b3c2a9f{/stages/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4f571c0e{/stages/stage,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@677274e7{/stages/stage/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@16279a5d{/stages/pool,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6bd8c398{/stages/pool/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1e487d57{/storage,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@66c32e15{/storage/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@304704ae{/storage/rdd,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@533a27f8{/storage/rdd/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@75b25ec3{/environment,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6b60d99c{/environment/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@33997e07{/executors,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@eda7dd3{/executors/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@71c69628{/executors/threadDump,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1028a747{/executors/threadDump/json,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@613ba54e{/static,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@ce8b59e{/,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@344cf00f{/api,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@126e2710{/jobs/job/kill,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1a22325d{/stages/stage/kill,null,AVAILABLE,@Spark}
23/11/30 16:00:08 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:4046
23/11/30 16:00:08 INFO Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
23/11/30 16:00:08 INFO AHSProxy: Connecting to Application History server at fks-fdp-galaxy-pluto-hs-0001-m.c.fks-fdp-galaxy.internal/10.116.4.108:10200
23/11/30 16:00:08 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm2
23/11/30 16:00:09 INFO Client: Requesting a new application from cluster with 30 NodeManagers
23/11/30 16:00:09 INFO Configuration: resource-types.xml not found
23/11/30 16:00:09 INFO ResourceUtils: Unable to find 'resource-types.xml'.
23/11/30 16:00:09 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (163840 MB per container)
23/11/30 16:00:09 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
23/11/30 16:00:09 INFO Client: Setting up container launch context for our AM
23/11/30 16:00:09 INFO Client: Setting up the launch environment for our AM container
23/11/30 16:00:09 INFO Client: Preparing resources for our AM container
23/11/30 16:00:10 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/HikariCP-2.5.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/HikariCP-2.5.1.jar
23/11/30 16:00:10 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:10 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/JLargeArrays-1.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/JLargeArrays-1.5.jar
23/11/30 16:00:10 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:10 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/JTransforms-3.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/JTransforms-3.1.jar
23/11/30 16:00:10 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:10 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/RoaringBitmap-0.9.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/RoaringBitmap-0.9.0.jar
23/11/30 16:00:10 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:10 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/ST4-4.0.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/ST4-4.0.4.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/accessors-smart-1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/accessors-smart-1.2.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/activation-1.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/activation-1.1.1.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/aircompressor-0.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/aircompressor-0.10.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/algebra_2.12-2.0.0-M2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/algebra_2.12-2.0.0-M2.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/antlr-runtime-3.5.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/antlr-runtime-3.5.2.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/antlr4-runtime-4.8-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/antlr4-runtime-4.8-1.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/aopalliance-1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/aopalliance-1.0.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/aopalliance-repackaged-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/aopalliance-repackaged-2.6.1.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arpack_combined_all-0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/arpack_combined_all-0.1.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arrow-format-2.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/arrow-format-2.0.0.jar
23/11/30 16:00:11 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:11 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arrow-memory-core-2.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/arrow-memory-core-2.0.0.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arrow-memory-netty-2.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/arrow-memory-netty-2.0.0.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arrow-vector-2.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/arrow-vector-2.0.0.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/audience-annotations-0.5.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/audience-annotations-0.5.0.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/avro-1.8.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/avro-1.8.2.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/avro-ipc-1.8.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/avro-ipc-1.8.2.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/avro-mapred-1.8.2-hadoop2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/avro-mapred-1.8.2-hadoop2.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/bcpkix-jdk15on-1.60.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/bcpkix-jdk15on-1.60.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/bcprov-jdk15on-1.60.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/bcprov-jdk15on-1.60.jar
23/11/30 16:00:12 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:12 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/bigquery-connector-hadoop3-latest.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/bigquery-connector-hadoop3-latest.jar
23/11/30 16:00:13 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:13 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/bonecp-0.8.0.RELEASE.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/bonecp-0.8.0.RELEASE.jar
23/11/30 16:00:13 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:13 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/breeze-macros_2.12-1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/breeze-macros_2.12-1.0.jar
23/11/30 16:00:13 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:13 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/breeze_2.12-1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/breeze_2.12-1.0.jar
23/11/30 16:00:13 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:13 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/cats-kernel_2.12-2.0.0-M4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/cats-kernel_2.12-2.0.0-M4.jar
23/11/30 16:00:13 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/chill-java-0.9.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/chill-java-0.9.5.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/chill_2.12-0.9.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/chill_2.12-0.9.5.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-beanutils-1.9.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-beanutils-1.9.4.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-cli-1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-cli-1.2.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-codec-1.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-codec-1.10.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-collections-3.2.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-collections-3.2.2.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-compiler-3.0.16.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-compiler-3.0.16.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-compress-1.20.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-compress-1.20.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-configuration2-2.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-configuration2-2.1.1.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-crypto-1.1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-crypto-1.1.0.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-daemon-1.0.13.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-daemon-1.0.13.jar
23/11/30 16:00:14 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:14 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-dbcp-1.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-dbcp-1.4.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-httpclient-3.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-httpclient-3.1.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-io-2.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-io-2.5.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-lang-2.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-lang-2.6.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-lang3-3.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-lang3-3.10.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-logging-1.1.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-logging-1.1.3.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-math3-3.4.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-math3-3.4.1.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-net-3.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-net-3.1.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-pool-1.5.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-pool-1.5.4.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-text-1.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/commons-text-1.6.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/compress-lzf-1.0.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/compress-lzf-1.0.3.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/core-1.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/core-1.1.2.jar
23/11/30 16:00:15 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:15 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/curator-client-2.13.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/curator-client-2.13.0.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/curator-framework-2.13.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/curator-framework-2.13.0.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/curator-recipes-2.13.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/curator-recipes-2.13.0.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/datanucleus-api-jdo-4.2.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/datanucleus-api-jdo-4.2.4.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/datanucleus-core-4.1.17.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/datanucleus-core-4.1.17.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/datanucleus-rdbms-4.1.19.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/datanucleus-rdbms-4.1.19.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/derby-10.12.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/derby-10.12.1.1.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/dnsjava-2.1.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/dnsjava-2.1.7.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar
23/11/30 16:00:16 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:16 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/ehcache-3.3.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/ehcache-3.3.1.jar
23/11/30 16:00:17 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:17 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/fdp-deps-3.1.2.fdp.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/fdp-deps-3.1.2.fdp.1.jar
23/11/30 16:00:17 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:17 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/flatbuffers-java-1.9.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/flatbuffers-java-1.9.0.jar
23/11/30 16:00:17 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:17 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/gcs-connector-hadoop3-2.2.7-shaded.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/gcs-connector-hadoop3-2.2.7-shaded.jar
23/11/30 16:00:17 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:17 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/geronimo-jcache_1.0_spec-1.0-alpha-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/geronimo-jcache_1.0_spec-1.0-alpha-1.jar
23/11/30 16:00:17 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:17 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/gson-2.2.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/gson-2.2.4.jar
23/11/30 16:00:17 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:17 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/guava-27.0-jre.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/guava-27.0-jre.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/guice-4.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/guice-4.0.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/guice-servlet-4.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/guice-servlet-4.0.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-annotations-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-annotations-3.2.1.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-auth-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-auth-3.2.1.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-client-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-client-3.2.1.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-common-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-common-3.2.1.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-hdfs-client-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-hdfs-client-3.2.1.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-mapreduce-client-common-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-mapreduce-client-common-3.2.1.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-mapreduce-client-core-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-mapreduce-client-core-3.2.1.jar
23/11/30 16:00:18 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:18 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-mapreduce-client-jobclient-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-mapreduce-client-jobclient-3.2.1.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:19 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-api-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-yarn-api-3.2.1.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:19 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-client-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-yarn-client-3.2.1.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:19 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-common-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-yarn-common-3.2.1.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:19 WARN DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
23/11/30 16:00:19 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-registry-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-yarn-registry-3.2.1.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:19 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-server-common-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-yarn-server-common-3.2.1.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:19 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-server-web-proxy-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-yarn-server-web-proxy-3.2.1.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:19 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-beeline-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-beeline-2.3.7.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:19 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-bigquery-connector-2.0.0-SNAPSHOT-with-dependencies.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-bigquery-connector-2.0.0-SNAPSHOT-with-dependencies.jar
23/11/30 16:00:19 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:20 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-cli-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-cli-2.3.7.jar
23/11/30 16:00:21 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:21 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-common-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-common-2.3.7.jar
23/11/30 16:00:21 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:21 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-exec-2.3.7-core.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-exec-2.3.7-core.jar
23/11/30 16:00:21 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:21 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-jdbc-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-jdbc-2.3.7.jar
23/11/30 16:00:21 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:21 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-llap-common-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-llap-common-2.3.7.jar
23/11/30 16:00:21 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:21 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-metastore-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-metastore-2.3.7.jar
23/11/30 16:00:21 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:21 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-serde-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-serde-2.3.7.jar
23/11/30 16:00:21 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:21 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-service-rpc-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-service-rpc-3.1.2.jar
23/11/30 16:00:21 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-shims-0.23-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-shims-0.23-2.3.7.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-shims-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-shims-2.3.7.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-shims-common-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-shims-common-2.3.7.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-shims-scheduler-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-shims-scheduler-2.3.7.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-storage-api-2.7.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-storage-api-2.7.2.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-vector-code-gen-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hive-vector-code-gen-2.3.7.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hk2-api-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hk2-api-2.6.1.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hk2-locator-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hk2-locator-2.6.1.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hk2-utils-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hk2-utils-2.6.1.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/htrace-core4-4.1.0-incubating.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/htrace-core4-4.1.0-incubating.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/httpclient-4.4.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/httpclient-4.4.1.jar
23/11/30 16:00:22 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:22 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/httpcore-4.4.12.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/httpcore-4.4.12.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/istack-commons-runtime-3.0.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/istack-commons-runtime-3.0.8.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/ivy-2.4.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/ivy-2.4.0.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-annotations-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-annotations-2.10.0.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-core-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-core-2.10.0.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-core-asl-1.9.13.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-core-asl-1.9.13.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-databind-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-databind-2.10.0.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-jaxrs-base-2.9.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-jaxrs-base-2.9.8.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-jaxrs-json-provider-2.9.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-jaxrs-json-provider-2.9.8.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-mapper-asl-1.9.13.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-mapper-asl-1.9.13.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-module-jaxb-annotations-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-module-jaxb-annotations-2.10.0.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-module-paranamer-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-module-paranamer-2.10.0.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:23 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-module-scala_2.12-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jackson-module-scala_2.12-2.10.0.jar
23/11/30 16:00:23 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.activation-api-1.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jakarta.activation-api-1.2.1.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.annotation-api-1.3.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jakarta.annotation-api-1.3.5.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.inject-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jakarta.inject-2.6.1.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.servlet-api-4.0.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jakarta.servlet-api-4.0.3.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.validation-api-2.0.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jakarta.validation-api-2.0.2.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.ws.rs-api-2.1.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jakarta.ws.rs-api-2.1.6.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.xml.bind-api-2.3.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jakarta.xml.bind-api-2.3.2.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/janino-3.0.16.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/janino-3.0.16.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/javassist-3.25.0-GA.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/javassist-3.25.0-GA.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/javax.inject-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/javax.inject-1.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/javax.jdo-3.2.0-m3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/javax.jdo-3.2.0-m3.jar
23/11/30 16:00:24 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:24 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/javolution-5.5.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/javolution-5.5.1.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jaxb-api-2.2.11.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jaxb-api-2.2.11.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jaxb-runtime-2.3.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jaxb-runtime-2.3.2.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jcip-annotations-1.0-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jcip-annotations-1.0-1.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jcl-over-slf4j-1.7.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jcl-over-slf4j-1.7.30.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jdo-api-3.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jdo-api-3.0.1.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-client-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jersey-client-2.30.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-common-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jersey-common-2.30.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-container-servlet-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jersey-container-servlet-2.30.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-container-servlet-core-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jersey-container-servlet-core-2.30.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-hk2-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jersey-hk2-2.30.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-media-jaxb-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jersey-media-jaxb-2.30.jar
23/11/30 16:00:25 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:25 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-server-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jersey-server-2.30.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jline-2.14.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jline-2.14.6.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/joda-time-2.10.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/joda-time-2.10.5.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jodd-core-3.5.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jodd-core-3.5.2.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jpam-1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jpam-1.1.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json-1.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/json-1.8.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json-smart-2.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/json-smart-2.3.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json4s-ast_2.12-3.7.0-M5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/json4s-ast_2.12-3.7.0-M5.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json4s-core_2.12-3.7.0-M5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/json4s-core_2.12-3.7.0-M5.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json4s-jackson_2.12-3.7.0-M5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/json4s-jackson_2.12-3.7.0-M5.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json4s-scalap_2.12-3.7.0-M5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/json4s-scalap_2.12-3.7.0-M5.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jsp-api-2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jsp-api-2.1.jar
23/11/30 16:00:26 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:26 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jsr305-3.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jsr305-3.0.0.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jta-1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jta-1.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jul-to-slf4j-1.7.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/jul-to-slf4j-1.7.30.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-admin-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-admin-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-client-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-client-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-common-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-common-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-core-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-core-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-crypto-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-crypto-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-identity-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-identity-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-server-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-server-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-simplekdc-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-simplekdc-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-util-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerb-util-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-asn1-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerby-asn1-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-config-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerby-config-1.0.1.jar
23/11/30 16:00:27 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:27 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-pkix-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerby-pkix-1.0.1.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-util-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerby-util-1.0.1.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-xdr-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kerby-xdr-1.0.1.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kryo-shaded-4.0.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/kryo-shaded-4.0.2.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/leveldbjni-all-1.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/leveldbjni-all-1.8.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/libfb303-0.9.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/libfb303-0.9.3.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/libthrift-0.12.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/libthrift-0.12.0.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/log4j-1.2.17.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/log4j-1.2.17.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/lz4-java-1.7.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/lz4-java-1.7.1.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/machinist_2.12-0.6.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/machinist_2.12-0.6.8.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/macro-compat_2.12-1.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/macro-compat_2.12-1.1.1.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-core-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/metrics-core-4.1.1.jar
23/11/30 16:00:28 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:28 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-graphite-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/metrics-graphite-4.1.1.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-jmx-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/metrics-jmx-4.1.1.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-json-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/metrics-json-4.1.1.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-jvm-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/metrics-jvm-4.1.1.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/minlog-1.3.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/minlog-1.3.0.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/netty-all-4.1.51.Final.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/netty-all-4.1.51.Final.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/nimbus-jose-jwt-4.41.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/nimbus-jose-jwt-4.41.1.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/objenesis-2.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/objenesis-2.6.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/okhttp-2.7.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/okhttp-2.7.5.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/okio-1.14.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/okio-1.14.0.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/opencsv-2.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/opencsv-2.3.jar
23/11/30 16:00:29 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:29 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/orc-core-1.5.12.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/orc-core-1.5.12.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/orc-mapreduce-1.5.12.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/orc-mapreduce-1.5.12.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/orc-shims-1.5.12.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/orc-shims-1.5.12.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/oro-2.0.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/oro-2.0.8.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/osgi-resource-locator-1.0.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/osgi-resource-locator-1.0.3.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/paranamer-2.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/paranamer-2.8.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-column-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/parquet-column-1.10.1.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-common-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/parquet-common-1.10.1.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-encoding-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/parquet-encoding-1.10.1.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-format-2.4.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/parquet-format-2.4.0.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-hadoop-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/parquet-hadoop-1.10.1.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-jackson-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/parquet-jackson-1.10.1.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/protobuf-java-2.5.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/protobuf-java-2.5.0.jar
23/11/30 16:00:30 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:30 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/py4j-0.10.9.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/py4j-0.10.9.jar
23/11/30 16:00:31 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:31 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/pyrolite-4.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/pyrolite-4.30.jar
23/11/30 16:00:31 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:31 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/re2j-1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/re2j-1.1.jar
23/11/30 16:00:31 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:31 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-collection-compat_2.12-2.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/scala-collection-compat_2.12-2.1.1.jar
23/11/30 16:00:31 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:31 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-compiler-2.12.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/scala-compiler-2.12.10.jar
23/11/30 16:00:31 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:31 WARN DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
23/11/30 16:00:31 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-library-2.12.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/scala-library-2.12.10.jar
23/11/30 16:00:31 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:31 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-parser-combinators_2.12-1.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/scala-parser-combinators_2.12-1.1.2.jar
23/11/30 16:00:31 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:31 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-reflect-2.12.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/scala-reflect-2.12.10.jar
23/11/30 16:00:31 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:31 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-xml_2.12-1.2.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/scala-xml_2.12-1.2.0.jar
23/11/30 16:00:32 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:32 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/shapeless_2.12-2.3.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/shapeless_2.12-2.3.3.jar
23/11/30 16:00:32 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:32 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/shims-0.9.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/shims-0.9.0.jar
23/11/30 16:00:32 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:32 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/slf4j-api-1.7.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/slf4j-api-1.7.30.jar
23/11/30 16:00:32 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:32 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/slf4j-log4j12-1.7.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/slf4j-log4j12-1.7.30.jar
23/11/30 16:00:32 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:32 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/snappy-java-1.1.8.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/snappy-java-1.1.8.2.jar
23/11/30 16:00:32 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:32 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-catalyst_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-catalyst_2.12-3.1.2.jar
23/11/30 16:00:32 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:32 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-core_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-core_2.12-3.1.2.jar
23/11/30 16:00:32 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:32 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-graphx_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-graphx_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-hive-thriftserver_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-hive-thriftserver_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-hive_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-hive_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-kvstore_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-kvstore_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-launcher_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-launcher_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-mllib-local_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-mllib-local_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-mllib_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-mllib_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-network-common_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-network-common_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-network-shuffle_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-network-shuffle_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-repl_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-repl_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-sketch_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-sketch_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:33 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-sql_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-sql_2.12-3.1.2.jar
23/11/30 16:00:33 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-streaming_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-streaming_2.12-3.1.2.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-tags_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-tags_2.12-3.1.2.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-unsafe_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-unsafe_2.12-3.1.2.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-yarn_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spark-yarn_2.12-3.1.2.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spire-macros_2.12-0.17.0-M1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spire-macros_2.12-0.17.0-M1.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spire-platform_2.12-0.17.0-M1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spire-platform_2.12-0.17.0-M1.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spire-util_2.12-0.17.0-M1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spire-util_2.12-0.17.0-M1.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spire_2.12-0.17.0-M1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/spire_2.12-0.17.0-M1.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/stax-api-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/stax-api-1.0.1.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/stax2-api-3.1.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/stax2-api-3.1.4.jar
23/11/30 16:00:34 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:34 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/stream-2.9.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/stream-2.9.6.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/super-csv-2.2.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/super-csv-2.2.0.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/threeten-extra-1.5.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/threeten-extra-1.5.0.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/token-provider-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/token-provider-1.0.1.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/transaction-api-1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/transaction-api-1.1.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/univocity-parsers-2.9.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/univocity-parsers-2.9.1.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/velocity-1.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/velocity-1.5.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/woodstox-core-5.0.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/woodstox-core-5.0.3.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/xbean-asm7-shaded-4.15.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/xbean-asm7-shaded-4.15.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/xz-1.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/xz-1.5.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/zookeeper-3.4.14.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/zookeeper-3.4.14.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/zstd-jni-1.4.8-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/zstd-jni-1.4.8-1.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-lzo-0.6.0.2.4.0.0-169.jar
23/11/30 16:00:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:36 INFO Client: Uploading resource file:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/hadoop-4mc-1.1.0.jar
23/11/30 16:00:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar
23/11/30 16:00:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar
23/11/30 16:00:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:36 WARN DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
23/11/30 16:00:36 INFO Client: Uploading resource file:/home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar
23/11/30 16:00:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:36 INFO Client: Uploading resource file:/var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/iceberg-hive-runtime-1.2.0.jar
23/11/30 16:00:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:36 INFO Client: Uploading resource file:/var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/iceberg-spark-runtime-3.1_2.12-1.2.0.jar
23/11/30 16:00:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:36 INFO Client: Uploading resource file:/grid/1/spark3/tmp/spark-10e271bd-3c13-4662-9310-466769eaffd2/__spark_conf__2885179455323425163.zip -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0375/__spark_conf__.zip
23/11/30 16:00:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:00:36 INFO SecurityManager: Changing view acls to: vanshika.yadav
23/11/30 16:00:36 INFO SecurityManager: Changing modify acls to: vanshika.yadav
23/11/30 16:00:36 INFO SecurityManager: Changing view acls groups to: 
23/11/30 16:00:36 INFO SecurityManager: Changing modify acls groups to: 
23/11/30 16:00:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vanshika.yadav); groups with view permissions: Set(); users  with modify permissions: Set(vanshika.yadav); groups with modify permissions: Set()
23/11/30 16:00:36 INFO Client: Submitting application application_1699449121496_0375 to ResourceManager
23/11/30 16:00:37 INFO YarnClientImpl: Submitted application application_1699449121496_0375
23/11/30 16:00:38 INFO Client: Application report for application_1699449121496_0375 (state: ACCEPTED)
23/11/30 16:00:38 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: de_adhoc
	 start time: 1701340236915
	 final status: UNDEFINED
	 tracking URL: http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0375/
	 user: vanshika.yadav
23/11/30 16:00:39 INFO Client: Application report for application_1699449121496_0375 (state: ACCEPTED)
23/11/30 16:00:40 INFO Client: Application report for application_1699449121496_0375 (state: ACCEPTED)
23/11/30 16:00:41 INFO Client: Application report for application_1699449121496_0375 (state: ACCEPTED)
23/11/30 16:00:42 INFO Client: Application report for application_1699449121496_0375 (state: ACCEPTED)
23/11/30 16:00:43 INFO Client: Application report for application_1699449121496_0375 (state: ACCEPTED)
23/11/30 16:00:44 INFO Client: Application report for application_1699449121496_0375 (state: ACCEPTED)
23/11/30 16:00:45 INFO Client: Application report for application_1699449121496_0375 (state: ACCEPTED)
23/11/30 16:00:46 INFO Client: Application report for application_1699449121496_0375 (state: RUNNING)
23/11/30 16:00:46 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 10.116.12.148
	 ApplicationMaster RPC port: -1
	 queue: de_adhoc
	 start time: 1701340236915
	 final status: UNDEFINED
	 tracking URL: http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0375/
	 user: vanshika.yadav
23/11/30 16:00:46 INFO YarnClientSchedulerBackend: Application application_1699449121496_0375 has started running.
23/11/30 16:00:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40621.
23/11/30 16:00:46 INFO NettyBlockTransferService: Server created on fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:40621
23/11/30 16:00:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/30 16:00:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal, 40621, None)
23/11/30 16:00:46 INFO BlockManagerMasterEndpoint: Registering block manager fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:40621 with 2.5 GiB RAM, BlockManagerId(driver, fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal, 40621, None)
23/11/30 16:00:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal, 40621, None)
23/11/30 16:00:46 INFO BlockManager: external shuffle service port = 7337
23/11/30 16:00:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal, 40621, None)
23/11/30 16:00:46 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal, PROXY_URI_BASES -> http://fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0375,http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0375, RM_HA_URLS -> fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088), /proxy/application_1699449121496_0375
23/11/30 16:00:46 INFO ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:00:46 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6722f81a{/metrics/json,null,AVAILABLE,@Spark}
23/11/30 16:00:46 INFO GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.
23/11/30 16:00:46 INFO SingleEventLogFileWriter: Logging events to gs://fks-fdp-infra-job-history/pluto/spark-job-history/application_1699449121496_0375.inprogress
23/11/30 16:00:46 INFO Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
23/11/30 16:00:46 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
23/11/30 16:00:46 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
23/11/30 16:00:46 INFO Main: Created Spark session with Hive support
Spark context Web UI available at http://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:4046
Spark context available as 'sc' (master = yarn, app id = application_1699449121496_0375).
Spark session available as 'spark'.
23/11/30 16:00:46 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:23: warning: This catches all Throwables. If this is really intended, use `case t : Throwable` to clear this warning.
try { benchmark.TPCDSDataLoad.main(Array[String]("--format", "ICEBERG", "--scale-in-gb", "1", "--exclude-nulls", "True", "--benchmark-path", "gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking", "--source-path", "gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb")) } catch { case t => println(t); println("FAILED"); System.exit(1) } ;;
                                                                                                                                                                                                                                                                                                                                                                        ^
2023-11-30T16:00:49.139 ================================================================================
2023-11-30T16:00:49.139 ================================================================================
23/11/30 16:00:49 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:00:49 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:00:49 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('gs://stage-hive-metastore-pluto/apps/hive/warehouse').
23/11/30 16:00:49 INFO SharedState: Warehouse path is 'gs://stage-hive-metastore-pluto/apps/hive/warehouse'.
23/11/30 16:00:49 INFO ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:00:49 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@41758fc9{/SQL,null,AVAILABLE,@Spark}
23/11/30 16:00:49 INFO ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:00:49 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5747a07c{/SQL/json,null,AVAILABLE,@Spark}
23/11/30 16:00:49 INFO ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:00:49 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@c9ec20e{/SQL/execution,null,AVAILABLE,@Spark}
23/11/30 16:00:49 INFO ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:00:49 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@529c002c{/SQL/execution/json,null,AVAILABLE,@Spark}
23/11/30 16:00:49 INFO ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:00:49 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@43c1dcb0{/static/sql,null,AVAILABLE,@Spark}
23/11/30 16:00:49 WARN SparkSession$Builder: Using an existing SparkSession; some spark core configurations may not take effect.
2023-11-30T16:00:49.724 Spark started with configuration:
	spark.app.id: application_1699449121496_0375
	spark.app.name: Spark shell
	spark.app.startTime: 1701340207853
	spark.benchmarkId: 20231130-155900-tpcds-1gb-iceberg-load
	spark.cleaner.ttl: 86400
	spark.delta.logStore.gs.impl: io.delta.storage.GCSLogStore
	spark.driver.appUIAddress: http://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:4046
	spark.driver.cores: 1
	spark.driver.extraClassPath: gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar
	spark.driver.extraJavaOptions: -Denv=prod -Dcom.sun.management.jmxremote.port=0 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=0 -XX:MaxDirectMemorySize=800M -XX:MaxMetaspaceSize=256M -XX:CompressedClassSpaceSize=100M -XX:+UnlockDiagnosticVMOptions -Djob.numOfRePartitions=30
	spark.driver.extraLibraryPath: /usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu
	spark.driver.host: fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal
	spark.driver.memory: 5120m
	spark.driver.port: 34105
	spark.dynamicAllocation.enabled: true
	spark.dynamicAllocation.executorIdleTimeout: 60s
	spark.dynamicAllocation.maxExecutors: 200
	spark.eventLog.dir: gs://fks-fdp-infra-job-history/pluto/spark-job-history
	spark.eventLog.enabled: true
	spark.executor.cores: 1
	spark.executor.extraClassPath: gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar
	spark.executor.extraJavaOptions: -XX:MaxDirectMemorySize=8096m -Dio.netty.maxDirectMemory=8096m -XX:+UseG1GC -XX:ConcGCThreads=2
	spark.executor.extraLibraryPath: /usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu
	spark.executor.id: driver
	spark.executor.memory: 10240m
	spark.fdp.orgqueue.cache.expire: 300
	spark.fdp.orgqueue.cache.size: 100
	spark.fdp.orgqueue.defaultQueue: adhoc
	spark.fdp.orgqueue.gringotts.clientId: QAAS
	spark.fdp.orgqueue.gringotts.clientSecret: 423de2b0-cc97-439d-a3f9-673e76d7bbea
	spark.fdp.orgqueue.gringotts.url: http://10.47.6.66/billingOrg/user
	spark.fdp.orgqueue.ironbank.url: http://10.47.4.16:/queue/
	spark.fdp.orgqueue.queueNotFound.errorMessage: Queue mapping not found
	spark.fdp.orgqueue.validInitiators: BADGER,QAAS
	spark.hadoop.fs.s3.useRequesterPaysHeader: true
	spark.hadoop.yarn.timeline-service.enabled: false
	spark.history.fs.cleaner.interval: 1d
	spark.history.fs.cleaner.maxAge: 60d
	spark.history.fs.logDirectory: gs://fks-fdp-infra-job-history/pluto/spark-job-history
	spark.history.provider: org.apache.spark.deploy.history.FsHistoryProvider
	spark.home: /var/lib/fk-pf-spark3
	spark.jars: 
	spark.master: yarn
	spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS: fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal
	spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES: http://fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0375,http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0375
	spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS: fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088
	spark.queue.enforcer.class: com.flipkart.fdp.orgqueue.OrgQueueEnforcerForInitiator
	spark.repl.class.outputDir: /grid/1/spark3/tmp/spark-10e271bd-3c13-4662-9310-466769eaffd2/repl-ce537423-ce5a-4483-a0da-6b2b6d017970
	spark.repl.class.uri: spark://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:34105/classes
	spark.repl.local.jars: file:///home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar
	spark.shuffle.service.enabled: true
	spark.shuffle.useOldFetchProtocol: true
	spark.sql.catalog.hive_pluto: org.apache.iceberg.spark.SparkCatalog
	spark.sql.catalog.hive_pluto.type: hive
	spark.sql.catalog.hive_pluto.uri: thrift://10.116.17.2:9083
	spark.sql.catalogImplementation: hive
	spark.sql.extensions: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
	spark.sql.sources.partitionOverwriteMode: dynamic
	spark.sql.warehouse.dir: gs://stage-hive-metastore-pluto/apps/hive/warehouse
	spark.streaming.concurrentJobs: 4
	spark.submit.deployMode: client
	spark.submit.pyFiles: 
	spark.ui.filters: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	spark.ui.proxyBase: 
	spark.ui.showConsoleProgress: true
	spark.yarn.dist.jars: gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar,file:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar,gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,file:///home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar
	spark.yarn.driver.memoryOverhead: 4096
	spark.yarn.executor.memoryOverhead: 4096
	spark.yarn.historyServer.address: http://fks-fdp-galaxy-pluto-hs-0001-m.c.fks-fdp-galaxy.internal:18080
	spark.yarn.jars: gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/*
	spark.yarn.queue: de_adhoc
	spark.yarn.report.interval: 60s
	spark.yarn.secondary.jars: hadoop-lzo-0.6.0.2.4.0.0-169.jar,hadoop-4mc-1.1.0.jar,json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar,iceberg-hive-runtime-1.2.0.jar,iceberg-spark-runtime-3.1_2.12-1.2.0.jar

2023-11-30T16:00:49.729 ================================================================================
2023-11-30T16:00:49.730 START: drop-database
2023-11-30T16:00:49.730 SQL: DROP DATABASE IF EXISTS tpcds_sf1_ICEBERG CASCADE
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.exec.orc.default.compress does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.vectorized.complex.types.enabled does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.exec.orc.compression.strategy does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.enforce.sorting does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.metastore.client.scheme.handlers does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.vectorized.execution.ptf.enabled does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.support.sql11.reserved.keywords does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.vectorized.groupby.complex.types.enabled does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.heapsize does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.enforce.bucketing does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.fileformat.managed does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.exec.orc.default.stripe.size does not exist
23/11/30 16:00:50 WARN HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
23/11/30 16:00:50 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic
2023-11-30T16:00:57.889 END took 8157 ms: drop-database
2023-11-30T16:00:57.890 ================================================================================
2023-11-30T16:00:57.890 ================================================================================
2023-11-30T16:00:57.890 START: create-database
2023-11-30T16:00:57.890 SQL: CREATE DATABASE IF NOT EXISTS tpcds_sf1_ICEBERG
2023-11-30T16:00:58.083 END took 193 ms: create-database
2023-11-30T16:00:58.083 ================================================================================
2023-11-30T16:00:58.086 Generating call_center at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_155900_tpcds_1gb_iceberg_load/call_center
2023-11-30T16:00:58.086 ================================================================================
2023-11-30T16:00:58.086 START: drop-table-call_center
2023-11-30T16:00:58.086 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`call_center`
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.exec.orc.default.compress does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.vectorized.complex.types.enabled does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.exec.orc.compression.strategy does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.enforce.sorting does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.metastore.client.scheme.handlers does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.vectorized.execution.ptf.enabled does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.support.sql11.reserved.keywords does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.vectorized.groupby.complex.types.enabled does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.heapsize does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.enforce.bucketing does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.fileformat.managed does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.exec.orc.default.stripe.size does not exist
23/11/30 16:00:58 WARN HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
2023-11-30T16:00:58.411 END took 324 ms: drop-table-call_center
2023-11-30T16:00:58.411 ================================================================================
2023-11-30T16:00:58.411 ================================================================================
2023-11-30T16:00:58.412 START: create-table-call_center
2023-11-30T16:00:58.412 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`call_center` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_155900_tpcds_1gb_iceberg_load/call_center/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/call_center_1gb_parquet`  
[Stage 0:>                                                          (0 + 0) / 1][Stage 0:>                                                          (0 + 1) / 1]                                                                                23/11/30 16:01:12 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[Stage 1:>                                                          (0 + 1) / 1]23/11/30 16:01:15 WARN ThrowableSerializationWrapper: Task exception could not be deserialized
java.io.InvalidClassException: com.fasterxml.jackson.databind.JsonMappingException; local class incompatible: stream classdesc serialVersionUID = 3, local class serialVersionUID = 1
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:687)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1883)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1749)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2040)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2285)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2209)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)
	at org.apache.spark.ThrowableSerializationWrapper.readObject(TaskEndReason.scala:202)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2176)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2285)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2209)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2285)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2209)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:115)
	at org.apache.spark.scheduler.TaskResultGetter.$anonfun$enqueueFailedTask$2(TaskResultGetter.scala:141)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996)
	at org.apache.spark.scheduler.TaskResultGetter.$anonfun$enqueueFailedTask$1(TaskResultGetter.scala:137)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
23/11/30 16:01:15 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1) (pluto-mig-adhoc-c-cimage-c69c6e1d-qc5d.c.fks-fdp-galaxy.internal executor 1): UnknownReason
23/11/30 16:01:15 WARN TaskSetManager: Lost task 0.1 in stage 1.0 (TID 2) (pluto-mig-adhoc-c-cimage-c69c6e1d-qc5d.c.fks-fdp-galaxy.internal executor 1): java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.sql.catalyst.util.RebaseDateTime$
	at org.apache.spark.sql.catalyst.util.RebaseDateTime.lastSwitchJulianDay(RebaseDateTime.scala)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.rebaseDays(VectorizedColumnReader.java:212)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.decodeDictionaryIds(VectorizedColumnReader.java:377)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.readBatch(VectorizedColumnReader.java:280)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:283)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:181)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:37)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:173)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

23/11/30 16:01:15 ERROR TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job
23/11/30 16:01:15 ERROR AtomicCreateTableAsSelectExec: Data source write support IcebergBatchWrite(table=tpcds_sf1_ICEBERG.call_center, format=PARQUET) is aborting.
23/11/30 16:01:15 ERROR AtomicCreateTableAsSelectExec: Data source write support IcebergBatchWrite(table=tpcds_sf1_ICEBERG.call_center, format=PARQUET) aborted.
23/11/30 16:01:15 ERROR Utils: Aborting task
org.apache.spark.SparkException: Writing job aborted.
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:388)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:336)
	at org.apache.spark.sql.execution.datasources.v2.AtomicCreateTableAsSelectExec.writeWithV2(WriteToDataSourceV2Exec.scala:97)
	at org.apache.spark.sql.execution.datasources.v2.TableWriteExecHelper.$anonfun$writeToTable$1(WriteToDataSourceV2Exec.scala:476)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)
	at org.apache.spark.sql.execution.datasources.v2.TableWriteExecHelper.writeToTable(WriteToDataSourceV2Exec.scala:465)
	at org.apache.spark.sql.execution.datasources.v2.TableWriteExecHelper.writeToTable$(WriteToDataSourceV2Exec.scala:460)
	at org.apache.spark.sql.execution.datasources.v2.AtomicCreateTableAsSelectExec.writeToTable(WriteToDataSourceV2Exec.scala:97)
	at org.apache.spark.sql.execution.datasources.v2.AtomicCreateTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:118)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)
	at org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)
	at benchmark.Benchmark.runQuery(Benchmark.scala:146)
	at benchmark.TPCDSDataLoad.$anonfun$runInternal$3(TPCDSDataLoad.scala:116)
	at benchmark.TPCDSDataLoad.$anonfun$runInternal$3$adapted(TPCDSDataLoad.scala:93)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at benchmark.TPCDSDataLoad.runInternal(TPCDSDataLoad.scala:93)
	at benchmark.Benchmark.run(Benchmark.scala:121)
	at benchmark.TPCDSDataLoad$.$anonfun$main$1(TPCDSDataLoad.scala:134)
	at benchmark.TPCDSDataLoad$.$anonfun$main$1$adapted(TPCDSDataLoad.scala:133)
	at scala.Option.foreach(Option.scala:407)
	at benchmark.TPCDSDataLoad$.main(TPCDSDataLoad.scala:133)
	at $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:23)
	at $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:30)
	at $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:32)
	at $line14.$read$$iw$$iw$$iw$$iw$$iw.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:34)
	at $line14.$read$$iw$$iw$$iw$$iw.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:36)
	at $line14.$read$$iw$$iw$$iw.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:38)
	at $line14.$read$$iw$$iw.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:40)
	at $line14.$read$$iw.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:42)
	at $line14.$read.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:44)
	at $line14.$read$.<init>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:48)
	at $line14.$read$.<clinit>(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala)
	at $line14.$eval$.$print$lzycompute(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:7)
	at $line14.$eval$.$print(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala:6)
	at $line14.$eval.$print(20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:745)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1021)
	at scala.tools.nsc.interpreter.IMain.$anonfun$interpret$1(IMain.scala:574)
	at scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:41)
	at scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:37)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:41)
	at scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:573)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:600)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:570)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:894)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:762)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:464)
	at scala.tools.nsc.interpreter.ILoop.loop(ILoop.scala:485)
	at scala.tools.nsc.interpreter.ILoop.loop(ILoop.scala:480)
	at scala.tools.nsc.interpreter.ILoop.$anonfun$interpretAllFrom$3(ILoop.scala:497)
	at scala.reflect.io.Streamable$Chars.applyReader(Streamable.scala:118)
	at scala.reflect.io.Streamable$Chars.applyReader$(Streamable.scala:116)
	at scala.reflect.io.File.applyReader(File.scala:50)
	at scala.tools.nsc.interpreter.ILoop.$anonfun$interpretAllFrom$2(ILoop.scala:493)
	at scala.tools.nsc.interpreter.ILoop.savingReplayStack(ILoop.scala:99)
	at scala.tools.nsc.interpreter.ILoop.$anonfun$interpretAllFrom$1(ILoop.scala:493)
	at scala.tools.nsc.interpreter.ILoop.savingReader(ILoop.scala:104)
	at scala.tools.nsc.interpreter.ILoop.interpretAllFrom(ILoop.scala:492)
	at scala.tools.nsc.interpreter.ILoop.$anonfun$loadCommand$1(ILoop.scala:658)
	at scala.tools.nsc.interpreter.ILoop.$anonfun$withFile$1(ILoop.scala:651)
	at scala.tools.nsc.interpreter.IMain.withLabel(IMain.scala:119)
	at scala.tools.nsc.interpreter.ILoop.withFile(ILoop.scala:650)
	at scala.tools.nsc.interpreter.ILoop.run$3(ILoop.scala:657)
	at scala.tools.nsc.interpreter.ILoop.loadCommand(ILoop.scala:664)
	at org.apache.spark.repl.SparkILoop.$anonfun$process$7(SparkILoop.scala:173)
	at org.apache.spark.repl.SparkILoop.$anonfun$process$7$adapted(SparkILoop.scala:172)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.repl.SparkILoop.loadInitFiles$1(SparkILoop.scala:172)
	at org.apache.spark.repl.SparkILoop.$anonfun$process$4(SparkILoop.scala:166)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.tools.nsc.interpreter.ILoop.$anonfun$mumly$1(ILoop.scala:168)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at scala.tools.nsc.interpreter.ILoop.mumly(ILoop.scala:165)
	at org.apache.spark.repl.SparkILoop.loopPostInit$1(SparkILoop.scala:153)
	at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:221)
	at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189)
	at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236)
	at org.apache.spark.repl.Main$.doMain(Main.scala:78)
	at org.apache.spark.repl.Main$.main(Main.scala:58)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4) (pluto-mig-adhoc-c-cimage-c69c6e1d-qc5d.c.fks-fdp-galaxy.internal executor 1): java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.sql.catalyst.util.RebaseDateTime$
	at org.apache.spark.sql.catalyst.util.RebaseDateTime.lastSwitchJulianDay(RebaseDateTime.scala)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.rebaseDays(VectorizedColumnReader.java:212)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.decodeDictionaryIds(VectorizedColumnReader.java:377)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.readBatch(VectorizedColumnReader.java:280)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:283)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:181)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:37)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:173)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:357)
	... 112 more
Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.sql.catalyst.util.RebaseDateTime$
	at org.apache.spark.sql.catalyst.util.RebaseDateTime.lastSwitchJulianDay(RebaseDateTime.scala)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.rebaseDays(VectorizedColumnReader.java:212)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.decodeDictionaryIds(VectorizedColumnReader.java:377)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.readBatch(VectorizedColumnReader.java:280)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:283)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:181)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:37)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:173)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-11-30T16:01:15.778 ERROR: create-table-call_center
Writing job aborted.
                                                                                RESULT:
{
  "benchmarkSpecs" : {
    "benchmarkId" : "20231130-155900-tpcds-1gb-iceberg-load",
    "benchmarkPath" : "gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking",
    "excludeNulls" : "true",
    "format" : "ICEBERG",
    "scaleInGB" : "1",
    "sourcePath" : "gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb"
  },
  "extraMetrics" : { },
  "queryResults" : [ {
    "durationMs" : 8157,
    "name" : "drop-database"
  }, {
    "durationMs" : 193,
    "name" : "create-database"
  }, {
    "durationMs" : 324,
    "name" : "drop-table-call_center"
  }, {
    "errorMsg" : "Writing job aborted.",
    "name" : "create-table-call_center"
  } ],
  "sparkEnvInfo" : {
    "classpathEntries" : {
      "//fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar" : "System Classpath",
      "/etc/hadoop/conf/" : "System Classpath",
      "/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/conf/" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/HikariCP-2.5.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/JLargeArrays-1.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/JTransforms-3.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/RoaringBitmap-0.9.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/ST4-4.0.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/accessors-smart-1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/activation-1.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/aircompressor-0.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/algebra_2.12-2.0.0-M2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/antlr-runtime-3.5.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/antlr4-runtime-4.8-1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/aopalliance-1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/aopalliance-repackaged-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arpack_combined_all-0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arrow-format-2.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arrow-memory-core-2.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arrow-memory-netty-2.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arrow-vector-2.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/audience-annotations-0.5.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/avro-1.8.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/avro-ipc-1.8.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/avro-mapred-1.8.2-hadoop2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/bcpkix-jdk15on-1.60.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/bcprov-jdk15on-1.60.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/bonecp-0.8.0.RELEASE.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/breeze-macros_2.12-1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/breeze_2.12-1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/cats-kernel_2.12-2.0.0-M4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/chill-java-0.9.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/chill_2.12-0.9.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-beanutils-1.9.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-cli-1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-codec-1.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-collections-3.2.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-compiler-3.0.16.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-compress-1.20.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-configuration2-2.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-crypto-1.1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-daemon-1.0.13.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-dbcp-1.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-httpclient-3.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-io-2.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-lang-2.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-lang3-3.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-logging-1.1.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-math3-3.4.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-net-3.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-pool-1.5.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-text-1.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/compress-lzf-1.0.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/core-1.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/curator-client-2.13.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/curator-framework-2.13.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/curator-recipes-2.13.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/datanucleus-api-jdo-4.2.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/datanucleus-core-4.1.17.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/datanucleus-rdbms-4.1.19.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/derby-10.12.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/dnsjava-2.1.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/ehcache-3.3.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/flatbuffers-java-1.9.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/gcs-connector-hadoop3-2.2.7-shaded.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/geronimo-jcache_1.0_spec-1.0-alpha-1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/gson-2.2.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/guava-27.0-jre.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/guice-4.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/guice-servlet-4.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-annotations-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-auth-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-client-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-common-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-hdfs-client-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-mapreduce-client-common-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-mapreduce-client-core-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-mapreduce-client-jobclient-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-api-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-client-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-common-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-registry-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-server-common-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-server-web-proxy-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-beeline-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-cli-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-common-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-exec-2.3.7-core.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-jdbc-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-llap-common-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-metastore-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-serde-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-service-rpc-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-shims-0.23-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-shims-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-shims-common-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-shims-scheduler-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-storage-api-2.7.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-vector-code-gen-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hk2-api-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hk2-locator-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hk2-utils-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/htrace-core4-4.1.0-incubating.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/httpclient-4.4.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/httpcore-4.4.12.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hudi-spark3.1-bundle_2.12-0.13.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/istack-commons-runtime-3.0.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/ivy-2.4.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-annotations-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-core-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-core-asl-1.9.13.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-databind-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-jaxrs-base-2.9.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-jaxrs-json-provider-2.9.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-mapper-asl-1.9.13.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-module-jaxb-annotations-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-module-paranamer-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-module-scala_2.12-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.activation-api-1.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.annotation-api-1.3.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.inject-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.servlet-api-4.0.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.validation-api-2.0.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.ws.rs-api-2.1.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.xml.bind-api-2.3.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/janino-3.0.16.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/javassist-3.25.0-GA.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/javax.inject-1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/javax.jdo-3.2.0-m3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/javolution-5.5.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jaxb-api-2.2.11.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jaxb-runtime-2.3.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jcip-annotations-1.0-1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jcl-over-slf4j-1.7.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jdo-api-3.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-client-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-common-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-container-servlet-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-container-servlet-core-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-hk2-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-media-jaxb-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-server-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jline-2.14.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/joda-time-2.10.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jodd-core-3.5.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jpam-1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json-1.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json-smart-2.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json4s-ast_2.12-3.7.0-M5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json4s-core_2.12-3.7.0-M5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json4s-jackson_2.12-3.7.0-M5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json4s-scalap_2.12-3.7.0-M5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jsp-api-2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jsr305-3.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jta-1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jul-to-slf4j-1.7.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-admin-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-client-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-common-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-core-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-crypto-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-identity-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-server-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-simplekdc-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-util-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-asn1-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-config-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-pkix-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-util-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-xdr-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kryo-shaded-4.0.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/leveldbjni-all-1.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/libfb303-0.9.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/libthrift-0.12.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/log4j-1.2.17.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/lz4-java-1.7.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/machinist_2.12-0.6.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/macro-compat_2.12-1.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-core-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-graphite-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-jmx-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-json-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-jvm-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/minlog-1.3.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/netty-all-4.1.51.Final.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/nimbus-jose-jwt-4.41.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/objenesis-2.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/okhttp-2.7.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/okio-1.14.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/opencsv-2.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/orc-core-1.5.12.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/orc-mapreduce-1.5.12.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/orc-shims-1.5.12.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/oro-2.0.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/osgi-resource-locator-1.0.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/paranamer-2.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-column-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-common-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-encoding-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-format-2.4.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-hadoop-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-jackson-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/protobuf-java-2.5.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/py4j-0.10.9.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/pyrolite-4.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/re2j-1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-collection-compat_2.12-2.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-compiler-2.12.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-library-2.12.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-parser-combinators_2.12-1.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-reflect-2.12.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-xml_2.12-1.2.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/shapeless_2.12-2.3.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/shims-0.9.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/slf4j-api-1.7.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/slf4j-log4j12-1.7.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/snappy-java-1.1.8.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-catalyst_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-core_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-graphx_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-hive-thriftserver_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-hive_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-kvstore_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-launcher_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-mllib-local_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-mllib_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-network-common_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-network-shuffle_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-repl_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-sketch_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-sql_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-streaming_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-tags_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-unsafe_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-yarn_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spire-macros_2.12-0.17.0-M1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spire-platform_2.12-0.17.0-M1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spire-util_2.12-0.17.0-M1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spire_2.12-0.17.0-M1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/stax-api-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/stax2-api-3.1.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/stream-2.9.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/super-csv-2.2.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/threeten-extra-1.5.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/token-provider-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/transaction-api-1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/univocity-parsers-2.9.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/velocity-1.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/woodstox-core-5.0.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/xbean-asm7-shaded-4.15.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/xz-1.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/zookeeper-3.4.14.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/zstd-jni-1.4.8-1.jar" : "System Classpath",
      "gs" : "System Classpath"
    },
    "hadoopProps" : {
      "adl.feature.ownerandgroup.enableupn" : "false",
      "adl.http.timeout" : "-1",
      "ambari.hive.db.schema.name" : "hive",
      "datanucleus.cache.level2.type" : "none",
      "datanucleus.connectionPool.maxPoolSize" : "10",
      "datanucleus.schema.autoCreateTables" : "true",
      "dfs.blocksize" : "536870912",
      "dfs.bytes-per-checksum" : "512",
      "dfs.client.failover.proxy.provider.pluto" : "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
      "dfs.client.failover.random.order" : "true",
      "dfs.client.read.shortcircuit" : "true",
      "dfs.client.read.shortcircuit.streams.cache.size" : "4096",
      "dfs.domain.socket.path" : "/var/lib/hadoop-hdfs/dn_socket",
      "dfs.ha.fencing.ssh.connect-timeout" : "30000",
      "dfs.ha.namenodes.pluto" : "nn1,nn2",
      "dfs.namenode.http-address.pluto.nn1" : "fks-fdp-galaxy-pluto-nn-0001.c.fks-fdp-galaxy.internal:50070",
      "dfs.namenode.http-address.pluto.nn2" : "fks-fdp-galaxy-pluto-nn-0002.c.fks-fdp-galaxy.internal:50070",
      "dfs.namenode.https-address.pluto.nn1" : "fks-fdp-galaxy-pluto-nn-0001.c.fks-fdp-galaxy.internal:50470",
      "dfs.namenode.https-address.pluto.nn2" : "fks-fdp-galaxy-pluto-nn-0002.c.fks-fdp-galaxy.internal:50470",
      "dfs.namenode.rpc-address.pluto.nn1" : "fks-fdp-galaxy-pluto-nn-0001.c.fks-fdp-galaxy.internal:8020",
      "dfs.namenode.rpc-address.pluto.nn2" : "fks-fdp-galaxy-pluto-nn-0002.c.fks-fdp-galaxy.internal:8020",
      "dfs.nameservices" : "pluto",
      "dfs.replication" : "3",
      "fdp.default.tier" : "Regular",
      "fdp.ironbank.url" : "http://console.fdp-ironbank-prod.fkcloud.in/",
      "fdp.orgqueue.cache.expire" : "300",
      "fdp.orgqueue.cache.size" : "100",
      "fdp.orgqueue.defaultQueue" : "adhoc",
      "fdp.orgqueue.gringotts.clientId" : "QAAS",
      "fdp.orgqueue.gringotts.clientSecret" : "*********(redacted)",
      "fdp.orgqueue.gringotts.url" : "http://gringotts.fdp-gringotts-prod.fkcloud.in/billingOrg/user",
      "fdp.orgqueue.queueNotFound.errorMessage" : "Queue mapping not found",
      "fdp.orgqueue.validInitiators" : "BADGER,QAAS,LQE,SUPERBI",
      "fdp.tier.expression" : "Regular",
      "fdp.tier.lqe.lock.wait.time.secs" : "30",
      "fdp.tier.lqe.max.sessions" : "1",
      "file.blocksize" : "67108864",
      "file.bytes-per-checksum" : "512",
      "file.client-write-packet-size" : "65536",
      "file.replication" : "1",
      "file.stream-buffer-size" : "4096",
      "fs.AbstractFileSystem.abfs.impl" : "org.apache.hadoop.fs.azurebfs.Abfs",
      "fs.AbstractFileSystem.abfss.impl" : "org.apache.hadoop.fs.azurebfs.Abfss",
      "fs.AbstractFileSystem.adl.impl" : "org.apache.hadoop.fs.adl.Adl",
      "fs.AbstractFileSystem.file.impl" : "org.apache.hadoop.fs.local.LocalFs",
      "fs.AbstractFileSystem.ftp.impl" : "org.apache.hadoop.fs.ftp.FtpFs",
      "fs.AbstractFileSystem.gs.impl" : "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS",
      "fs.AbstractFileSystem.har.impl" : "org.apache.hadoop.fs.HarFs",
      "fs.AbstractFileSystem.hdfs.impl" : "org.apache.hadoop.fs.Hdfs",
      "fs.AbstractFileSystem.s3a.impl" : "org.apache.hadoop.fs.s3a.S3A",
      "fs.AbstractFileSystem.swebhdfs.impl" : "org.apache.hadoop.fs.SWebHdfs",
      "fs.AbstractFileSystem.viewfs.impl" : "org.apache.hadoop.fs.viewfs.ViewFs",
      "fs.AbstractFileSystem.wasb.impl" : "org.apache.hadoop.fs.azure.Wasb",
      "fs.AbstractFileSystem.wasbs.impl" : "org.apache.hadoop.fs.azure.Wasbs",
      "fs.AbstractFileSystem.webhdfs.impl" : "org.apache.hadoop.fs.WebHdfs",
      "fs.abfs.impl" : "org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem",
      "fs.abfss.impl" : "org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem",
      "fs.adl.impl" : "org.apache.hadoop.fs.adl.AdlFileSystem",
      "fs.adl.oauth2.access.token.provider.type" : "*********(redacted)",
      "fs.automatic.close" : "true",
      "fs.azure.authorization" : "false",
      "fs.azure.authorization.caching.enable" : "true",
      "fs.azure.local.sas.key.mode" : "false",
      "fs.azure.sas.expiry.period" : "90d",
      "fs.azure.saskey.usecontainersaskeyforallaccess" : "true",
      "fs.azure.secure.mode" : "false",
      "fs.azure.user.agent.prefix" : "unknown",
      "fs.client.resolve.remote.symlinks" : "true",
      "fs.client.resolve.topology.enabled" : "false",
      "fs.defaultFS" : "hdfs://pluto",
      "fs.df.interval" : "60000",
      "fs.du.interval" : "600000",
      "fs.ftp.data.connection.mode" : "ACTIVE_LOCAL_DATA_CONNECTION_MODE",
      "fs.ftp.host" : "0.0.0.0",
      "fs.ftp.host.port" : "21",
      "fs.ftp.impl" : "org.apache.hadoop.fs.ftp.FTPFileSystem",
      "fs.ftp.transfer.mode" : "BLOCK_TRANSFER_MODE",
      "fs.gs.auth.service.account.enable" : "true",
      "fs.gs.batch.threads" : "60",
      "fs.gs.impl" : "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem",
      "fs.gs.max.requests.per.batch" : "300",
      "fs.gs.reported.permissions" : "777",
      "fs.har.impl.disable.cache" : "true",
      "fs.permissions.umask-mode" : "022",
      "fs.s3.useRequesterPaysHeader" : "true",
      "fs.s3a.assumed.role.credentials.provider" : "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider",
      "fs.s3a.assumed.role.session.duration" : "30m",
      "fs.s3a.assumed.role.sts.endpoint.region" : "us-west-1",
      "fs.s3a.attempts.maximum" : "20",
      "fs.s3a.block.size" : "32M",
      "fs.s3a.buffer.dir" : "${hadoop.tmp.dir}/s3a",
      "fs.s3a.change.detection.mode" : "server",
      "fs.s3a.change.detection.source" : "etag",
      "fs.s3a.change.detection.version.required" : "true",
      "fs.s3a.committer.magic.enabled" : "false",
      "fs.s3a.committer.name" : "file",
      "fs.s3a.committer.staging.abort.pending.uploads" : "true",
      "fs.s3a.committer.staging.conflict-mode" : "fail",
      "fs.s3a.committer.staging.tmp.path" : "tmp/staging",
      "fs.s3a.committer.staging.unique-filenames" : "true",
      "fs.s3a.committer.threads" : "8",
      "fs.s3a.connection.establish.timeout" : "5000",
      "fs.s3a.connection.maximum" : "15",
      "fs.s3a.connection.ssl.enabled" : "true",
      "fs.s3a.connection.timeout" : "200000",
      "fs.s3a.etag.checksum.enabled" : "false",
      "fs.s3a.fast.upload.active.blocks" : "4",
      "fs.s3a.fast.upload.buffer" : "disk",
      "fs.s3a.impl" : "org.apache.hadoop.fs.s3a.S3AFileSystem",
      "fs.s3a.list.version" : "2",
      "fs.s3a.max.total.tasks" : "5",
      "fs.s3a.metadatastore.authoritative" : "false",
      "fs.s3a.metadatastore.impl" : "org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore",
      "fs.s3a.multiobjectdelete.enable" : "true",
      "fs.s3a.multipart.purge" : "false",
      "fs.s3a.multipart.purge.age" : "86400",
      "fs.s3a.multipart.size" : "100M",
      "fs.s3a.multipart.threshold" : "2147483647",
      "fs.s3a.paging.maximum" : "5000",
      "fs.s3a.path.style.access" : "false",
      "fs.s3a.readahead.range" : "64K",
      "fs.s3a.retry.interval" : "500ms",
      "fs.s3a.retry.limit" : "${fs.s3a.attempts.maximum}",
      "fs.s3a.retry.throttle.interval" : "1000ms",
      "fs.s3a.retry.throttle.limit" : "${fs.s3a.attempts.maximum}",
      "fs.s3a.s3guard.cli.prune.age" : "86400000",
      "fs.s3a.s3guard.ddb.background.sleep" : "25ms",
      "fs.s3a.s3guard.ddb.max.retries" : "9",
      "fs.s3a.s3guard.ddb.table.capacity.read" : "500",
      "fs.s3a.s3guard.ddb.table.capacity.write" : "100",
      "fs.s3a.s3guard.ddb.table.create" : "false",
      "fs.s3a.s3guard.ddb.throttle.retry.interval" : "100ms",
      "fs.s3a.socket.recv.buffer" : "8192",
      "fs.s3a.socket.send.buffer" : "8192",
      "fs.s3a.threads.keepalivetime" : "60",
      "fs.s3a.threads.max" : "10",
      "fs.swift.impl" : "org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem",
      "fs.trash.checkpoint.interval" : "0",
      "fs.trash.interval" : "0",
      "fs.viewfs.rename.strategy" : "SAME_MOUNTPOINT",
      "fs.wasb.impl" : "org.apache.hadoop.fs.azure.NativeAzureFileSystem",
      "fs.wasbs.impl" : "org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure",
      "ftp.blocksize" : "67108864",
      "ftp.bytes-per-checksum" : "512",
      "ftp.client-write-packet-size" : "65536",
      "ftp.replication" : "3",
      "ftp.stream-buffer-size" : "4096",
      "google.cloud.auth.service.account.enable" : "true",
      "ha.failover-controller.cli-check.rpc-timeout.ms" : "20000",
      "ha.failover-controller.graceful-fence.connection.retries" : "1",
      "ha.failover-controller.graceful-fence.rpc-timeout.ms" : "5000",
      "ha.failover-controller.new-active.rpc-timeout.ms" : "60000",
      "ha.health-monitor.check-interval.ms" : "1000",
      "ha.health-monitor.connect-retry-interval.ms" : "1000",
      "ha.health-monitor.rpc-timeout.ms" : "45000",
      "ha.health-monitor.sleep-after-disconnect.ms" : "1000",
      "ha.zookeeper.acl" : "world:anyone:rwcda",
      "ha.zookeeper.parent-znode" : "/hadoop-ha",
      "ha.zookeeper.session-timeout.ms" : "10000",
      "hadoop.caller.context.enabled" : "false",
      "hadoop.caller.context.max.size" : "128",
      "hadoop.caller.context.signature.max.size" : "40",
      "hadoop.common.configuration.version" : "3.0.0",
      "hadoop.http.authentication.kerberos.keytab" : "${user.home}/hadoop.keytab",
      "hadoop.http.authentication.kerberos.principal" : "HTTP/_HOST@LOCALHOST",
      "hadoop.http.authentication.signature.secret.file" : "*********(redacted)",
      "hadoop.http.authentication.simple.anonymous.allowed" : "true",
      "hadoop.http.authentication.token.validity" : "*********(redacted)",
      "hadoop.http.authentication.type" : "simple",
      "hadoop.http.cross-origin.allowed-headers" : "X-Requested-With,Content-Type,Accept,Origin",
      "hadoop.http.cross-origin.allowed-methods" : "GET,POST,HEAD",
      "hadoop.http.cross-origin.allowed-origins" : "*",
      "hadoop.http.cross-origin.enabled" : "false",
      "hadoop.http.cross-origin.max-age" : "1800",
      "hadoop.http.filter.initializers" : "org.apache.hadoop.http.lib.StaticUserWebFilter",
      "hadoop.http.logs.enabled" : "true",
      "hadoop.http.staticuser.user" : "dr.who",
      "hadoop.jetty.logs.serve.aliases" : "true",
      "hadoop.kerberos.kinit.command" : "kinit",
      "hadoop.kerberos.min.seconds.before.relogin" : "60",
      "hadoop.proxyuser.hive.groups" : "*",
      "hadoop.proxyuser.hive.hosts" : "*",
      "hadoop.registry.jaas.context" : "Client",
      "hadoop.registry.secure" : "false",
      "hadoop.registry.system.acls" : "sasl:yarn@, sasl:mapred@, sasl:hdfs@",
      "hadoop.registry.zk.connection.timeout.ms" : "15000",
      "hadoop.registry.zk.quorum" : "localhost:2181",
      "hadoop.registry.zk.retry.ceiling.ms" : "60000",
      "hadoop.registry.zk.retry.interval.ms" : "1000",
      "hadoop.registry.zk.retry.times" : "5",
      "hadoop.registry.zk.root" : "/registry",
      "hadoop.registry.zk.session.timeout.ms" : "60000",
      "hadoop.rpc.protection" : "authentication",
      "hadoop.rpc.socket.factory.class.default" : "org.apache.hadoop.net.StandardSocketFactory",
      "hadoop.security.auth_to_local" : "DEFAULT",
      "hadoop.security.auth_to_local.mechanism" : "hadoop",
      "hadoop.security.authentication" : "simple",
      "hadoop.security.authorization" : "false",
      "hadoop.security.credential.clear-text-fallback" : "true",
      "hadoop.security.crypto.buffer.size" : "8192",
      "hadoop.security.crypto.cipher.suite" : "AES/CTR/NoPadding",
      "hadoop.security.crypto.codec.classes.aes.ctr.nopadding" : "org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec",
      "hadoop.security.dns.log-slow-lookups.enabled" : "false",
      "hadoop.security.dns.log-slow-lookups.threshold.ms" : "1000",
      "hadoop.security.group.mapping" : "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback",
      "hadoop.security.group.mapping.ldap.connection.timeout.ms" : "60000",
      "hadoop.security.group.mapping.ldap.conversion.rule" : "none",
      "hadoop.security.group.mapping.ldap.directory.search.timeout" : "10000",
      "hadoop.security.group.mapping.ldap.num.attempts" : "3",
      "hadoop.security.group.mapping.ldap.num.attempts.before.failover" : "3",
      "hadoop.security.group.mapping.ldap.posix.attr.gid.name" : "gidNumber",
      "hadoop.security.group.mapping.ldap.posix.attr.uid.name" : "uidNumber",
      "hadoop.security.group.mapping.ldap.read.timeout.ms" : "60000",
      "hadoop.security.group.mapping.ldap.search.attr.group.name" : "cn",
      "hadoop.security.group.mapping.ldap.search.attr.member" : "member",
      "hadoop.security.group.mapping.ldap.search.filter.group" : "(objectClass=group)",
      "hadoop.security.group.mapping.ldap.search.filter.user" : "(&(objectClass=user)(sAMAccountName={0}))",
      "hadoop.security.group.mapping.ldap.search.group.hierarchy.levels" : "0",
      "hadoop.security.group.mapping.ldap.ssl" : "false",
      "hadoop.security.group.mapping.providers.combined" : "true",
      "hadoop.security.groups.cache.background.reload" : "false",
      "hadoop.security.groups.cache.background.reload.threads" : "3",
      "hadoop.security.groups.cache.secs" : "300",
      "hadoop.security.groups.cache.warn.after.ms" : "5000",
      "hadoop.security.groups.negative-cache.secs" : "30",
      "hadoop.security.groups.shell.command.timeout" : "0s",
      "hadoop.security.instrumentation.requires.admin" : "false",
      "hadoop.security.java.secure.random.algorithm" : "SHA1PRNG",
      "hadoop.security.key.default.bitlength" : "128",
      "hadoop.security.key.default.cipher" : "AES/CTR/NoPadding",
      "hadoop.security.kms.client.authentication.retry-count" : "1",
      "hadoop.security.kms.client.encrypted.key.cache.expiry" : "43200000",
      "hadoop.security.kms.client.encrypted.key.cache.low-watermark" : "0.3f",
      "hadoop.security.kms.client.encrypted.key.cache.num.refill.threads" : "2",
      "hadoop.security.kms.client.encrypted.key.cache.size" : "500",
      "hadoop.security.kms.client.failover.sleep.base.millis" : "100",
      "hadoop.security.kms.client.failover.sleep.max.millis" : "2000",
      "hadoop.security.kms.client.timeout" : "60",
      "hadoop.security.random.device.file.path" : "/dev/urandom",
      "hadoop.security.sensitive-config-keys" : "*********(redacted)",
      "hadoop.security.uid.cache.secs" : "14400",
      "hadoop.service.shutdown.timeout" : "30s",
      "hadoop.shell.missing.defaultFs.warning" : "false",
      "hadoop.shell.safely.delete.limit.num.files" : "100",
      "hadoop.ssl.client.conf" : "ssl-client.xml",
      "hadoop.ssl.enabled" : "false",
      "hadoop.ssl.enabled.protocols" : "TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2",
      "hadoop.ssl.hostname.verifier" : "DEFAULT",
      "hadoop.ssl.keystores.factory.class" : "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory",
      "hadoop.ssl.require.client.cert" : "false",
      "hadoop.ssl.server.conf" : "ssl-server.xml",
      "hadoop.system.tags" : "YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL",
      "hadoop.tags.system" : "YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL",
      "hadoop.tmp.dir" : "/tmp/hadoop-${user.name}",
      "hadoop.user.group.static.mapping.overrides" : "dr.who=;",
      "hadoop.util.hash.type" : "murmur",
      "hadoop.workaround.non.threadsafe.getpwuid" : "true",
      "hadoop.zk.acl" : "world:anyone:rwcda",
      "hadoop.zk.num-retries" : "1000",
      "hadoop.zk.retry-interval-ms" : "1000",
      "hadoop.zk.timeout-ms" : "10000",
      "hbase.zookeeper.quorum" : "fks-fdp-galaxy-pluto-zkjn-0001.c.fks-fdp-galaxy.internal:2181,fks-fdp-galaxy-pluto-zkjn-0002.c.fks-fdp-galaxy.internal:2181,fks-fdp-galaxy-pluto-zkjn-0003.c.fks-fdp-galaxy.internal:2181",
      "hive.auto.convert.join" : "false",
      "hive.auto.convert.join.noconditionaltask" : "false",
      "hive.auto.convert.join.noconditionaltask.size" : "134217728",
      "hive.auto.convert.sortmerge.join" : "false",
      "hive.auto.convert.sortmerge.join.noconditionaltask" : "false",
      "hive.auto.convert.sortmerge.join.to.mapjoin" : "false",
      "hive.cbo.enable" : "true",
      "hive.cli.print.header" : "false",
      "hive.cluster.delegation.token.store.class" : "*********(redacted)",
      "hive.cluster.delegation.token.store.zookeeper.connectString" : "*********(redacted)",
      "hive.cluster.delegation.token.store.zookeeper.znode" : "*********(redacted)",
      "hive.compactor.abortedtxn.threshold" : "1000",
      "hive.compactor.check.interval" : "300L",
      "hive.compactor.delta.num.threshold" : "10",
      "hive.compactor.delta.pct.threshold" : "0.1f",
      "hive.compactor.initiator.on" : "false",
      "hive.compactor.worker.threads" : "0",
      "hive.compactor.worker.timeout" : "86400L",
      "hive.compute.query.using.stats" : "false",
      "hive.conf.restricted.list" : "hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role",
      "hive.convert.join.bucket.mapjoin.tez" : "true",
      "hive.default.fileformat.managed" : "ORC",
      "hive.driver.parallel.compilation" : "true",
      "hive.enforce.bucketing" : "true",
      "hive.enforce.sorting" : "true",
      "hive.enforce.sortmergebucketmapjoin" : "true",
      "hive.exec.compress.intermediate" : "true",
      "hive.exec.compress.output" : "false",
      "hive.exec.dynamic.partition" : "true",
      "hive.exec.dynamic.partition.mode" : "nonstrict",
      "hive.exec.failure.hooks" : "com.flipkart.fdp.hive.hooks.EnforceSingleQueryPostExecHook",
      "hive.exec.max.created.files" : "100000",
      "hive.exec.max.dynamic.partitions" : "1000000",
      "hive.exec.max.dynamic.partitions.pernode" : "1000000",
      "hive.exec.orc.compression.strategy" : "SPEED",
      "hive.exec.orc.default.compress" : "ZLIB",
      "hive.exec.orc.default.stripe.size" : "67108864",
      "hive.exec.parallel" : "true",
      "hive.exec.parallel.thread.number" : "8",
      "hive.exec.post.hooks" : "org.apache.hadoop.hive.ql.hooks.LineageLogger,com.flipkart.fdp.hive.hooks.EnforceSingleQueryPostExecHook",
      "hive.exec.pre.hooks" : "com.flipkart.fdp.hive.hooks.EnforceSingleQueryPreExecHook",
      "hive.exec.reducers.bytes.per.reducer" : "134217728",
      "hive.exec.reducers.max" : "250",
      "hive.exec.scratchdir" : "gs://stage-hive-metastore-pluto/user/hiveexternaldir",
      "hive.exec.submit.local.task.via.child" : "true",
      "hive.exec.submitviachild" : "false",
      "hive.execution.engine" : "tez",
      "hive.fetch.task.aggr" : "true",
      "hive.fetch.task.conversion" : "more",
      "hive.fetch.task.conversion.threshold" : "1073741824",
      "hive.fileformat.managed" : "ORC",
      "hive.heapsize" : "2048",
      "hive.input.format" : "org.apache.hadoop.hive.ql.io.CombineHiveInputFormat",
      "hive.limit.optimize.enable" : "true",
      "hive.limit.pushdown.memory.usage" : "0.2",
      "hive.map.aggr" : "true",
      "hive.map.aggr.hash.force.flush.memory.threshold" : "0.5",
      "hive.map.aggr.hash.min.reduction" : "0.5",
      "hive.map.aggr.hash.percentmemory" : "0.5",
      "hive.mapjoin.bucket.cache.size" : "1000",
      "hive.mapjoin.localtask.max.memory.usage" : "0.4",
      "hive.mapjoin.optimized.hashtable" : "false",
      "hive.mapred.reduce.tasks.speculative.execution" : "false",
      "hive.merge.mapfiles" : "true",
      "hive.merge.mapredfiles" : "false",
      "hive.merge.orcfile.stripe.level" : "true",
      "hive.merge.rcfile.block.level" : "true",
      "hive.merge.size.per.task" : "256000000",
      "hive.merge.smallfiles.avgsize" : "16000000",
      "hive.merge.tezfiles" : "true",
      "hive.metastore.authorization.storage.checks" : "false",
      "hive.metastore.cache.pinobjtypes" : "Table,Database,Type,FieldSchema,Order",
      "hive.metastore.client.connect.retry.delay" : "5s",
      "hive.metastore.client.scheme.handlers" : "com.flipkart.fdp.hive.metastore.ELBSchemeHandler",
      "hive.metastore.client.socket.timeout" : "1800s",
      "hive.metastore.connect.retries" : "24",
      "hive.metastore.execute.setugi" : "true",
      "hive.metastore.failure.retries" : "24",
      "hive.metastore.fshandler.threads" : "15",
      "hive.metastore.kerberos.keytab.file" : "/etc/security/keytabs/hive.service.keytab",
      "hive.metastore.kerberos.principal" : "hive/_HOST@EXAMPLE.COM",
      "hive.metastore.limit.partition.request" : "-1",
      "hive.metastore.metrics.enabled" : "true",
      "hive.metastore.pre.event.listeners" : "org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener",
      "hive.metastore.sasl.enabled" : "false",
      "hive.metastore.server.max.threads" : "100000",
      "hive.metastore.uris" : "thrift://10.116.17.2:9083",
      "hive.metastore.warehouse.dir" : "gs://stage-hive-metastore-pluto/apps/hive/warehouse",
      "hive.msck.path.validation" : "ignore",
      "hive.msck.repair.batch.size" : "0",
      "hive.optimize.bucketmapjoin" : "true",
      "hive.optimize.bucketmapjoin.sortedmerge" : "true",
      "hive.optimize.constant.propagation" : "true",
      "hive.optimize.index.filter" : "true",
      "hive.optimize.mapjoin.mapreduce" : "true",
      "hive.optimize.metadataonly" : "true",
      "hive.optimize.null.scan" : "true",
      "hive.optimize.reducededuplication" : "true",
      "hive.optimize.reducededuplication.min.reducer" : "4",
      "hive.optimize.sort.dynamic.partition" : "true",
      "hive.orc.compute.splits.num.threads" : "10",
      "hive.orc.splits.include.file.footer" : "false",
      "hive.prewarm.enabled" : "false",
      "hive.prewarm.numcontainers" : "10",
      "hive.querylog.enable.plan.progress" : "false",
      "hive.security.authenticator.manager" : "org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator",
      "hive.security.authorization.enabled" : "false",
      "hive.security.authorization.manager" : "org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory",
      "hive.security.authorization.sqlstd.confwhitelist.append" : "|initiator.*|job.*|mapred.*|badger.*|azkaban.*|tez.*|dfs.*|mapreduce.*|hive.*|hbase.*|light.*|beeline.*|orc.*|fdp.*|.*impersonation.*|fs.gs.*",
      "hive.security.metastore.authenticator.manager" : "org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator",
      "hive.security.metastore.authorization.auth.reads" : "true",
      "hive.security.metastore.authorization.manager" : "\n            org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider\n        ",
      "hive.server2.allow.user.substitution" : "true",
      "hive.server2.authentication" : "NONE",
      "hive.server2.authentication.spnego.keytab" : "HTTP/_HOST@EXAMPLE.COM",
      "hive.server2.authentication.spnego.principal" : "/etc/security/keytabs/spnego.service.keytab",
      "hive.server2.clear.dangling.scratchdir" : "true",
      "hive.server2.clear.dangling.scratchdir.interval" : "1800",
      "hive.server2.enable.doAs" : "true",
      "hive.server2.enable.impersonation" : "true",
      "hive.server2.idle.operation.timeout" : "1d",
      "hive.server2.idle.session.timeout" : "1d",
      "hive.server2.logging.operation.enabled" : "true",
      "hive.server2.logging.operation.log.location" : "${java.io.tmpdir}/${user.name}/operation_logs",
      "hive.server2.metrics.enabled" : "true",
      "hive.server2.session.check.interval" : "60m",
      "hive.server2.support.dynamic.service.discovery" : "true",
      "hive.server2.table.type.mapping" : "CLASSIC",
      "hive.server2.tez.default.queues" : "default",
      "hive.server2.tez.initialize.default.sessions" : "false",
      "hive.server2.tez.sessions.per.default.queue" : "1",
      "hive.server2.thrift.http.path" : "cliservice",
      "hive.server2.thrift.http.port" : "10001",
      "hive.server2.thrift.max.worker.threads" : "500",
      "hive.server2.thrift.sasl.qop" : "auth",
      "hive.server2.transport.mode" : "http",
      "hive.server2.use.SSL" : "false",
      "hive.server2.zookeeper.namespace" : "fks-fdp-galaxy-hive3-hs2-pluto",
      "hive.session.history.enabled" : "false",
      "hive.smbjoin.cache.rows" : "1000",
      "hive.stats.autogather" : "true",
      "hive.stats.dbclass" : "fs",
      "hive.stats.fetch.column.stats" : "false",
      "hive.stats.fetch.partition.stats" : "false",
      "hive.strict.checks.cartesian.product" : "false",
      "hive.strict.checks.type.safety" : "false",
      "hive.support.concurrency" : "false",
      "hive.support.sql11.reserved.keywords" : "true",
      "hive.tez.auto.reducer.parallelism" : "false",
      "hive.tez.container.size" : "3072",
      "hive.tez.cpu.vcores" : "-1",
      "hive.tez.dynamic.partition.pruning" : "true",
      "hive.tez.dynamic.partition.pruning.max.data.size" : "104857600",
      "hive.tez.dynamic.partition.pruning.max.event.size" : "1048576",
      "hive.tez.input.format" : "org.apache.hadoop.hive.ql.io.HiveInputFormat",
      "hive.tez.log.level" : "INFO",
      "hive.tez.max.partition.factor" : "2.0",
      "hive.tez.min.partition.factor" : "0.25",
      "hive.tez.smb.number.waves" : "0.5",
      "hive.txn.manager" : "org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager",
      "hive.txn.max.open.batch" : "1000",
      "hive.txn.timeout" : "300",
      "hive.user.install.directory" : "gs://stage-hive-metastore-pluto/user/",
      "hive.vectorized.complex.types.enabled" : "false",
      "hive.vectorized.execution.enabled" : "true",
      "hive.vectorized.execution.ptf.enabled" : "false",
      "hive.vectorized.execution.reduce.enabled" : "true",
      "hive.vectorized.groupby.checkinterval" : "4096",
      "hive.vectorized.groupby.complex.types.enabled" : "false",
      "hive.vectorized.groupby.flush.percent" : "0.1",
      "hive.vectorized.groupby.maxentries" : "10000",
      "hive.zookeeper.client.port" : "2181",
      "hive.zookeeper.namespace" : "fks-sco-hive-pluto-zookeeper-namespace",
      "hive.zookeeper.quorum" : "fks-fdp-galaxy-pluto-zkjn-0001.c.fks-fdp-galaxy.internal:2181,fks-fdp-galaxy-pluto-zkjn-0002.c.fks-fdp-galaxy.internal:2181,fks-fdp-galaxy-pluto-zkjn-0003.c.fks-fdp-galaxy.internal:2181",
      "hive.zookeeper.session.timeout" : "120s",
      "io.compression.codec.bzip2.library" : "system-native",
      "io.compression.codec.lzo.class" : "com.hadoop.compression.lzo.LzoCodec",
      "io.compression.codecs" : "org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,com.hadoop.compression.fourmc.Lz4Codec,com.hadoop.compression.fourmc.Lz4MediumCodec,com.hadoop.compression.fourmc.Lz4HighCodec,com.hadoop.compression.fourmc.Lz4UltraCodec,com.hadoop.compression.fourmc.FourMcCodec,com.hadoop.compression.fourmc.FourMcMediumCodec,com.hadoop.compression.fourmc.FourMcHighCodec,com.hadoop.compression.fourmc.FourMcUltraCodec",
      "io.erasurecode.codec.rs-legacy.rawcoders" : "rs-legacy_java",
      "io.erasurecode.codec.rs.rawcoders" : "rs_native,rs_java",
      "io.erasurecode.codec.xor.rawcoders" : "xor_native,xor_java",
      "io.file.buffer.size" : "65536",
      "io.map.index.interval" : "128",
      "io.map.index.skip" : "0",
      "io.mapfile.bloom.error.rate" : "0.005",
      "io.mapfile.bloom.size" : "1048576",
      "io.seqfile.compress.blocksize" : "1000000",
      "io.seqfile.local.dir" : "${hadoop.tmp.dir}/io/local",
      "io.serializations" : "org.apache.hadoop.io.serializer.WritableSerialization",
      "io.skip.checksum.errors" : "false",
      "ipc.client.bind.wildcard.addr" : "false",
      "ipc.client.connect.max.retries" : "50",
      "ipc.client.connect.max.retries.on.timeouts" : "45",
      "ipc.client.connect.retry.interval" : "1000",
      "ipc.client.connect.timeout" : "20000",
      "ipc.client.connection.maxidletime" : "30000",
      "ipc.client.fallback-to-simple-auth-allowed" : "false",
      "ipc.client.idlethreshold" : "8000",
      "ipc.client.kill.max" : "10",
      "ipc.client.low-latency" : "false",
      "ipc.client.ping" : "true",
      "ipc.client.rpc-timeout.ms" : "0",
      "ipc.client.tcpnodelay" : "true",
      "ipc.maximum.data.length" : "67108864",
      "ipc.maximum.response.length" : "134217728",
      "ipc.ping.interval" : "60000",
      "ipc.server.listen.queue.size" : "128",
      "ipc.server.log.slow.rpc" : "false",
      "ipc.server.max.connections" : "0",
      "javax.jdo.option.ConnectionDriverName" : "com.mysql.jdbc.Driver",
      "javax.jdo.option.ConnectionPassword" : "*********(redacted)",
      "javax.jdo.option.ConnectionURL" : "jdbc:mysql://10.117.192.58/stage_hive_metastore?createDatabaseIfNotExist=true",
      "javax.jdo.option.ConnectionUserName" : "stage_sco_rw",
      "jobname.enricher.class" : "org.apache.hadoop.hive.ql.propertymodifier.NoEnrichment",
      "map.sort.class" : "org.apache.hadoop.util.QuickSort",
      "net.topology.impl" : "org.apache.hadoop.net.NetworkTopology",
      "net.topology.node.switch.mapping.impl" : "org.apache.hadoop.net.ScriptBasedMapping",
      "net.topology.script.file.name" : "/etc/hadoop/conf/topology.py",
      "net.topology.script.number.args" : "100",
      "nfs.exports.allowed.hosts" : "* rw",
      "orc.schema.evolution.case.sensitive" : "false",
      "parser.timeoutSec" : "900",
      "queue.enforcer.class" : "com.flipkart.fdp.hive.orgqueue.OrgQueueEnforcerForInitiator",
      "rpc.metrics.quantile.enable" : "false",
      "seq.io.sort.factor" : "100",
      "seq.io.sort.mb" : "100",
      "tfile.fs.input.buffer.size" : "262144",
      "tfile.fs.output.buffer.size" : "262144",
      "tfile.io.chunk.size" : "1048576",
      "zookeeper.znode.parent" : "/hbase-unsecure"
    },
    "runtimeInfo" : {
      "javaHome" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre",
      "javaVersion" : "1.8.0_172 (Oracle Corporation)",
      "scalaVersion" : "version 2.12.10"
    },
    "sparkBuildInfo" : {
      "sparkBuildBranch" : "fdp-3.1.2-hadoop-3.2",
      "sparkBuildDate" : "2023-04-05T09:07:25Z",
      "sparkBuildRevision" : "1f03c4907e323e2f782742ceae6feff6c8ddcd12",
      "sparkBuildUser" : "somi.biswas",
      "sparkBuildVersion" : "3.1.2"
    },
    "sparkProps" : {
      "spark.app.id" : "application_1699449121496_0375",
      "spark.app.name" : "Spark shell",
      "spark.app.startTime" : "1701340207853",
      "spark.benchmarkId" : "20231130-155900-tpcds-1gb-iceberg-load",
      "spark.cleaner.ttl" : "86400",
      "spark.delta.logStore.gs.impl" : "io.delta.storage.GCSLogStore",
      "spark.driver.appUIAddress" : "http://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:4046",
      "spark.driver.cores" : "1",
      "spark.driver.extraClassPath" : "gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar",
      "spark.driver.extraJavaOptions" : "-Denv=prod -Dcom.sun.management.jmxremote.port=0 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=0 -XX:MaxDirectMemorySize=800M -XX:MaxMetaspaceSize=256M -XX:CompressedClassSpaceSize=100M -XX:+UnlockDiagnosticVMOptions -Djob.numOfRePartitions=30",
      "spark.driver.extraLibraryPath" : "/usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu",
      "spark.driver.host" : "fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal",
      "spark.driver.memory" : "5120m",
      "spark.driver.port" : "34105",
      "spark.dynamicAllocation.enabled" : "true",
      "spark.dynamicAllocation.executorIdleTimeout" : "60s",
      "spark.dynamicAllocation.maxExecutors" : "200",
      "spark.eventLog.dir" : "gs://fks-fdp-infra-job-history/pluto/spark-job-history",
      "spark.eventLog.enabled" : "true",
      "spark.executor.cores" : "1",
      "spark.executor.extraClassPath" : "gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar",
      "spark.executor.extraJavaOptions" : "-XX:MaxDirectMemorySize=8096m -Dio.netty.maxDirectMemory=8096m -XX:+UseG1GC -XX:ConcGCThreads=2",
      "spark.executor.extraLibraryPath" : "/usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu",
      "spark.executor.id" : "driver",
      "spark.executor.memory" : "10240m",
      "spark.fdp.orgqueue.cache.expire" : "300",
      "spark.fdp.orgqueue.cache.size" : "100",
      "spark.fdp.orgqueue.defaultQueue" : "adhoc",
      "spark.fdp.orgqueue.gringotts.clientId" : "QAAS",
      "spark.fdp.orgqueue.gringotts.clientSecret" : "*********(redacted)",
      "spark.fdp.orgqueue.gringotts.url" : "http://10.47.6.66/billingOrg/user",
      "spark.fdp.orgqueue.ironbank.url" : "http://10.47.4.16:/queue/",
      "spark.fdp.orgqueue.queueNotFound.errorMessage" : "Queue mapping not found",
      "spark.fdp.orgqueue.validInitiators" : "BADGER,QAAS",
      "spark.hadoop.fs.s3.useRequesterPaysHeader" : "true",
      "spark.hadoop.yarn.timeline-service.enabled" : "false",
      "spark.history.fs.cleaner.interval" : "1d",
      "spark.history.fs.cleaner.maxAge" : "60d",
      "spark.history.fs.logDirectory" : "gs://fks-fdp-infra-job-history/pluto/spark-job-history",
      "spark.history.provider" : "org.apache.spark.deploy.history.FsHistoryProvider",
      "spark.home" : "/var/lib/fk-pf-spark3",
      "spark.jars" : "",
      "spark.master" : "yarn",
      "spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS" : "fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal",
      "spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES" : "http://fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0375,http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0375",
      "spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS" : "fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088",
      "spark.queue.enforcer.class" : "com.flipkart.fdp.orgqueue.OrgQueueEnforcerForInitiator",
      "spark.repl.class.outputDir" : "/grid/1/spark3/tmp/spark-10e271bd-3c13-4662-9310-466769eaffd2/repl-ce537423-ce5a-4483-a0da-6b2b6d017970",
      "spark.repl.class.uri" : "spark://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:34105/classes",
      "spark.repl.local.jars" : "file:///home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar",
      "spark.scheduler.mode" : "FIFO",
      "spark.shuffle.service.enabled" : "true",
      "spark.shuffle.useOldFetchProtocol" : "true",
      "spark.sql.catalog.hive_pluto" : "org.apache.iceberg.spark.SparkCatalog",
      "spark.sql.catalog.hive_pluto.type" : "hive",
      "spark.sql.catalog.hive_pluto.uri" : "thrift://10.116.17.2:9083",
      "spark.sql.catalogImplementation" : "hive",
      "spark.sql.extensions" : "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions",
      "spark.sql.sources.partitionOverwriteMode" : "dynamic",
      "spark.streaming.concurrentJobs" : "4",
      "spark.submit.deployMode" : "client",
      "spark.submit.pyFiles" : "",
      "spark.ui.filters" : "org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter",
      "spark.ui.showConsoleProgress" : "true",
      "spark.yarn.dist.jars" : "gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar,file:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar,gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,file:///home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar",
      "spark.yarn.driver.memoryOverhead" : "4096",
      "spark.yarn.executor.memoryOverhead" : "4096",
      "spark.yarn.historyServer.address" : "http://fks-fdp-galaxy-pluto-hs-0001-m.c.fks-fdp-galaxy.internal:18080",
      "spark.yarn.jars" : "",
      "spark.yarn.queue" : "de_adhoc",
      "spark.yarn.report.interval" : "60s",
      "spark.yarn.secondary.jars" : "hadoop-lzo-0.6.0.2.4.0.0-169.jar,hadoop-4mc-1.1.0.jar,json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar,iceberg-hive-runtime-1.2.0.jar,iceberg-spark-runtime-3.1_2.12-1.2.0.jar"
    },
    "systemProps" : {
      "SPARK_SUBMIT" : "true",
      "awt.toolkit" : "sun.awt.X11.XToolkit",
      "com.sun.management.jmxremote.authenticate" : "false",
      "com.sun.management.jmxremote.port" : "0",
      "com.sun.management.jmxremote.ssl" : "false",
      "env" : "prod",
      "file.encoding" : "ANSI_X3.4-1968",
      "file.encoding.pkg" : "sun.io",
      "file.separator" : "/",
      "java.awt.graphicsenv" : "sun.awt.X11GraphicsEnvironment",
      "java.awt.printerjob" : "sun.print.PSPrinterJob",
      "java.class.version" : "52.0",
      "java.endorsed.dirs" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/endorsed",
      "java.ext.dirs" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext",
      "java.home" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre",
      "java.io.tmpdir" : "/tmp",
      "java.library.path" : "/usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib",
      "java.rmi.server.randomIDs" : "true",
      "java.runtime.name" : "Java(TM) SE Runtime Environment",
      "java.runtime.version" : "1.8.0_172-b11",
      "java.specification.name" : "Java Platform API Specification",
      "java.specification.vendor" : "Oracle Corporation",
      "java.specification.version" : "1.8",
      "java.vendor" : "Oracle Corporation",
      "java.vendor.url" : "http://java.oracle.com/",
      "java.vendor.url.bug" : "http://bugreport.sun.com/bugreport/",
      "java.version" : "1.8.0_172",
      "java.vm.info" : "mixed mode",
      "java.vm.name" : "Java HotSpot(TM) 64-Bit Server VM",
      "java.vm.specification.name" : "Java Virtual Machine Specification",
      "java.vm.specification.vendor" : "Oracle Corporation",
      "java.vm.specification.version" : "1.8",
      "java.vm.vendor" : "Oracle Corporation",
      "java.vm.version" : "25.172-b11",
      "jetty.git.hash" : "b881a572662e1943a14ae12e7e1207989f218b74",
      "job.numOfRePartitions" : "30",
      "line.separator" : "\n",
      "os.arch" : "amd64",
      "os.name" : "Linux",
      "os.version" : "4.19.0-19-cloud-amd64",
      "path.separator" : ":",
      "scala.usejavacp" : "true",
      "sun.arch.data.model" : "64",
      "sun.boot.class.path" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/classes",
      "sun.boot.library.path" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/amd64",
      "sun.cpu.endian" : "little",
      "sun.cpu.isalist" : "",
      "sun.io.unicode.encoding" : "UnicodeLittle",
      "sun.java.command" : "org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.sql.sources.partitionOverwriteMode=dynamic --conf spark.executor.memory=10240m --conf spark.sql.catalog.hive_pluto=org.apache.iceberg.spark.SparkCatalog --conf spark.driver.memory=5120m --conf spark.sql.catalog.hive_pluto.uri=thrift://10.116.17.2:9083 --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.hive_pluto.type=hive --conf spark.benchmarkId=20231130-155900-tpcds-1gb-iceberg-load --conf spark.executor.extraJavaOptions=-XX:MaxDirectMemorySize=8096m -Dio.netty.maxDirectMemory=8096m -XX:+UseG1GC -XX:ConcGCThreads=2 --conf spark.hadoop.fs.s3.useRequesterPaysHeader=true --conf spark.delta.logStore.gs.impl=io.delta.storage.GCSLogStore --class org.apache.spark.repl.Main --name Spark shell --queue de_adhoc --jars /home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-benchmarks.jar,/var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,/var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar spark-shell -I 20231130-155900-tpcds-1gb-iceberg-load_shell_init.scala",
      "sun.java.launcher" : "SUN_STANDARD",
      "sun.jnu.encoding" : "ANSI_X3.4-1968",
      "sun.management.compiler" : "HotSpot 64-Bit Tiered Compilers",
      "sun.nio.ch.bugLevel" : "",
      "sun.os.patch.level" : "unknown",
      "user.country" : "US",
      "user.dir" : "/home/vanshika.yadav",
      "user.home" : "/home/vanshika.yadav",
      "user.language" : "en",
      "user.name" : "vanshika.yadav",
      "user.timezone" : "Asia/Kolkata"
    }
  }
}
Copying file:///home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-report.json [Content-Type=application/json]...
/ [0 files][    0.0 B/ 62.6 KiB]                                                / [1 files][ 62.6 KiB/ 62.6 KiB]                                                
Operation completed over 1 objects/62.6 KiB.                                     
FILE UPLOAD: Uploaded /home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-report.json to gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/reports/json/
Copying file:///home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-report.csv [Content-Type=text/csv]...
/ [0 files][    0.0 B/  127.0 B]                                                / [1 files][  127.0 B/  127.0 B]                                                
Operation completed over 1 objects/127.0 B.                                      
FILE UPLOAD: Uploaded /home/vanshika.yadav/20231130-155900-tpcds-1gb-iceberg-load-report.csv to gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/reports/csv/
org.apache.spark.sql.AnalysisException: Table or view not found: hive_pluto.tpcds_sf1_ICEBERG.call_center;
'UnresolvedRelation [hive_pluto, tpcds_sf1_ICEBERG, call_center], [], false

FAILED
