Listening for transport dt_socket at address: 41071
23/11/30 16:41:28 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:41:28 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:41:28 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:41:28 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:41:29 INFO SignalUtils: Registering signal handler for INT
23/11/30 16:41:29 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:41:29 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:41:33 INFO HiveConf: Found configuration file file:/var/lib/fk-pf-spark3/conf/hive-site.xml
23/11/30 16:41:33 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:41:33 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:41:33 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:41:33 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:41:33 INFO SparkContext: Running Spark version 3.1.2
23/11/30 16:41:33 INFO ResourceUtils: ==============================================================
23/11/30 16:41:33 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/30 16:41:33 INFO ResourceUtils: ==============================================================
23/11/30 16:41:33 INFO SparkContext: Submitted application: Spark shell
23/11/30 16:41:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 4096, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 10240, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/30 16:41:33 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
23/11/30 16:41:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/30 16:41:33 INFO SecurityManager: Changing view acls to: vanshika.yadav
23/11/30 16:41:33 INFO SecurityManager: Changing modify acls to: vanshika.yadav
23/11/30 16:41:33 INFO SecurityManager: Changing view acls groups to: 
23/11/30 16:41:33 INFO SecurityManager: Changing modify acls groups to: 
23/11/30 16:41:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vanshika.yadav); groups with view permissions: Set(); users  with modify permissions: Set(vanshika.yadav); groups with modify permissions: Set()
23/11/30 16:41:33 INFO Utils: Successfully started service 'sparkDriver' on port 40915.
23/11/30 16:41:33 INFO SparkEnv: Registering MapOutputTracker
23/11/30 16:41:33 INFO SparkEnv: Registering BlockManagerMaster
23/11/30 16:41:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/30 16:41:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/30 16:41:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/30 16:41:33 INFO DiskBlockManager: Created local directory at /grid/1/spark3/tmp/blockmgr-b164d17f-63c5-4a7a-8c86-b6ee5c202b67
23/11/30 16:41:33 INFO MemoryStore: MemoryStore started with capacity 2.5 GiB
23/11/30 16:41:33 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/30 16:41:33 INFO log: Logging initialized @6230ms to org.sparkproject.jetty.util.log.Slf4jLog
23/11/30 16:41:33 INFO Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_172-b11
23/11/30 16:41:33 INFO Server: Started @6331ms
23/11/30 16:41:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/11/30 16:41:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/11/30 16:41:33 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/11/30 16:41:33 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/11/30 16:41:33 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
23/11/30 16:41:33 INFO AbstractConnector: Started ServerConnector@3b8a063d{HTTP/1.1, (http/1.1)}{0.0.0.0:4045}
23/11/30 16:41:33 INFO Utils: Successfully started service 'SparkUI' on port 4045.
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@28f6a008{/jobs,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6e475994{/jobs/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1a99744a{/jobs/job,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@75d9b73c{/jobs/job/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5a08d301{/stages,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5b3c2a9f{/stages/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4f571c0e{/stages/stage,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@677274e7{/stages/stage/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@16279a5d{/stages/pool,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6bd8c398{/stages/pool/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1e487d57{/storage,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@66c32e15{/storage/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@304704ae{/storage/rdd,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@533a27f8{/storage/rdd/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@75b25ec3{/environment,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6b60d99c{/environment/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@33997e07{/executors,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@eda7dd3{/executors/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@71c69628{/executors/threadDump,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1028a747{/executors/threadDump/json,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@613ba54e{/static,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@ce8b59e{/,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@344cf00f{/api,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@126e2710{/jobs/job/kill,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1a22325d{/stages/stage/kill,null,AVAILABLE,@Spark}
23/11/30 16:41:33 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:4045
23/11/30 16:41:33 INFO Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
23/11/30 16:41:34 INFO AHSProxy: Connecting to Application History server at fks-fdp-galaxy-pluto-hs-0001-m.c.fks-fdp-galaxy.internal/10.116.4.108:10200
23/11/30 16:41:34 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm2
23/11/30 16:41:34 INFO Client: Requesting a new application from cluster with 30 NodeManagers
23/11/30 16:41:34 INFO Configuration: resource-types.xml not found
23/11/30 16:41:34 INFO ResourceUtils: Unable to find 'resource-types.xml'.
23/11/30 16:41:34 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (163840 MB per container)
23/11/30 16:41:34 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
23/11/30 16:41:34 INFO Client: Setting up container launch context for our AM
23/11/30 16:41:34 INFO Client: Setting up the launch environment for our AM container
23/11/30 16:41:34 INFO Client: Preparing resources for our AM container
23/11/30 16:41:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/HikariCP-2.5.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/HikariCP-2.5.1.jar
23/11/30 16:41:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/JLargeArrays-1.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/JLargeArrays-1.5.jar
23/11/30 16:41:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:35 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/JTransforms-3.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/JTransforms-3.1.jar
23/11/30 16:41:35 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/RoaringBitmap-0.9.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/RoaringBitmap-0.9.0.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/ST4-4.0.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/ST4-4.0.4.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/accessors-smart-1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/accessors-smart-1.2.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/activation-1.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/activation-1.1.1.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/aircompressor-0.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/aircompressor-0.10.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/algebra_2.12-2.0.0-M2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/algebra_2.12-2.0.0-M2.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/antlr-runtime-3.5.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/antlr-runtime-3.5.2.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/antlr4-runtime-4.8-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/antlr4-runtime-4.8-1.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/aopalliance-1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/aopalliance-1.0.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/aopalliance-repackaged-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/aopalliance-repackaged-2.6.1.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:36 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arpack_combined_all-0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/arpack_combined_all-0.1.jar
23/11/30 16:41:36 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arrow-format-2.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/arrow-format-2.0.0.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arrow-memory-core-2.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/arrow-memory-core-2.0.0.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arrow-memory-netty-2.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/arrow-memory-netty-2.0.0.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/arrow-vector-2.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/arrow-vector-2.0.0.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/audience-annotations-0.5.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/audience-annotations-0.5.0.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/avro-1.8.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/avro-1.8.2.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/avro-ipc-1.8.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/avro-ipc-1.8.2.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/avro-mapred-1.8.2-hadoop2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/avro-mapred-1.8.2-hadoop2.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/bcpkix-jdk15on-1.60.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/bcpkix-jdk15on-1.60.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/bcprov-jdk15on-1.60.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/bcprov-jdk15on-1.60.jar
23/11/30 16:41:37 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:37 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/bigquery-connector-hadoop3-latest.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/bigquery-connector-hadoop3-latest.jar
23/11/30 16:41:38 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:38 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/bonecp-0.8.0.RELEASE.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/bonecp-0.8.0.RELEASE.jar
23/11/30 16:41:38 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:38 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/breeze-macros_2.12-1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/breeze-macros_2.12-1.0.jar
23/11/30 16:41:38 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:38 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/breeze_2.12-1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/breeze_2.12-1.0.jar
23/11/30 16:41:38 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:38 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/cats-kernel_2.12-2.0.0-M4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/cats-kernel_2.12-2.0.0-M4.jar
23/11/30 16:41:38 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:38 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/chill-java-0.9.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/chill-java-0.9.5.jar
23/11/30 16:41:38 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/chill_2.12-0.9.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/chill_2.12-0.9.5.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-beanutils-1.9.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-beanutils-1.9.4.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-cli-1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-cli-1.2.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-codec-1.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-codec-1.10.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-collections-3.2.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-collections-3.2.2.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-compiler-3.0.16.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-compiler-3.0.16.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-compress-1.20.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-compress-1.20.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-configuration2-2.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-configuration2-2.1.1.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-crypto-1.1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-crypto-1.1.0.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-daemon-1.0.13.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-daemon-1.0.13.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-dbcp-1.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-dbcp-1.4.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-httpclient-3.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-httpclient-3.1.jar
23/11/30 16:41:39 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:39 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-io-2.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-io-2.5.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-lang-2.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-lang-2.6.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-lang3-3.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-lang3-3.10.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-logging-1.1.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-logging-1.1.3.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-math3-3.4.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-math3-3.4.1.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-net-3.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-net-3.1.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-pool-1.5.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-pool-1.5.4.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/commons-text-1.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/commons-text-1.6.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/compress-lzf-1.0.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/compress-lzf-1.0.3.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/core-1.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/core-1.1.2.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/curator-client-2.13.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/curator-client-2.13.0.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/curator-framework-2.13.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/curator-framework-2.13.0.jar
23/11/30 16:41:40 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:40 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/curator-recipes-2.13.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/curator-recipes-2.13.0.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/datanucleus-api-jdo-4.2.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/datanucleus-api-jdo-4.2.4.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/datanucleus-core-4.1.17.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/datanucleus-core-4.1.17.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/datanucleus-rdbms-4.1.19.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/datanucleus-rdbms-4.1.19.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/derby-10.12.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/derby-10.12.1.1.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/dnsjava-2.1.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/dnsjava-2.1.7.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/ehcache-3.3.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/ehcache-3.3.1.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/fdp-deps-3.1.2.fdp.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/fdp-deps-3.1.2.fdp.1.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/flatbuffers-java-1.9.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/flatbuffers-java-1.9.0.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:41 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/gcs-connector-hadoop3-2.2.7-shaded.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/gcs-connector-hadoop3-2.2.7-shaded.jar
23/11/30 16:41:41 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:42 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/geronimo-jcache_1.0_spec-1.0-alpha-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/geronimo-jcache_1.0_spec-1.0-alpha-1.jar
23/11/30 16:41:42 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:42 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/gson-2.2.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/gson-2.2.4.jar
23/11/30 16:41:42 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:42 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/guava-27.0-jre.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/guava-27.0-jre.jar
23/11/30 16:41:42 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:42 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/guice-4.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/guice-4.0.jar
23/11/30 16:41:42 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:42 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/guice-servlet-4.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/guice-servlet-4.0.jar
23/11/30 16:41:42 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:42 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-annotations-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-annotations-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-auth-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-auth-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-client-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-client-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-common-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-common-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-hdfs-client-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-hdfs-client-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-mapreduce-client-common-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-mapreduce-client-common-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-mapreduce-client-core-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-mapreduce-client-core-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-mapreduce-client-jobclient-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-mapreduce-client-jobclient-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-api-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-yarn-api-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-client-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-yarn-client-3.2.1.jar
23/11/30 16:41:43 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:43 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-common-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-yarn-common-3.2.1.jar
23/11/30 16:41:44 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:44 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-registry-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-yarn-registry-3.2.1.jar
23/11/30 16:41:44 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:44 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-server-common-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-yarn-server-common-3.2.1.jar
23/11/30 16:41:44 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:44 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hadoop-yarn-server-web-proxy-3.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-yarn-server-web-proxy-3.2.1.jar
23/11/30 16:41:44 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:44 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-beeline-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-beeline-2.3.7.jar
23/11/30 16:41:44 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:44 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-bigquery-connector-2.0.0-SNAPSHOT-with-dependencies.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-bigquery-connector-2.0.0-SNAPSHOT-with-dependencies.jar
23/11/30 16:41:44 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:45 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-cli-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-cli-2.3.7.jar
23/11/30 16:41:45 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:45 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-common-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-common-2.3.7.jar
23/11/30 16:41:45 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:45 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-exec-2.3.7-core.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-exec-2.3.7-core.jar
23/11/30 16:41:45 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:45 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-jdbc-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-jdbc-2.3.7.jar
23/11/30 16:41:45 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:45 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-llap-common-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-llap-common-2.3.7.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-metastore-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-metastore-2.3.7.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-serde-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-serde-2.3.7.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-service-rpc-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-service-rpc-3.1.2.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-shims-0.23-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-shims-0.23-2.3.7.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-shims-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-shims-2.3.7.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-shims-common-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-shims-common-2.3.7.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-shims-scheduler-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-shims-scheduler-2.3.7.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-storage-api-2.7.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-storage-api-2.7.2.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hive-vector-code-gen-2.3.7.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hive-vector-code-gen-2.3.7.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hk2-api-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hk2-api-2.6.1.jar
23/11/30 16:41:46 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:46 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hk2-locator-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hk2-locator-2.6.1.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/hk2-utils-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hk2-utils-2.6.1.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/htrace-core4-4.1.0-incubating.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/htrace-core4-4.1.0-incubating.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/httpclient-4.4.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/httpclient-4.4.1.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/httpcore-4.4.12.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/httpcore-4.4.12.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/istack-commons-runtime-3.0.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/istack-commons-runtime-3.0.8.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/ivy-2.4.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/ivy-2.4.0.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-annotations-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-annotations-2.10.0.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-core-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-core-2.10.0.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-core-asl-1.9.13.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-core-asl-1.9.13.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-databind-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-databind-2.10.0.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-jaxrs-base-2.9.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-jaxrs-base-2.9.8.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-jaxrs-json-provider-2.9.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-jaxrs-json-provider-2.9.8.jar
23/11/30 16:41:47 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:47 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-mapper-asl-1.9.13.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-mapper-asl-1.9.13.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-module-jaxb-annotations-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-module-jaxb-annotations-2.10.0.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-module-paranamer-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-module-paranamer-2.10.0.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jackson-module-scala_2.12-2.10.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jackson-module-scala_2.12-2.10.0.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.activation-api-1.2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jakarta.activation-api-1.2.1.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.annotation-api-1.3.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jakarta.annotation-api-1.3.5.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.inject-2.6.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jakarta.inject-2.6.1.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.servlet-api-4.0.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jakarta.servlet-api-4.0.3.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.validation-api-2.0.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jakarta.validation-api-2.0.2.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.ws.rs-api-2.1.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jakarta.ws.rs-api-2.1.6.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jakarta.xml.bind-api-2.3.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jakarta.xml.bind-api-2.3.2.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/janino-3.0.16.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/janino-3.0.16.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/javassist-3.25.0-GA.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/javassist-3.25.0-GA.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/javax.inject-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/javax.inject-1.jar
23/11/30 16:41:48 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:48 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/javax.jdo-3.2.0-m3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/javax.jdo-3.2.0-m3.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/javolution-5.5.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/javolution-5.5.1.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jaxb-api-2.2.11.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jaxb-api-2.2.11.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jaxb-runtime-2.3.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jaxb-runtime-2.3.2.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jcip-annotations-1.0-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jcip-annotations-1.0-1.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jcl-over-slf4j-1.7.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jcl-over-slf4j-1.7.30.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jdo-api-3.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jdo-api-3.0.1.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-client-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jersey-client-2.30.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-common-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jersey-common-2.30.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-container-servlet-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jersey-container-servlet-2.30.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-container-servlet-core-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jersey-container-servlet-core-2.30.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-hk2-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jersey-hk2-2.30.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-media-jaxb-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jersey-media-jaxb-2.30.jar
23/11/30 16:41:49 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:49 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jersey-server-2.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jersey-server-2.30.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jline-2.14.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jline-2.14.6.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/joda-time-2.10.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/joda-time-2.10.5.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jodd-core-3.5.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jodd-core-3.5.2.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jpam-1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jpam-1.1.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json-1.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/json-1.8.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json-smart-2.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/json-smart-2.3.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json4s-ast_2.12-3.7.0-M5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/json4s-ast_2.12-3.7.0-M5.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json4s-core_2.12-3.7.0-M5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/json4s-core_2.12-3.7.0-M5.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json4s-jackson_2.12-3.7.0-M5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/json4s-jackson_2.12-3.7.0-M5.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/json4s-scalap_2.12-3.7.0-M5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/json4s-scalap_2.12-3.7.0-M5.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jsp-api-2.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jsp-api-2.1.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jsr305-3.0.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jsr305-3.0.0.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jta-1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jta-1.1.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/jul-to-slf4j-1.7.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/jul-to-slf4j-1.7.30.jar
23/11/30 16:41:50 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:50 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-admin-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-admin-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-client-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-client-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-common-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-common-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-core-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-core-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-crypto-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-crypto-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-identity-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-identity-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-server-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-server-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-simplekdc-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-simplekdc-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerb-util-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerb-util-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-asn1-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerby-asn1-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-config-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerby-config-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-pkix-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerby-pkix-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-util-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerby-util-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kerby-xdr-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kerby-xdr-1.0.1.jar
23/11/30 16:41:51 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:51 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/kryo-shaded-4.0.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/kryo-shaded-4.0.2.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/leveldbjni-all-1.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/leveldbjni-all-1.8.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/libfb303-0.9.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/libfb303-0.9.3.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/libthrift-0.12.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/libthrift-0.12.0.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/log4j-1.2.17.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/log4j-1.2.17.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/lz4-java-1.7.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/lz4-java-1.7.1.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/machinist_2.12-0.6.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/machinist_2.12-0.6.8.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/macro-compat_2.12-1.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/macro-compat_2.12-1.1.1.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-core-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/metrics-core-4.1.1.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-graphite-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/metrics-graphite-4.1.1.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-jmx-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/metrics-jmx-4.1.1.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-json-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/metrics-json-4.1.1.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/metrics-jvm-4.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/metrics-jvm-4.1.1.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/minlog-1.3.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/minlog-1.3.0.jar
23/11/30 16:41:52 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:52 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/netty-all-4.1.51.Final.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/netty-all-4.1.51.Final.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/nimbus-jose-jwt-4.41.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/nimbus-jose-jwt-4.41.1.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/objenesis-2.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/objenesis-2.6.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/okhttp-2.7.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/okhttp-2.7.5.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/okio-1.14.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/okio-1.14.0.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/opencsv-2.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/opencsv-2.3.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/orc-core-1.5.12.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/orc-core-1.5.12.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/orc-mapreduce-1.5.12.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/orc-mapreduce-1.5.12.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/orc-shims-1.5.12.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/orc-shims-1.5.12.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/oro-2.0.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/oro-2.0.8.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/osgi-resource-locator-1.0.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/osgi-resource-locator-1.0.3.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/paranamer-2.8.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/paranamer-2.8.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-column-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/parquet-column-1.10.1.jar
23/11/30 16:41:53 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:53 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-common-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/parquet-common-1.10.1.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-encoding-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/parquet-encoding-1.10.1.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-format-2.4.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/parquet-format-2.4.0.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-hadoop-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/parquet-hadoop-1.10.1.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/parquet-jackson-1.10.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/parquet-jackson-1.10.1.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/protobuf-java-2.5.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/protobuf-java-2.5.0.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/py4j-0.10.9.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/py4j-0.10.9.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/pyrolite-4.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/pyrolite-4.30.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/re2j-1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/re2j-1.1.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-collection-compat_2.12-2.1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/scala-collection-compat_2.12-2.1.1.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-compiler-2.12.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/scala-compiler-2.12.10.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:54 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-library-2.12.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/scala-library-2.12.10.jar
23/11/30 16:41:54 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-parser-combinators_2.12-1.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/scala-parser-combinators_2.12-1.1.2.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-reflect-2.12.10.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/scala-reflect-2.12.10.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/scala-xml_2.12-1.2.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/scala-xml_2.12-1.2.0.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/shapeless_2.12-2.3.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/shapeless_2.12-2.3.3.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/shims-0.9.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/shims-0.9.0.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/slf4j-api-1.7.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/slf4j-api-1.7.30.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/slf4j-log4j12-1.7.30.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/slf4j-log4j12-1.7.30.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/snappy-java-1.1.8.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/snappy-java-1.1.8.2.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-catalyst_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-catalyst_2.12-3.1.2.jar
23/11/30 16:41:55 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:55 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-core_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-core_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-graphx_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-graphx_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-hive-thriftserver_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-hive-thriftserver_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-hive_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-hive_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-kvstore_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-kvstore_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-launcher_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-launcher_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-mllib-local_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-mllib-local_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-mllib_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-mllib_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-network-common_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-network-common_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-network-shuffle_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-network-shuffle_2.12-3.1.2.jar
23/11/30 16:41:56 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:56 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-repl_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-repl_2.12-3.1.2.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-sketch_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-sketch_2.12-3.1.2.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-sql_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-sql_2.12-3.1.2.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-streaming_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-streaming_2.12-3.1.2.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-tags_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-tags_2.12-3.1.2.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-unsafe_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-unsafe_2.12-3.1.2.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spark-yarn_2.12-3.1.2.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spark-yarn_2.12-3.1.2.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spire-macros_2.12-0.17.0-M1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spire-macros_2.12-0.17.0-M1.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spire-platform_2.12-0.17.0-M1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spire-platform_2.12-0.17.0-M1.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spire-util_2.12-0.17.0-M1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spire-util_2.12-0.17.0-M1.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/spire_2.12-0.17.0-M1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/spire_2.12-0.17.0-M1.jar
23/11/30 16:41:57 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:57 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/stax-api-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/stax-api-1.0.1.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/stax2-api-3.1.4.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/stax2-api-3.1.4.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/stream-2.9.6.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/stream-2.9.6.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/super-csv-2.2.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/super-csv-2.2.0.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/threeten-extra-1.5.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/threeten-extra-1.5.0.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/token-provider-1.0.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/token-provider-1.0.1.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/transaction-api-1.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/transaction-api-1.1.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/univocity-parsers-2.9.1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/univocity-parsers-2.9.1.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/velocity-1.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/velocity-1.5.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/woodstox-core-5.0.3.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/woodstox-core-5.0.3.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/xbean-asm7-shaded-4.15.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/xbean-asm7-shaded-4.15.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/xz-1.5.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/xz-1.5.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/zookeeper-3.4.14.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/zookeeper-3.4.14.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:58 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/zstd-jni-1.4.8-1.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/zstd-jni-1.4.8-1.jar
23/11/30 16:41:58 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-lzo-0.6.0.2.4.0.0-169.jar
23/11/30 16:41:59 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO Client: Uploading resource file:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/hadoop-4mc-1.1.0.jar
23/11/30 16:41:59 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar
23/11/30 16:41:59 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO Client: Uploading resource gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar
23/11/30 16:41:59 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO Client: Uploading resource file:/home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar
23/11/30 16:41:59 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO Client: Uploading resource file:/var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/iceberg-hive-runtime-1.2.0.jar
23/11/30 16:41:59 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO Client: Uploading resource file:/var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/iceberg-spark-runtime-3.1_2.12-1.2.0.jar
23/11/30 16:41:59 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO Client: Uploading resource file:/grid/1/spark3/tmp/spark-e9ee4777-da8d-4630-91ac-406365aca7f2/__spark_conf__6595334018844418252.zip -> hdfs://pluto/user/vanshika.yadav/.sparkStaging/application_1699449121496_0380/__spark_conf__.zip
23/11/30 16:41:59 INFO SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
23/11/30 16:41:59 INFO SecurityManager: Changing view acls to: vanshika.yadav
23/11/30 16:41:59 INFO SecurityManager: Changing modify acls to: vanshika.yadav
23/11/30 16:41:59 INFO SecurityManager: Changing view acls groups to: 
23/11/30 16:41:59 INFO SecurityManager: Changing modify acls groups to: 
23/11/30 16:41:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vanshika.yadav); groups with view permissions: Set(); users  with modify permissions: Set(vanshika.yadav); groups with modify permissions: Set()
23/11/30 16:41:59 INFO Client: Submitting application application_1699449121496_0380 to ResourceManager
23/11/30 16:42:00 INFO YarnClientImpl: Submitted application application_1699449121496_0380
23/11/30 16:42:01 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:01 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: de_adhoc
	 start time: 1701342719989
	 final status: UNDEFINED
	 tracking URL: http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0380/
	 user: vanshika.yadav
23/11/30 16:42:02 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:03 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:04 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:05 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:06 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:07 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:08 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:09 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:10 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:11 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:12 INFO Client: Application report for application_1699449121496_0380 (state: ACCEPTED)
23/11/30 16:42:12 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal, PROXY_URI_BASES -> http://fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0380,http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0380, RM_HA_URLS -> fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088), /proxy/application_1699449121496_0380
23/11/30 16:42:13 INFO Client: Application report for application_1699449121496_0380 (state: RUNNING)
23/11/30 16:42:13 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 10.116.12.113
	 ApplicationMaster RPC port: -1
	 queue: de_adhoc
	 start time: 1701342719989
	 final status: UNDEFINED
	 tracking URL: http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0380/
	 user: vanshika.yadav
23/11/30 16:42:13 INFO YarnClientSchedulerBackend: Application application_1699449121496_0380 has started running.
23/11/30 16:42:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43399.
23/11/30 16:42:13 INFO NettyBlockTransferService: Server created on fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:43399
23/11/30 16:42:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/30 16:42:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal, 43399, None)
23/11/30 16:42:13 INFO BlockManagerMasterEndpoint: Registering block manager fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:43399 with 2.5 GiB RAM, BlockManagerId(driver, fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal, 43399, None)
23/11/30 16:42:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal, 43399, None)
23/11/30 16:42:13 INFO BlockManager: external shuffle service port = 7337
23/11/30 16:42:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal, 43399, None)
23/11/30 16:42:13 INFO ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:42:13 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@759fe679{/metrics/json,null,AVAILABLE,@Spark}
23/11/30 16:42:13 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
23/11/30 16:42:13 INFO GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.
23/11/30 16:42:13 INFO SingleEventLogFileWriter: Logging events to gs://fks-fdp-infra-job-history/pluto/spark-job-history/application_1699449121496_0380.inprogress
23/11/30 16:42:13 INFO Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
23/11/30 16:42:13 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
23/11/30 16:42:13 INFO Main: Created Spark session with Hive support
Spark context Web UI available at http://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:4045
Spark context available as 'sc' (master = yarn, app id = application_1699449121496_0380).
Spark session available as 'spark'.
20231130-164024-tpcds-1gb-iceberg-load_shell_init.scala:23: warning: This catches all Throwables. If this is really intended, use `case t : Throwable` to clear this warning.
try { benchmark.TPCDSDataLoad.main(Array[String]("--format", "ICEBERG", "--scale-in-gb", "1", "--exclude-nulls", "True", "--benchmark-path", "gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking", "--source-path", "gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb")) } catch { case t => println(t); println("FAILED"); System.exit(1) } ;;
                                                                                                                                                                                                                                                                                                                                                                        ^
2023-11-30T16:42:16.062 ================================================================================
2023-11-30T16:42:16.062 ================================================================================
23/11/30 16:42:16 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 16:42:16 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
23/11/30 16:42:16 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('gs://stage-hive-metastore-pluto/apps/hive/warehouse').
23/11/30 16:42:16 INFO SharedState: Warehouse path is 'gs://stage-hive-metastore-pluto/apps/hive/warehouse'.
23/11/30 16:42:16 INFO ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:42:16 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@254bd293{/SQL,null,AVAILABLE,@Spark}
23/11/30 16:42:16 INFO ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:42:16 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6c3dae0f{/SQL/json,null,AVAILABLE,@Spark}
23/11/30 16:42:16 INFO ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:42:16 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4b8bacb0{/SQL/execution,null,AVAILABLE,@Spark}
23/11/30 16:42:16 INFO ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:42:16 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1c204621{/SQL/execution/json,null,AVAILABLE,@Spark}
23/11/30 16:42:16 INFO ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
23/11/30 16:42:16 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4dae054b{/static/sql,null,AVAILABLE,@Spark}
23/11/30 16:42:16 WARN SparkSession$Builder: Using an existing SparkSession; some spark core configurations may not take effect.
2023-11-30T16:42:16.620 Spark started with configuration:
	spark.app.id: application_1699449121496_0380
	spark.app.name: Spark shell
	spark.app.startTime: 1701342693143
	spark.benchmarkId: 20231130-164024-tpcds-1gb-iceberg-load
	spark.cleaner.ttl: 86400
	spark.delta.logStore.gs.impl: io.delta.storage.GCSLogStore
	spark.driver.appUIAddress: http://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:4045
	spark.driver.cores: 1
	spark.driver.extraClassPath: gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar
	spark.driver.extraJavaOptions: -Denv=prod -Dcom.sun.management.jmxremote.port=0 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=0 -XX:MaxDirectMemorySize=800M -XX:MaxMetaspaceSize=256M -XX:CompressedClassSpaceSize=100M -XX:+UnlockDiagnosticVMOptions -Djob.numOfRePartitions=30
	spark.driver.extraLibraryPath: /usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu
	spark.driver.host: fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal
	spark.driver.memory: 5120m
	spark.driver.port: 40915
	spark.dynamicAllocation.enabled: true
	spark.dynamicAllocation.executorIdleTimeout: 60s
	spark.dynamicAllocation.maxExecutors: 200
	spark.eventLog.dir: gs://fks-fdp-infra-job-history/pluto/spark-job-history
	spark.eventLog.enabled: true
	spark.executor.cores: 1
	spark.executor.extraClassPath: gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar
	spark.executor.extraJavaOptions: -XX:MaxDirectMemorySize=8096m -Dio.netty.maxDirectMemory=8096m -XX:+UseG1GC -XX:ConcGCThreads=2
	spark.executor.extraLibraryPath: /usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu
	spark.executor.id: driver
	spark.executor.memory: 10240m
	spark.fdp.orgqueue.cache.expire: 300
	spark.fdp.orgqueue.cache.size: 100
	spark.fdp.orgqueue.defaultQueue: adhoc
	spark.fdp.orgqueue.gringotts.clientId: QAAS
	spark.fdp.orgqueue.gringotts.clientSecret: 423de2b0-cc97-439d-a3f9-673e76d7bbea
	spark.fdp.orgqueue.gringotts.url: http://10.47.6.66/billingOrg/user
	spark.fdp.orgqueue.ironbank.url: http://10.47.4.16:/queue/
	spark.fdp.orgqueue.queueNotFound.errorMessage: Queue mapping not found
	spark.fdp.orgqueue.validInitiators: BADGER,QAAS
	spark.hadoop.fs.s3.useRequesterPaysHeader: true
	spark.hadoop.yarn.timeline-service.enabled: false
	spark.history.fs.cleaner.interval: 1d
	spark.history.fs.cleaner.maxAge: 60d
	spark.history.fs.logDirectory: gs://fks-fdp-infra-job-history/pluto/spark-job-history
	spark.history.provider: org.apache.spark.deploy.history.FsHistoryProvider
	spark.home: /var/lib/fk-pf-spark3
	spark.jars: 
	spark.master: yarn
	spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS: fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal
	spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES: http://fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0380,http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0380
	spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS: fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088
	spark.queue.enforcer.class: com.flipkart.fdp.orgqueue.OrgQueueEnforcerForInitiator
	spark.repl.class.outputDir: /grid/1/spark3/tmp/spark-e9ee4777-da8d-4630-91ac-406365aca7f2/repl-7d088c05-0c57-4fc5-8d02-18931c4f778e
	spark.repl.class.uri: spark://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:40915/classes
	spark.repl.local.jars: file:///home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar
	spark.shuffle.service.enabled: true
	spark.shuffle.useOldFetchProtocol: true
	spark.sql.catalog.hive_pluto: org.apache.iceberg.spark.SparkCatalog
	spark.sql.catalog.hive_pluto.type: hive
	spark.sql.catalog.hive_pluto.uri: thrift://10.116.17.2:9083
	spark.sql.catalogImplementation: hive
	spark.sql.extensions: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
	spark.sql.sources.partitionOverwriteMode: dynamic
	spark.sql.warehouse.dir: gs://stage-hive-metastore-pluto/apps/hive/warehouse
	spark.streaming.concurrentJobs: 4
	spark.submit.deployMode: client
	spark.submit.pyFiles: 
	spark.ui.filters: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	spark.ui.proxyBase: 
	spark.ui.showConsoleProgress: true
	spark.yarn.dist.jars: gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar,file:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar,gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,file:///home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar
	spark.yarn.driver.memoryOverhead: 4096
	spark.yarn.executor.memoryOverhead: 4096
	spark.yarn.historyServer.address: http://fks-fdp-galaxy-pluto-hs-0001-m.c.fks-fdp-galaxy.internal:18080
	spark.yarn.jars: gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/spark3/jars/*
	spark.yarn.queue: de_adhoc
	spark.yarn.report.interval: 60s
	spark.yarn.secondary.jars: hadoop-lzo-0.6.0.2.4.0.0-169.jar,hadoop-4mc-1.1.0.jar,json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar,iceberg-hive-runtime-1.2.0.jar,iceberg-spark-runtime-3.1_2.12-1.2.0.jar

2023-11-30T16:42:16.623 ================================================================================
2023-11-30T16:42:16.624 START: drop-database
2023-11-30T16:42:16.624 SQL: DROP DATABASE IF EXISTS tpcds_sf1_ICEBERG CASCADE
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.exec.orc.default.compress does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.vectorized.complex.types.enabled does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.exec.orc.compression.strategy does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.enforce.sorting does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.metastore.client.scheme.handlers does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.vectorized.execution.ptf.enabled does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.support.sql11.reserved.keywords does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.vectorized.groupby.complex.types.enabled does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.heapsize does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.enforce.bucketing does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.fileformat.managed does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.exec.orc.default.stripe.size does not exist
23/11/30 16:42:17 WARN HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
23/11/30 16:42:17 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic
2023-11-30T16:42:19.702 END took 3076 ms: drop-database
2023-11-30T16:42:19.702 ================================================================================
2023-11-30T16:42:19.702 ================================================================================
2023-11-30T16:42:19.702 START: create-database
2023-11-30T16:42:19.702 SQL: CREATE DATABASE IF NOT EXISTS tpcds_sf1_ICEBERG
2023-11-30T16:42:20.126 END took 423 ms: create-database
2023-11-30T16:42:20.126 ================================================================================
2023-11-30T16:42:20.128 Generating call_center at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/call_center
2023-11-30T16:42:20.128 ================================================================================
2023-11-30T16:42:20.128 START: drop-table-call_center
2023-11-30T16:42:20.128 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`call_center`
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.exec.orc.default.compress does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.vectorized.complex.types.enabled does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.exec.orc.compression.strategy does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.enforce.sorting does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.metastore.client.scheme.handlers does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.vectorized.execution.ptf.enabled does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.support.sql11.reserved.keywords does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.vectorized.groupby.complex.types.enabled does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.heapsize does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.enforce.bucketing does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.fileformat.managed does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.exec.orc.default.stripe.size does not exist
23/11/30 16:42:20 WARN HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
2023-11-30T16:42:20.447 END took 319 ms: drop-table-call_center
2023-11-30T16:42:20.447 ================================================================================
2023-11-30T16:42:20.447 ================================================================================
2023-11-30T16:42:20.447 START: create-table-call_center
2023-11-30T16:42:20.447 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`call_center` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/call_center/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/call_center_1gb_parquet`  
[Stage 0:>                                                          (0 + 0) / 1][Stage 0:>                                                          (0 + 1) / 1]                                                                                23/11/30 16:42:27 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[Stage 1:>                                                          (0 + 1) / 1]                                                                                2023-11-30T16:42:31.886 END took 11438 ms: create-table-call_center
2023-11-30T16:42:31.886 ================================================================================
2023-11-30T16:42:33.559 Generating catalog_page at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/catalog_page
2023-11-30T16:42:33.559 ================================================================================
2023-11-30T16:42:33.559 START: drop-table-catalog_page
2023-11-30T16:42:33.559 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`catalog_page`
2023-11-30T16:42:33.577 END took 17 ms: drop-table-catalog_page
2023-11-30T16:42:33.577 ================================================================================
2023-11-30T16:42:33.577 ================================================================================
2023-11-30T16:42:33.577 START: create-table-catalog_page
2023-11-30T16:42:33.577 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`catalog_page` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/catalog_page/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/catalog_page_1gb_parquet`  
[Stage 7:>                                                          (0 + 1) / 1]                                                                                2023-11-30T16:42:35.099 END took 1522 ms: create-table-catalog_page
2023-11-30T16:42:35.099 ================================================================================
2023-11-30T16:42:35.927 Generating catalog_returns at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/catalog_returns
2023-11-30T16:42:35.928 ================================================================================
2023-11-30T16:42:35.928 START: drop-table-catalog_returns
2023-11-30T16:42:35.928 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`catalog_returns`
2023-11-30T16:42:35.939 END took 11 ms: drop-table-catalog_returns
2023-11-30T16:42:35.939 ================================================================================
2023-11-30T16:42:35.939 ================================================================================
2023-11-30T16:42:35.939 START: create-table-catalog_returns
2023-11-30T16:42:35.939 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`catalog_returns` USING ICEBERG PARTITIONED BY (cr_returned_date_sk)  LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/catalog_returns/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/catalog_returns_1gb_parquet` WHERE cr_returned_date_sk IS NOT NULL 
[Stage 13:>                                                         (0 + 1) / 2][Stage 13:>                                                         (0 + 2) / 2][Stage 13:=============================>                            (1 + 1) / 2][Stage 13:=============================>                            (1 + 1) / 2][Stage 13:=============================>                            (1 + 1) / 2][Stage 13:=============================>                            (1 + 1) / 2]                                                                                2023-11-30T16:46:12.264 END took 216324 ms: create-table-catalog_returns
2023-11-30T16:46:12.264 ================================================================================
[Stage 17:>                                                        (0 + 1) / 65][Stage 17:>                                                        (1 + 1) / 65][Stage 17:=>                                                       (2 + 1) / 65][Stage 17:==>                                                      (3 + 2) / 65][Stage 17:===>                                                     (4 + 2) / 65][Stage 17:===>                                                     (4 + 4) / 65][Stage 17:====>                                                    (5 + 4) / 65][Stage 17:=====>                                                   (6 + 4) / 65][Stage 17:=====>                                                  (6 + 13) / 65][Stage 17:======>                                                 (7 + 20) / 65][Stage 17:======>                                                 (7 + 21) / 65][Stage 17:======>                                                 (8 + 21) / 65][Stage 17:======>                                                 (8 + 32) / 65][Stage 17:=======>                                                (9 + 32) / 65][Stage 17:=========>                                             (11 + 32) / 65][Stage 17:==========>                                            (12 + 32) / 65][Stage 17:===========>                                           (13 + 32) / 65][Stage 17:===========>                                           (13 + 35) / 65][Stage 17:===========>                                           (14 + 43) / 65][Stage 17:============>                                          (15 + 43) / 65][Stage 17:================>                                      (20 + 43) / 65][Stage 17:=====================>                                 (25 + 40) / 65][Stage 17:======================>                                (26 + 39) / 65][Stage 17:========================>                              (29 + 36) / 65][Stage 17:==============================>                        (36 + 29) / 65][Stage 17:===============================>                       (37 + 28) / 65][Stage 17:===================================>                   (42 + 23) / 65][Stage 17:=====================================>                 (44 + 21) / 65][Stage 17:========================================>              (48 + 17) / 65][Stage 17:=============================================>         (54 + 11) / 65][Stage 17:=================================================>      (57 + 8) / 65][Stage 17:=======================================================>(64 + 1) / 65][Stage 18:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:46:32.930 Generating catalog_sales at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/catalog_sales
2023-11-30T16:46:32.930 ================================================================================
2023-11-30T16:46:32.930 START: drop-table-catalog_sales
2023-11-30T16:46:32.930 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`catalog_sales`
2023-11-30T16:46:32.943 END took 12 ms: drop-table-catalog_sales
2023-11-30T16:46:32.943 ================================================================================
2023-11-30T16:46:32.943 ================================================================================
2023-11-30T16:46:32.943 START: create-table-catalog_sales
2023-11-30T16:46:32.943 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`catalog_sales` USING ICEBERG PARTITIONED BY (cs_sold_date_sk)  LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/catalog_sales/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/catalog_sales_1gb_parquet` WHERE cs_sold_date_sk IS NOT NULL 
[Stage 19:>                                                         (0 + 1) / 1]                                                                                [Stage 20:=>                                                      (1 + 28) / 29][Stage 20:==============================================>         (24 + 5) / 29]23/11/30 16:46:36 WARN TaskSetManager: Lost task 26.0 in stage 20.0 (TID 112) (pluto-mig-adhoc-c-cimage-c69c6e1d-p7lh.c.fks-fdp-galaxy.internal executor 59): java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonParser.getReadCapabilities()Lcom/fasterxml/jackson/core/util/JacksonFeatureSet;
	at com.fasterxml.jackson.databind.DeserializationContext.<init>(DeserializationContext.java:213)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.<init>(DefaultDeserializationContext.java:50)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.<init>(DefaultDeserializationContext.java:392)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.createInstance(DefaultDeserializationContext.java:414)
	at com.fasterxml.jackson.databind.ObjectReader.createDeserializationContext(ObjectReader.java:2335)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2094)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1546)
	at org.json4s.jackson.JsonMethods.parse(JsonMethods.scala:25)
	at org.json4s.jackson.JsonMethods.parse$(JsonMethods.scala:19)
	at org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:55)
	at org.apache.spark.sql.types.DataType$.fromJson(DataType.scala:169)
	at org.apache.spark.sql.types.StructType$.$anonfun$fromString$1(StructType.scala:524)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.sql.types.StructType$.fromString(StructType.scala:524)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetReadSupport.init(ParquetReadSupport.scala:82)
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:141)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:153)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$2(ParquetFileFormat.scala:329)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:116)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

[Stage 20:==================================================>     (26 + 3) / 29][Stage 20:======================================================> (28 + 1) / 29][Stage 20:======================================================> (28 + 1) / 29][Stage 20:======================================================> (28 + 1) / 29][Stage 20:======================================================> (28 + 1) / 29]                                                                                2023-11-30T16:49:48.048 END took 195105 ms: create-table-catalog_sales
2023-11-30T16:49:48.048 ================================================================================
[Stage 24:>                                                        (0 + 1) / 58][Stage 24:>                                                        (1 + 1) / 58][Stage 24:=>                                                       (2 + 1) / 58][Stage 24:=>                                                       (2 + 2) / 58][Stage 24:==>                                                      (3 + 2) / 58][Stage 24:===>                                                     (4 + 2) / 58][Stage 24:===>                                                     (4 + 3) / 58][Stage 24:====>                                                    (5 + 3) / 58][Stage 24:====>                                                    (5 + 4) / 58][Stage 24:======>                                                  (7 + 7) / 58][Stage 24:=======>                                                 (8 + 7) / 58][Stage 24:=======>                                                 (8 + 9) / 58][Stage 24:========>                                               (9 + 18) / 58][Stage 24:========>                                               (9 + 23) / 58][Stage 24:========>                                               (9 + 32) / 58][Stage 24:=========>                                             (10 + 34) / 58][Stage 24:==========>                                            (11 + 34) / 58][Stage 24:===========>                                           (12 + 34) / 58][Stage 24:===========>                                           (12 + 39) / 58][Stage 24:============>                                          (13 + 43) / 58][Stage 24:=============>                                         (14 + 43) / 58][Stage 24:=============>                                         (14 + 44) / 58][Stage 24:==============>                                        (15 + 43) / 58][Stage 24:==================>                                    (19 + 39) / 58][Stage 24:==================>                                    (20 + 38) / 58][Stage 24:===================>                                   (21 + 37) / 58][Stage 24:====================>                                  (22 + 36) / 58][Stage 24:============================>                          (30 + 28) / 58][Stage 24:=====================================>                 (40 + 18) / 58][Stage 24:===============================================>        (49 + 9) / 58][Stage 24:=================================================>      (51 + 7) / 58][Stage 24:=======================================================>(57 + 1) / 58][Stage 25:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:50:08.692 Generating customer at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/customer
2023-11-30T16:50:08.692 ================================================================================
2023-11-30T16:50:08.692 START: drop-table-customer
2023-11-30T16:50:08.692 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`customer`
2023-11-30T16:50:08.704 END took 11 ms: drop-table-customer
2023-11-30T16:50:08.704 ================================================================================
2023-11-30T16:50:08.704 ================================================================================
2023-11-30T16:50:08.704 START: create-table-customer
2023-11-30T16:50:08.704 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`customer` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/customer/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/customer_1gb_parquet`  
[Stage 27:>                                                         (0 + 2) / 2][Stage 27:=============================>                            (1 + 1) / 2]                                                                                2023-11-30T16:50:13.108 END took 4404 ms: create-table-customer
2023-11-30T16:50:13.108 ================================================================================
[Stage 31:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:50:16.938 Generating customer_address at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/customer_address
2023-11-30T16:50:16.938 ================================================================================
2023-11-30T16:50:16.938 START: drop-table-customer_address
2023-11-30T16:50:16.938 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`customer_address`
2023-11-30T16:50:16.949 END took 10 ms: drop-table-customer_address
2023-11-30T16:50:16.949 ================================================================================
2023-11-30T16:50:16.949 ================================================================================
2023-11-30T16:50:16.949 START: create-table-customer_address
2023-11-30T16:50:16.949 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`customer_address` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/customer_address/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/customer_address_1gb_parquet`  
[Stage 33:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:50:20.824 END took 3874 ms: create-table-customer_address
2023-11-30T16:50:20.824 ================================================================================
2023-11-30T16:50:22.501 Generating customer_demographics at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/customer_demographics
2023-11-30T16:50:22.502 ================================================================================
2023-11-30T16:50:22.502 START: drop-table-customer_demographics
2023-11-30T16:50:22.502 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`customer_demographics`
2023-11-30T16:50:22.512 END took 9 ms: drop-table-customer_demographics
2023-11-30T16:50:22.512 ================================================================================
2023-11-30T16:50:22.512 ================================================================================
2023-11-30T16:50:22.512 START: create-table-customer_demographics
2023-11-30T16:50:22.512 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`customer_demographics` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/customer_demographics/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/customer_demographics_1gb_parquet`  
[Stage 38:>                                                         (0 + 1) / 1]                                                                                [Stage 39:>                                                         (0 + 3) / 3][Stage 39:===================>                                      (1 + 2) / 3][Stage 39:======================================>                   (2 + 1) / 3]                                                                                2023-11-30T16:50:28.467 END took 5955 ms: create-table-customer_demographics
2023-11-30T16:50:28.467 ================================================================================
2023-11-30T16:50:30.214 Generating date_dim at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/date_dim
2023-11-30T16:50:30.214 ================================================================================
2023-11-30T16:50:30.214 START: drop-table-date_dim
2023-11-30T16:50:30.214 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`date_dim`
2023-11-30T16:50:30.224 END took 10 ms: drop-table-date_dim
2023-11-30T16:50:30.224 ================================================================================
2023-11-30T16:50:30.224 ================================================================================
2023-11-30T16:50:30.224 START: create-table-date_dim
2023-11-30T16:50:30.224 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`date_dim` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/date_dim/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/date_dim_1gb_parquet`  
[Stage 45:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:50:33.202 END took 2977 ms: create-table-date_dim
2023-11-30T16:50:33.202 ================================================================================
[Stage 48:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:50:34.942 Generating household_demographics at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/household_demographics
2023-11-30T16:50:34.942 ================================================================================
2023-11-30T16:50:34.942 START: drop-table-household_demographics
2023-11-30T16:50:34.942 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`household_demographics`
2023-11-30T16:50:34.953 END took 10 ms: drop-table-household_demographics
2023-11-30T16:50:34.953 ================================================================================
2023-11-30T16:50:34.953 ================================================================================
2023-11-30T16:50:34.953 START: create-table-household_demographics
2023-11-30T16:50:34.953 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`household_demographics` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/household_demographics/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/household_demographics_1gb_parquet`  
[Stage 51:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:50:37.295 END took 2341 ms: create-table-household_demographics
2023-11-30T16:50:37.295 ================================================================================
2023-11-30T16:50:38.498 Generating income_band at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/income_band
2023-11-30T16:50:38.498 ================================================================================
2023-11-30T16:50:38.498 START: drop-table-income_band
2023-11-30T16:50:38.498 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`income_band`
2023-11-30T16:50:38.509 END took 10 ms: drop-table-income_band
2023-11-30T16:50:38.509 ================================================================================
2023-11-30T16:50:38.509 ================================================================================
2023-11-30T16:50:38.509 START: create-table-income_band
2023-11-30T16:50:38.509 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`income_band` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/income_band/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/income_band_1gb_parquet`  
[Stage 57:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:50:40.427 END took 1918 ms: create-table-income_band
2023-11-30T16:50:40.427 ================================================================================
[Stage 59:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:50:41.945 Generating inventory at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/inventory
2023-11-30T16:50:41.945 ================================================================================
2023-11-30T16:50:41.945 START: drop-table-inventory
2023-11-30T16:50:41.945 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`inventory`
2023-11-30T16:50:41.956 END took 10 ms: drop-table-inventory
2023-11-30T16:50:41.956 ================================================================================
2023-11-30T16:50:41.956 ================================================================================
2023-11-30T16:50:41.956 START: create-table-inventory
2023-11-30T16:50:41.956 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`inventory` USING ICEBERG PARTITIONED BY (inv_date_sk)  LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/inventory/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/inventory_1gb_parquet` WHERE inv_date_sk IS NOT NULL 
[Stage 63:===================================================>      (8 + 1) / 9]                                                                                2023-11-30T16:51:19.135 END took 37178 ms: create-table-inventory
2023-11-30T16:51:19.135 ================================================================================
[Stage 64:>                                                         (0 + 1) / 1]                                                                                [Stage 65:===================================================>      (8 + 1) / 9]                                                                                [Stage 67:======>                                                   (1 + 8) / 9][Stage 67:======================================>                   (6 + 3) / 9][Stage 67:=============================================>            (7 + 2) / 9][Stage 67:===================================================>      (8 + 1) / 9]                                                                                2023-11-30T16:51:24.046 Generating item at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/item
2023-11-30T16:51:24.046 ================================================================================
2023-11-30T16:51:24.046 START: drop-table-item
2023-11-30T16:51:24.046 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`item`
2023-11-30T16:51:24.055 END took 9 ms: drop-table-item
2023-11-30T16:51:24.056 ================================================================================
2023-11-30T16:51:24.056 ================================================================================
2023-11-30T16:51:24.056 START: create-table-item
2023-11-30T16:51:24.056 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`item` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/item/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/item_1gb_parquet`  
[Stage 70:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:51:26.076 END took 2020 ms: create-table-item
2023-11-30T16:51:26.076 ================================================================================
2023-11-30T16:51:26.927 Generating promotion at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/promotion
2023-11-30T16:51:26.927 ================================================================================
2023-11-30T16:51:26.927 START: drop-table-promotion
2023-11-30T16:51:26.927 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`promotion`
2023-11-30T16:51:26.936 END took 8 ms: drop-table-promotion
2023-11-30T16:51:26.936 ================================================================================
2023-11-30T16:51:26.936 ================================================================================
2023-11-30T16:51:26.936 START: create-table-promotion
2023-11-30T16:51:26.936 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`promotion` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/promotion/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/promotion_1gb_parquet`  
2023-11-30T16:51:28.209 END took 1272 ms: create-table-promotion
2023-11-30T16:51:28.209 ================================================================================
2023-11-30T16:51:29.336 Generating reason at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/reason
2023-11-30T16:51:29.336 ================================================================================
2023-11-30T16:51:29.336 START: drop-table-reason
2023-11-30T16:51:29.336 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`reason`
2023-11-30T16:51:29.345 END took 8 ms: drop-table-reason
2023-11-30T16:51:29.345 ================================================================================
2023-11-30T16:51:29.345 ================================================================================
2023-11-30T16:51:29.345 START: create-table-reason
2023-11-30T16:51:29.345 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`reason` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/reason/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/reason_1gb_parquet`  
[Stage 82:>                                                         (0 + 1) / 1]                                                                                2023-11-30T16:51:31.340 END took 1994 ms: create-table-reason
2023-11-30T16:51:31.340 ================================================================================
2023-11-30T16:51:32.217 Generating ship_mode at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/ship_mode
2023-11-30T16:51:32.217 ================================================================================
2023-11-30T16:51:32.217 START: drop-table-ship_mode
2023-11-30T16:51:32.217 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`ship_mode`
2023-11-30T16:51:32.227 END took 9 ms: drop-table-ship_mode
2023-11-30T16:51:32.227 ================================================================================
2023-11-30T16:51:32.227 ================================================================================
2023-11-30T16:51:32.227 START: create-table-ship_mode
2023-11-30T16:51:32.227 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`ship_mode` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/ship_mode/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/ship_mode_1gb_parquet`  
2023-11-30T16:51:33.358 END took 1131 ms: create-table-ship_mode
2023-11-30T16:51:33.358 ================================================================================
2023-11-30T16:51:34.065 Generating store at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/store
2023-11-30T16:51:34.065 ================================================================================
2023-11-30T16:51:34.065 START: drop-table-store
2023-11-30T16:51:34.065 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`store`
2023-11-30T16:51:34.121 END took 55 ms: drop-table-store
2023-11-30T16:51:34.121 ================================================================================
2023-11-30T16:51:34.121 ================================================================================
2023-11-30T16:51:34.121 START: create-table-store
2023-11-30T16:51:34.121 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`store` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/store/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/store_1gb_parquet`  
[Stage 94:>                                                         (0 + 1) / 1]23/11/30 16:51:35 WARN ThrowableSerializationWrapper: Task exception could not be deserialized
java.io.InvalidClassException: com.fasterxml.jackson.databind.JsonMappingException; local class incompatible: stream classdesc serialVersionUID = 3, local class serialVersionUID = 1
	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:687)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1883)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1749)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2040)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2285)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2209)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)
	at org.apache.spark.ThrowableSerializationWrapper.readObject(TaskEndReason.scala:202)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2176)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2285)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2209)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2285)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2209)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:115)
	at org.apache.spark.scheduler.TaskResultGetter.$anonfun$enqueueFailedTask$2(TaskResultGetter.scala:141)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996)
	at org.apache.spark.scheduler.TaskResultGetter.$anonfun$enqueueFailedTask$1(TaskResultGetter.scala:137)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
23/11/30 16:51:35 WARN TaskSetManager: Lost task 0.0 in stage 94.0 (TID 277) (pluto-mig-adhoc-c-cimage-c69c6e1d-qc5d.c.fks-fdp-galaxy.internal executor 113): UnknownReason
                                                                                2023-11-30T16:51:36.231 END took 2109 ms: create-table-store
2023-11-30T16:51:36.231 ================================================================================
2023-11-30T16:51:37.128 Generating store_returns at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/store_returns
2023-11-30T16:51:37.128 ================================================================================
2023-11-30T16:51:37.128 START: drop-table-store_returns
2023-11-30T16:51:37.128 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`store_returns`
2023-11-30T16:51:37.137 END took 9 ms: drop-table-store_returns
2023-11-30T16:51:37.137 ================================================================================
2023-11-30T16:51:37.137 ================================================================================
2023-11-30T16:51:37.137 START: create-table-store_returns
2023-11-30T16:51:37.137 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`store_returns` USING ICEBERG PARTITIONED BY (sr_returned_date_sk)  LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/store_returns/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/store_returns_1gb_parquet` WHERE sr_returned_date_sk IS NOT NULL 
[Stage 100:=============================================>           (4 + 1) / 5][Stage 100:=============================================>           (4 + 1) / 5][Stage 100:=============================================>           (4 + 1) / 5][Stage 100:=============================================>           (4 + 1) / 5]                                                                                2023-11-30T16:55:01.903 END took 204766 ms: create-table-store_returns
2023-11-30T16:55:01.903 ================================================================================
[Stage 104:>                                                       (0 + 1) / 63][Stage 104:>                                                       (1 + 1) / 63][Stage 104:=>                                                      (2 + 1) / 63][Stage 104:==>                                                     (3 + 1) / 63][Stage 104:==>                                                     (3 + 2) / 63][Stage 104:===>                                                    (4 + 2) / 63][Stage 104:====>                                                   (5 + 5) / 63][Stage 104:====>                                                   (5 + 6) / 63][Stage 104:=====>                                                  (6 + 6) / 63][Stage 104:======>                                                 (7 + 6) / 63][Stage 104:======>                                                 (7 + 7) / 63][Stage 104:======>                                                (7 + 12) / 63][Stage 104:======>                                                (8 + 12) / 63][Stage 104:======>                                                (8 + 22) / 63][Stage 104:=======>                                               (9 + 22) / 63][Stage 104:========>                                             (10 + 25) / 63][Stage 104:========>                                             (10 + 30) / 63][Stage 104:==========>                                           (12 + 34) / 63][Stage 104:============>                                         (14 + 34) / 63][Stage 104:============>                                         (15 + 34) / 63][Stage 104:=============>                                        (16 + 34) / 63][Stage 104:==============>                                       (17 + 34) / 63][Stage 104:=================>                                    (20 + 34) / 63][Stage 104:==================>                                   (21 + 34) / 63][Stage 104:========================>                             (28 + 34) / 63][Stage 104:========================>                             (28 + 35) / 63][Stage 104:========================>                             (29 + 34) / 63][Stage 104:=========================>                            (30 + 33) / 63][Stage 104:=============================>                        (34 + 29) / 63][Stage 104:========================================>             (47 + 16) / 63][Stage 104:===========================================>          (51 + 12) / 63][Stage 104:=============================================>        (53 + 10) / 63][Stage 104:===============================================>       (54 + 9) / 63][Stage 104:==================================================>    (58 + 5) / 63][Stage 104:=====================================================> (61 + 2) / 63][Stage 104:======================================================>(62 + 1) / 63][Stage 105:>                                                        (0 + 1) / 1]                                                                                2023-11-30T16:55:21.706 Generating store_sales at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/store_sales
2023-11-30T16:55:21.706 ================================================================================
2023-11-30T16:55:21.706 START: drop-table-store_sales
2023-11-30T16:55:21.706 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`store_sales`
2023-11-30T16:55:21.715 END took 9 ms: drop-table-store_sales
2023-11-30T16:55:21.716 ================================================================================
2023-11-30T16:55:21.716 ================================================================================
2023-11-30T16:55:21.716 START: create-table-store_sales
2023-11-30T16:55:21.716 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`store_sales` USING ICEBERG PARTITIONED BY (ss_sold_date_sk)  LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/store_sales/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/store_sales_1gb_parquet` WHERE ss_sold_date_sk IS NOT NULL 
[Stage 107:=>                                                     (1 + 39) / 40][Stage 107:============>                                          (9 + 31) / 40]23/11/30 16:55:23 WARN TaskSetManager: Lost task 6.0 in stage 107.0 (TID 364) (pluto-mig-adhoc-c-cimage-c69c6e1d-wkxs.c.fks-fdp-galaxy.internal executor 165): java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonParser.getReadCapabilities()Lcom/fasterxml/jackson/core/util/JacksonFeatureSet;
	at com.fasterxml.jackson.databind.DeserializationContext.<init>(DeserializationContext.java:213)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.<init>(DefaultDeserializationContext.java:50)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.<init>(DefaultDeserializationContext.java:392)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.createInstance(DefaultDeserializationContext.java:414)
	at com.fasterxml.jackson.databind.ObjectReader.createDeserializationContext(ObjectReader.java:2335)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2094)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1546)
	at org.json4s.jackson.JsonMethods.parse(JsonMethods.scala:25)
	at org.json4s.jackson.JsonMethods.parse$(JsonMethods.scala:19)
	at org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:55)
	at org.apache.spark.sql.types.DataType$.fromJson(DataType.scala:169)
	at org.apache.spark.sql.types.StructType$.$anonfun$fromString$1(StructType.scala:524)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.sql.types.StructType$.fromString(StructType.scala:524)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetReadSupport.init(ParquetReadSupport.scala:82)
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:141)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:153)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$2(ParquetFileFormat.scala:329)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:116)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

[Stage 107:=============================>                        (22 + 18) / 40][Stage 107:===============================>                      (23 + 17) / 40][Stage 107:================================>                     (24 + 16) / 40][Stage 107:========================================>             (30 + 10) / 40][Stage 107:==============================================>        (34 + 6) / 40][Stage 107:====================================================>  (38 + 2) / 40][Stage 107:====================================================>  (38 + 2) / 40][Stage 107:====================================================>  (38 + 2) / 40][Stage 107:=====================================================> (39 + 1) / 40]                                                                                2023-11-30T16:58:27.629 END took 185913 ms: create-table-store_sales
2023-11-30T16:58:27.629 ================================================================================
[Stage 111:>                                                      (0 + 2) / 114][Stage 111:>                                                      (2 + 2) / 114][Stage 111:=>                                                     (3 + 2) / 114][Stage 111:=>                                                     (4 + 2) / 114][Stage 111:==>                                                    (5 + 3) / 114][Stage 111:==>                                                    (6 + 3) / 114][Stage 111:===>                                                   (7 + 3) / 114][Stage 111:===>                                                   (8 + 3) / 114][Stage 111:===>                                                   (8 + 4) / 114][Stage 111:====>                                                  (9 + 5) / 114][Stage 111:====>                                                  (9 + 7) / 114][Stage 111:====>                                                 (10 + 8) / 114][Stage 111:=====>                                               (11 + 10) / 114][Stage 111:=====>                                               (12 + 10) / 114][Stage 111:======>                                              (13 + 10) / 114][Stage 111:======>                                              (14 + 11) / 114][Stage 111:======>                                              (14 + 21) / 114][Stage 111:======>                                              (14 + 26) / 114][Stage 111:=======>                                             (16 + 26) / 114][Stage 111:=======>                                             (16 + 29) / 114][Stage 111:=======>                                             (16 + 43) / 114][Stage 111:=======>                                             (17 + 60) / 114][Stage 111:========>                                            (18 + 66) / 114][Stage 111:========>                                            (19 + 66) / 114][Stage 111:========>                                            (19 + 69) / 114][Stage 111:==========>                                          (22 + 75) / 114][Stage 111:==========>                                          (22 + 81) / 114][Stage 111:==========>                                          (23 + 81) / 114][Stage 111:===========>                                         (24 + 81) / 114][Stage 111:============>                                        (26 + 81) / 114][Stage 111:=============>                                       (28 + 81) / 114][Stage 111:=============>                                       (29 + 81) / 114][Stage 111:===============>                                     (33 + 81) / 114][Stage 111:================>                                    (35 + 79) / 114][Stage 111:================>                                    (36 + 78) / 114][Stage 111:==================>                                  (39 + 75) / 114][Stage 111:======================>                              (48 + 66) / 114][Stage 111:=======================>                             (51 + 63) / 114][Stage 111:=========================>                           (54 + 60) / 114][Stage 111:=============================>                       (63 + 51) / 114][Stage 111:==================================>                  (75 + 39) / 114][Stage 111:==========================================>          (91 + 23) / 114][Stage 111:=============================================>      (100 + 14) / 114][Stage 111:==============================================>     (103 + 11) / 114][Stage 111:==================================================>  (109 + 5) / 114]                                                                                2023-11-30T16:58:45.881 Generating time_dim at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/time_dim
2023-11-30T16:58:45.882 ================================================================================
2023-11-30T16:58:45.882 START: drop-table-time_dim
2023-11-30T16:58:45.882 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`time_dim`
2023-11-30T16:58:45.891 END took 9 ms: drop-table-time_dim
2023-11-30T16:58:45.891 ================================================================================
2023-11-30T16:58:45.891 ================================================================================
2023-11-30T16:58:45.891 START: create-table-time_dim
2023-11-30T16:58:45.891 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`time_dim` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/time_dim/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/time_dim_1gb_parquet`  
[Stage 114:>                                                        (0 + 1) / 1]                                                                                2023-11-30T16:58:51.073 END took 5182 ms: create-table-time_dim
2023-11-30T16:58:51.073 ================================================================================
[Stage 115:>                                                        (0 + 1) / 1]                                                                                2023-11-30T16:58:53.953 Generating warehouse at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/warehouse
2023-11-30T16:58:53.953 ================================================================================
2023-11-30T16:58:53.953 START: drop-table-warehouse
2023-11-30T16:58:53.953 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`warehouse`
2023-11-30T16:58:53.962 END took 9 ms: drop-table-warehouse
2023-11-30T16:58:53.962 ================================================================================
2023-11-30T16:58:53.962 ================================================================================
2023-11-30T16:58:53.962 START: create-table-warehouse
2023-11-30T16:58:53.962 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`warehouse` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/warehouse/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/warehouse_1gb_parquet`  
[Stage 120:>                                                        (0 + 1) / 1]23/11/30 16:58:55 WARN TaskSetManager: Lost task 0.0 in stage 120.0 (TID 527) (pluto-mig-adhoc-c-cimage-c69c6e1d-p7lh.c.fks-fdp-galaxy.internal executor 202): java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonParser.getReadCapabilities()Lcom/fasterxml/jackson/core/util/JacksonFeatureSet;
	at com.fasterxml.jackson.databind.DeserializationContext.<init>(DeserializationContext.java:213)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.<init>(DefaultDeserializationContext.java:50)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.<init>(DefaultDeserializationContext.java:392)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.createInstance(DefaultDeserializationContext.java:414)
	at com.fasterxml.jackson.databind.ObjectReader.createDeserializationContext(ObjectReader.java:2335)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2094)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1546)
	at org.json4s.jackson.JsonMethods.parse(JsonMethods.scala:25)
	at org.json4s.jackson.JsonMethods.parse$(JsonMethods.scala:19)
	at org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:55)
	at org.apache.spark.sql.types.DataType$.fromJson(DataType.scala:169)
	at org.apache.spark.sql.types.StructType$.$anonfun$fromString$1(StructType.scala:524)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.sql.types.StructType$.fromString(StructType.scala:524)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetReadSupport.init(ParquetReadSupport.scala:82)
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:141)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:153)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$2(ParquetFileFormat.scala:329)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:116)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

                                                                                2023-11-30T16:58:57.121 END took 3158 ms: create-table-warehouse
2023-11-30T16:58:57.121 ================================================================================
[Stage 124:>                                                        (0 + 1) / 1]                                                                                2023-11-30T16:59:00.748 Generating web_page at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/web_page
2023-11-30T16:59:00.748 ================================================================================
2023-11-30T16:59:00.748 START: drop-table-web_page
2023-11-30T16:59:00.748 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`web_page`
2023-11-30T16:59:00.757 END took 8 ms: drop-table-web_page
2023-11-30T16:59:00.758 ================================================================================
2023-11-30T16:59:00.758 ================================================================================
2023-11-30T16:59:00.758 START: create-table-web_page
2023-11-30T16:59:00.758 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`web_page` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/web_page/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/web_page_1gb_parquet`  
[Stage 126:>                                                        (0 + 1) / 1]                                                                                2023-11-30T16:59:03.075 END took 2317 ms: create-table-web_page
2023-11-30T16:59:03.075 ================================================================================
2023-11-30T16:59:04.437 Generating web_returns at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/web_returns
2023-11-30T16:59:04.437 ================================================================================
2023-11-30T16:59:04.437 START: drop-table-web_returns
2023-11-30T16:59:04.437 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`web_returns`
2023-11-30T16:59:04.446 END took 8 ms: drop-table-web_returns
2023-11-30T16:59:04.446 ================================================================================
2023-11-30T16:59:04.446 ================================================================================
2023-11-30T16:59:04.446 START: create-table-web_returns
2023-11-30T16:59:04.446 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`web_returns` USING ICEBERG PARTITIONED BY (wr_returned_date_sk)  LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/web_returns/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/web_returns_1gb_parquet` WHERE wr_returned_date_sk IS NOT NULL 
[Stage 132:============================>                            (1 + 1) / 2][Stage 132:============================>                            (1 + 1) / 2][Stage 132:============================>                            (1 + 1) / 2][Stage 132:============================>                            (1 + 1) / 2]                                                                                2023-11-30T17:02:43.011 END took 218564 ms: create-table-web_returns
2023-11-30T17:02:43.011 ================================================================================
[Stage 136:>                                                       (0 + 1) / 67][Stage 136:>                                                       (1 + 1) / 67][Stage 136:=>                                                      (2 + 1) / 67][Stage 136:=>                                                      (2 + 2) / 67][Stage 136:==>                                                     (3 + 2) / 67][Stage 136:==>                                                     (3 + 3) / 67][Stage 136:===>                                                    (4 + 3) / 67][Stage 136:===>                                                    (4 + 5) / 67][Stage 136:====>                                                   (5 + 8) / 67][Stage 136:====>                                                   (5 + 9) / 67][Stage 136:=====>                                                  (6 + 9) / 67][Stage 136:=====>                                                  (7 + 9) / 67][Stage 136:=====>                                                 (7 + 10) / 67][Stage 136:=====>                                                 (7 + 16) / 67][Stage 136:=====>                                                 (7 + 17) / 67][Stage 136:=====>                                                 (7 + 20) / 67][Stage 136:======>                                                (8 + 24) / 67][Stage 136:=======>                                               (9 + 31) / 67][Stage 136:========>                                             (10 + 33) / 67][Stage 136:========>                                             (10 + 34) / 67][Stage 136:=========>                                            (12 + 39) / 67][Stage 136:==========>                                           (13 + 49) / 67][Stage 136:==========>                                           (13 + 51) / 67][Stage 136:============>                                         (15 + 51) / 67][Stage 136:=============>                                        (17 + 50) / 67][Stage 136:=================>                                    (22 + 45) / 67][Stage 136:==================>                                   (23 + 44) / 67][Stage 136:====================>                                 (25 + 42) / 67][Stage 136:=====================>                                (27 + 40) / 67][Stage 136:==========================>                           (33 + 34) / 67][Stage 136:===========================>                          (34 + 33) / 67][Stage 136:=============================>                        (36 + 31) / 67][Stage 136:====================================>                 (45 + 22) / 67][Stage 136:======================================>               (48 + 19) / 67][Stage 136:=======================================>              (49 + 18) / 67][Stage 136:===========================================>          (54 + 13) / 67][Stage 136:======================================================>(66 + 1) / 67]                                                                                2023-11-30T17:03:00.151 Generating web_sales at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/web_sales
2023-11-30T17:03:00.151 ================================================================================
2023-11-30T17:03:00.151 START: drop-table-web_sales
2023-11-30T17:03:00.151 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`web_sales`
2023-11-30T17:03:00.160 END took 9 ms: drop-table-web_sales
2023-11-30T17:03:00.160 ================================================================================
2023-11-30T17:03:00.160 ================================================================================
2023-11-30T17:03:00.161 START: create-table-web_sales
2023-11-30T17:03:00.161 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`web_sales` USING ICEBERG PARTITIONED BY (ws_sold_date_sk)  LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/web_sales/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/web_sales_1gb_parquet` WHERE ws_sold_date_sk IS NOT NULL 
[Stage 139:>                                                      (0 + 13) / 13]23/11/30 17:03:01 WARN TaskSetManager: Lost task 0.0 in stage 139.0 (TID 615) (pluto-mig-adhoc-c-cimage-c69c6e1d-p7lh.c.fks-fdp-galaxy.internal executor 326): java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonParser.getReadCapabilities()Lcom/fasterxml/jackson/core/util/JacksonFeatureSet;
	at com.fasterxml.jackson.databind.DeserializationContext.<init>(DeserializationContext.java:213)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.<init>(DefaultDeserializationContext.java:50)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.<init>(DefaultDeserializationContext.java:392)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.createInstance(DefaultDeserializationContext.java:414)
	at com.fasterxml.jackson.databind.ObjectReader.createDeserializationContext(ObjectReader.java:2335)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2094)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1546)
	at org.json4s.jackson.JsonMethods.parse(JsonMethods.scala:25)
	at org.json4s.jackson.JsonMethods.parse$(JsonMethods.scala:19)
	at org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:55)
	at org.apache.spark.sql.types.DataType$.fromJson(DataType.scala:169)
	at org.apache.spark.sql.types.StructType$.$anonfun$fromString$1(StructType.scala:524)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.sql.types.StructType$.fromString(StructType.scala:524)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetReadSupport.init(ParquetReadSupport.scala:82)
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:141)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:153)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$2(ParquetFileFormat.scala:329)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:116)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$1(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:452)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:360)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

[Stage 139:==============================>                         (7 + 6) / 13][Stage 139:==================================>                     (8 + 5) / 13][Stage 139:======================================>                 (9 + 4) / 13][Stage 139:==========================================>            (10 + 3) / 13][Stage 139:==============================================>        (11 + 2) / 13][Stage 139:==================================================>    (12 + 1) / 13][Stage 139:==================================================>    (12 + 1) / 13][Stage 139:==================================================>    (12 + 1) / 13]                                                                                2023-11-30T17:06:05.210 END took 185049 ms: create-table-web_sales
2023-11-30T17:06:05.210 ================================================================================
[Stage 143:>                                                       (0 + 1) / 57][Stage 143:>                                                       (1 + 1) / 57][Stage 143:=>                                                      (2 + 1) / 57][Stage 143:==>                                                     (3 + 1) / 57][Stage 143:==>                                                     (3 + 2) / 57][Stage 143:==>                                                     (3 + 3) / 57][Stage 143:===>                                                    (4 + 3) / 57][Stage 143:===>                                                    (4 + 5) / 57][Stage 143:====>                                                   (5 + 5) / 57][Stage 143:====>                                                   (5 + 6) / 57][Stage 143:====>                                                   (5 + 9) / 57][Stage 143:=====>                                                  (6 + 9) / 57][Stage 143:======>                                                 (7 + 9) / 57][Stage 143:=======>                                                (8 + 9) / 57][Stage 143:========>                                               (9 + 9) / 57][Stage 143:========>                                              (9 + 15) / 57][Stage 143:=========>                                            (10 + 17) / 57][Stage 143:=========>                                            (10 + 20) / 57][Stage 143:=========>                                            (10 + 24) / 57][Stage 143:=========>                                            (10 + 32) / 57][Stage 143:===========>                                          (12 + 33) / 57][Stage 143:=============>                                        (14 + 36) / 57][Stage 143:==============>                                       (15 + 42) / 57][Stage 143:===============>                                      (16 + 41) / 57][Stage 143:==================>                                   (20 + 37) / 57][Stage 143:=====================>                                (23 + 34) / 57][Stage 143:======================>                               (24 + 33) / 57][Stage 143:==============================>                       (32 + 25) / 57][Stage 143:================================>                     (34 + 23) / 57][Stage 143:====================================>                 (38 + 19) / 57][Stage 143:======================================>               (41 + 16) / 57][Stage 143:========================================>             (43 + 14) / 57][Stage 143:================================================>      (50 + 7) / 57][Stage 144:>                                                        (0 + 1) / 1]                                                                                2023-11-30T17:06:22.345 Generating web_site at gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/web_site
2023-11-30T17:06:22.345 ================================================================================
2023-11-30T17:06:22.345 START: drop-table-web_site
2023-11-30T17:06:22.345 SQL: DROP TABLE IF EXISTS `hive_pluto`.`tpcds_sf1_ICEBERG`.`web_site`
2023-11-30T17:06:22.356 END took 10 ms: drop-table-web_site
2023-11-30T17:06:22.356 ================================================================================
2023-11-30T17:06:22.356 ================================================================================
2023-11-30T17:06:22.356 START: create-table-web_site
2023-11-30T17:06:22.356 SQL: CREATE TABLE `hive_pluto`.`tpcds_sf1_ICEBERG`.`web_site` USING ICEBERG LOCATION 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load/web_site/' TBLPROPERTIES ('write.spark.fanout.enabled'='true', 'format-version'=2) AS SELECT * FROM `parquet`.`gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb/web_site_1gb_parquet`  
[Stage 146:>                                                        (0 + 1) / 1]                                                                                2023-11-30T17:06:24.912 END took 2556 ms: create-table-web_site
2023-11-30T17:06:24.912 ================================================================================
23/11/30 17:06:25 WARN TaskSetManager: Lost task 0.0 in stage 148.0 (TID 696) (pluto-mig-adhoc-c-cimage-c69c6e1d-z9lx.c.fks-fdp-galaxy.internal executor 355): java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonParser.getReadCapabilities()Lcom/fasterxml/jackson/core/util/JacksonFeatureSet;
	at com.fasterxml.jackson.databind.DeserializationContext.<init>(DeserializationContext.java:213)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.<init>(DefaultDeserializationContext.java:50)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.<init>(DefaultDeserializationContext.java:392)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext$Impl.createInstance(DefaultDeserializationContext.java:414)
	at com.fasterxml.jackson.databind.ObjectReader.createDeserializationContext(ObjectReader.java:2335)
	at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2094)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1546)
	at org.json4s.jackson.JsonMethods.parse(JsonMethods.scala:25)
	at org.json4s.jackson.JsonMethods.parse$(JsonMethods.scala:19)
	at org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:55)
	at org.apache.spark.sql.types.DataType$.fromJson(DataType.scala:169)
	at org.apache.spark.sql.types.StructType$.$anonfun$fromString$1(StructType.scala:524)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.sql.types.StructType$.fromString(StructType.scala:524)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetReadSupport.init(ParquetReadSupport.scala:82)
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:141)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:153)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$2(ParquetFileFormat.scala:329)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:116)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

[Stage 148:>                                                        (0 + 1) / 1]                                                                                [Stage 150:>                                                        (0 + 1) / 1]                                                                                2023-11-30T17:06:28.774 ====== Created all tables in database tpcds_sf1_ICEBERG at 'gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/databases/tpcds_sf1_ICEBERG_20231130_164024_tpcds_1gb_iceberg_load' =======
2023-11-30T17:06:28.775 ================================================================================
2023-11-30T17:06:28.775 START: USE hive_pluto.tpcds_sf1_ICEBERG;
2023-11-30T17:06:28.775 SQL: USE hive_pluto.tpcds_sf1_ICEBERG;
2023-11-30T17:06:28.890 END took 115 ms: USE hive_pluto.tpcds_sf1_ICEBERG;
2023-11-30T17:06:28.890 ================================================================================
2023-11-30T17:06:28.890 ================================================================================
2023-11-30T17:06:28.890 START: SHOW TABLES
2023-11-30T17:06:28.890 SQL: SHOW TABLES
23/11/30 17:06:28 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
23/11/30 17:06:28 WARN SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
+-----------------+----------------------+
|namespace        |tableName             |
+-----------------+----------------------+
|tpcds_sf1_ICEBERG|call_center           |
|tpcds_sf1_ICEBERG|catalog_page          |
|tpcds_sf1_ICEBERG|catalog_returns       |
|tpcds_sf1_ICEBERG|catalog_sales         |
|tpcds_sf1_ICEBERG|customer              |
|tpcds_sf1_ICEBERG|customer_address      |
|tpcds_sf1_ICEBERG|customer_demographics |
|tpcds_sf1_ICEBERG|date_dim              |
|tpcds_sf1_ICEBERG|household_demographics|
|tpcds_sf1_ICEBERG|income_band           |
|tpcds_sf1_ICEBERG|inventory             |
|tpcds_sf1_ICEBERG|item                  |
|tpcds_sf1_ICEBERG|promotion             |
|tpcds_sf1_ICEBERG|reason                |
|tpcds_sf1_ICEBERG|ship_mode             |
|tpcds_sf1_ICEBERG|store                 |
|tpcds_sf1_ICEBERG|store_returns         |
|tpcds_sf1_ICEBERG|store_sales           |
|tpcds_sf1_ICEBERG|time_dim              |
|tpcds_sf1_ICEBERG|warehouse             |
+-----------------+----------------------+
only showing top 20 rows

2023-11-30T17:06:29.281 END took 337 ms: SHOW TABLES
2023-11-30T17:06:29.281 ================================================================================
2023-11-30T17:06:29.283 ================================================================================
RESULT:
{
  "benchmarkSpecs" : {
    "benchmarkId" : "20231130-164024-tpcds-1gb-iceberg-load",
    "benchmarkPath" : "gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking",
    "excludeNulls" : "true",
    "format" : "ICEBERG",
    "scaleInGB" : "1",
    "sourcePath" : "gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/1gb"
  },
  "extraMetrics" : { },
  "queryResults" : [ {
    "durationMs" : 3076,
    "name" : "drop-database"
  }, {
    "durationMs" : 423,
    "name" : "create-database"
  }, {
    "durationMs" : 319,
    "name" : "drop-table-call_center"
  }, {
    "durationMs" : 11438,
    "name" : "create-table-call_center"
  }, {
    "durationMs" : 17,
    "name" : "drop-table-catalog_page"
  }, {
    "durationMs" : 1522,
    "name" : "create-table-catalog_page"
  }, {
    "durationMs" : 11,
    "name" : "drop-table-catalog_returns"
  }, {
    "durationMs" : 216324,
    "name" : "create-table-catalog_returns"
  }, {
    "durationMs" : 12,
    "name" : "drop-table-catalog_sales"
  }, {
    "durationMs" : 195105,
    "name" : "create-table-catalog_sales"
  }, {
    "durationMs" : 11,
    "name" : "drop-table-customer"
  }, {
    "durationMs" : 4404,
    "name" : "create-table-customer"
  }, {
    "durationMs" : 10,
    "name" : "drop-table-customer_address"
  }, {
    "durationMs" : 3874,
    "name" : "create-table-customer_address"
  }, {
    "durationMs" : 9,
    "name" : "drop-table-customer_demographics"
  }, {
    "durationMs" : 5955,
    "name" : "create-table-customer_demographics"
  }, {
    "durationMs" : 10,
    "name" : "drop-table-date_dim"
  }, {
    "durationMs" : 2977,
    "name" : "create-table-date_dim"
  }, {
    "durationMs" : 10,
    "name" : "drop-table-household_demographics"
  }, {
    "durationMs" : 2341,
    "name" : "create-table-household_demographics"
  }, {
    "durationMs" : 10,
    "name" : "drop-table-income_band"
  }, {
    "durationMs" : 1918,
    "name" : "create-table-income_band"
  }, {
    "durationMs" : 10,
    "name" : "drop-table-inventory"
  }, {
    "durationMs" : 37178,
    "name" : "create-table-inventory"
  }, {
    "durationMs" : 9,
    "name" : "drop-table-item"
  }, {
    "durationMs" : 2020,
    "name" : "create-table-item"
  }, {
    "durationMs" : 8,
    "name" : "drop-table-promotion"
  }, {
    "durationMs" : 1272,
    "name" : "create-table-promotion"
  }, {
    "durationMs" : 8,
    "name" : "drop-table-reason"
  }, {
    "durationMs" : 1994,
    "name" : "create-table-reason"
  }, {
    "durationMs" : 9,
    "name" : "drop-table-ship_mode"
  }, {
    "durationMs" : 1131,
    "name" : "create-table-ship_mode"
  }, {
    "durationMs" : 55,
    "name" : "drop-table-store"
  }, {
    "durationMs" : 2109,
    "name" : "create-table-store"
  }, {
    "durationMs" : 9,
    "name" : "drop-table-store_returns"
  }, {
    "durationMs" : 204766,
    "name" : "create-table-store_returns"
  }, {
    "durationMs" : 9,
    "name" : "drop-table-store_sales"
  }, {
    "durationMs" : 185913,
    "name" : "create-table-store_sales"
  }, {
    "durationMs" : 9,
    "name" : "drop-table-time_dim"
  }, {
    "durationMs" : 5182,
    "name" : "create-table-time_dim"
  }, {
    "durationMs" : 9,
    "name" : "drop-table-warehouse"
  }, {
    "durationMs" : 3158,
    "name" : "create-table-warehouse"
  }, {
    "durationMs" : 8,
    "name" : "drop-table-web_page"
  }, {
    "durationMs" : 2317,
    "name" : "create-table-web_page"
  }, {
    "durationMs" : 8,
    "name" : "drop-table-web_returns"
  }, {
    "durationMs" : 218564,
    "name" : "create-table-web_returns"
  }, {
    "durationMs" : 9,
    "name" : "drop-table-web_sales"
  }, {
    "durationMs" : 185049,
    "name" : "create-table-web_sales"
  }, {
    "durationMs" : 10,
    "name" : "drop-table-web_site"
  }, {
    "durationMs" : 2556,
    "name" : "create-table-web_site"
  }, {
    "durationMs" : 115,
    "name" : ""
  }, {
    "durationMs" : 337,
    "name" : ""
  } ],
  "sparkEnvInfo" : {
    "classpathEntries" : {
      "//fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar" : "System Classpath",
      "/etc/hadoop/conf/" : "System Classpath",
      "/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/conf/" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/HikariCP-2.5.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/JLargeArrays-1.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/JTransforms-3.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/RoaringBitmap-0.9.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/ST4-4.0.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/accessors-smart-1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/activation-1.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/aircompressor-0.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/algebra_2.12-2.0.0-M2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/antlr-runtime-3.5.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/antlr4-runtime-4.8-1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/aopalliance-1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/aopalliance-repackaged-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arpack_combined_all-0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arrow-format-2.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arrow-memory-core-2.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arrow-memory-netty-2.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/arrow-vector-2.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/audience-annotations-0.5.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/avro-1.8.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/avro-ipc-1.8.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/avro-mapred-1.8.2-hadoop2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/bcpkix-jdk15on-1.60.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/bcprov-jdk15on-1.60.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/bonecp-0.8.0.RELEASE.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/breeze-macros_2.12-1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/breeze_2.12-1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/cats-kernel_2.12-2.0.0-M4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/chill-java-0.9.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/chill_2.12-0.9.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-beanutils-1.9.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-cli-1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-codec-1.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-collections-3.2.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-compiler-3.0.16.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-compress-1.20.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-configuration2-2.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-crypto-1.1.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-daemon-1.0.13.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-dbcp-1.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-httpclient-3.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-io-2.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-lang-2.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-lang3-3.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-logging-1.1.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-math3-3.4.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-net-3.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-pool-1.5.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/commons-text-1.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/compress-lzf-1.0.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/core-1.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/curator-client-2.13.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/curator-framework-2.13.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/curator-recipes-2.13.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/datanucleus-api-jdo-4.2.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/datanucleus-core-4.1.17.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/datanucleus-rdbms-4.1.19.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/derby-10.12.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/dnsjava-2.1.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/ehcache-3.3.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/flatbuffers-java-1.9.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/gcs-connector-hadoop3-2.2.7-shaded.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/geronimo-jcache_1.0_spec-1.0-alpha-1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/gson-2.2.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/guava-27.0-jre.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/guice-4.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/guice-servlet-4.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-annotations-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-auth-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-client-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-common-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-hdfs-client-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-mapreduce-client-common-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-mapreduce-client-core-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-mapreduce-client-jobclient-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-api-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-client-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-common-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-registry-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-server-common-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hadoop-yarn-server-web-proxy-3.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-beeline-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-cli-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-common-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-exec-2.3.7-core.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-jdbc-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-llap-common-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-metastore-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-serde-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-service-rpc-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-shims-0.23-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-shims-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-shims-common-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-shims-scheduler-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-storage-api-2.7.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hive-vector-code-gen-2.3.7.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hk2-api-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hk2-locator-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hk2-utils-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/htrace-core4-4.1.0-incubating.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/httpclient-4.4.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/httpcore-4.4.12.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/hudi-spark3.1-bundle_2.12-0.13.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/istack-commons-runtime-3.0.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/ivy-2.4.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-annotations-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-core-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-core-asl-1.9.13.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-databind-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-jaxrs-base-2.9.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-jaxrs-json-provider-2.9.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-mapper-asl-1.9.13.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-module-jaxb-annotations-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-module-paranamer-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jackson-module-scala_2.12-2.10.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.activation-api-1.2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.annotation-api-1.3.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.inject-2.6.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.servlet-api-4.0.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.validation-api-2.0.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.ws.rs-api-2.1.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jakarta.xml.bind-api-2.3.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/janino-3.0.16.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/javassist-3.25.0-GA.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/javax.inject-1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/javax.jdo-3.2.0-m3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/javolution-5.5.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jaxb-api-2.2.11.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jaxb-runtime-2.3.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jcip-annotations-1.0-1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jcl-over-slf4j-1.7.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jdo-api-3.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-client-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-common-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-container-servlet-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-container-servlet-core-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-hk2-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-media-jaxb-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jersey-server-2.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jline-2.14.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/joda-time-2.10.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jodd-core-3.5.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jpam-1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json-1.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json-smart-2.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json4s-ast_2.12-3.7.0-M5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json4s-core_2.12-3.7.0-M5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json4s-jackson_2.12-3.7.0-M5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/json4s-scalap_2.12-3.7.0-M5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jsp-api-2.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jsr305-3.0.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jta-1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/jul-to-slf4j-1.7.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-admin-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-client-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-common-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-core-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-crypto-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-identity-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-server-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-simplekdc-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerb-util-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-asn1-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-config-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-pkix-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-util-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kerby-xdr-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/kryo-shaded-4.0.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/leveldbjni-all-1.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/libfb303-0.9.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/libthrift-0.12.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/log4j-1.2.17.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/lz4-java-1.7.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/machinist_2.12-0.6.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/macro-compat_2.12-1.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-core-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-graphite-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-jmx-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-json-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/metrics-jvm-4.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/minlog-1.3.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/netty-all-4.1.51.Final.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/nimbus-jose-jwt-4.41.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/objenesis-2.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/okhttp-2.7.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/okio-1.14.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/opencsv-2.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/orc-core-1.5.12.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/orc-mapreduce-1.5.12.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/orc-shims-1.5.12.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/oro-2.0.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/osgi-resource-locator-1.0.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/paranamer-2.8.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-column-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-common-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-encoding-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-format-2.4.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-hadoop-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/parquet-jackson-1.10.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/protobuf-java-2.5.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/py4j-0.10.9.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/pyrolite-4.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/re2j-1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-collection-compat_2.12-2.1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-compiler-2.12.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-library-2.12.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-parser-combinators_2.12-1.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-reflect-2.12.10.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/scala-xml_2.12-1.2.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/shapeless_2.12-2.3.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/shims-0.9.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/slf4j-api-1.7.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/slf4j-log4j12-1.7.30.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/snappy-java-1.1.8.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-catalyst_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-core_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-graphx_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-hive-thriftserver_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-hive_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-kvstore_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-launcher_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-mllib-local_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-mllib_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-network-common_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-network-shuffle_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-repl_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-sketch_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-sql_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-streaming_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-tags_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-unsafe_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spark-yarn_2.12-3.1.2.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spire-macros_2.12-0.17.0-M1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spire-platform_2.12-0.17.0-M1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spire-util_2.12-0.17.0-M1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/spire_2.12-0.17.0-M1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/stax-api-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/stax2-api-3.1.4.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/stream-2.9.6.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/super-csv-2.2.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/threeten-extra-1.5.0.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/token-provider-1.0.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/transaction-api-1.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/univocity-parsers-2.9.1.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/velocity-1.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/woodstox-core-5.0.3.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/xbean-asm7-shaded-4.15.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/xz-1.5.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/zookeeper-3.4.14.jar" : "System Classpath",
      "/var/lib/fk-pf-spark3/jars/zstd-jni-1.4.8-1.jar" : "System Classpath",
      "gs" : "System Classpath"
    },
    "hadoopProps" : {
      "adl.feature.ownerandgroup.enableupn" : "false",
      "adl.http.timeout" : "-1",
      "ambari.hive.db.schema.name" : "hive",
      "datanucleus.cache.level2.type" : "none",
      "datanucleus.connectionPool.maxPoolSize" : "10",
      "datanucleus.schema.autoCreateTables" : "true",
      "dfs.blocksize" : "536870912",
      "dfs.bytes-per-checksum" : "512",
      "dfs.client.failover.proxy.provider.pluto" : "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
      "dfs.client.failover.random.order" : "true",
      "dfs.client.read.shortcircuit" : "true",
      "dfs.client.read.shortcircuit.streams.cache.size" : "4096",
      "dfs.domain.socket.path" : "/var/lib/hadoop-hdfs/dn_socket",
      "dfs.ha.fencing.ssh.connect-timeout" : "30000",
      "dfs.ha.namenodes.pluto" : "nn1,nn2",
      "dfs.namenode.http-address.pluto.nn1" : "fks-fdp-galaxy-pluto-nn-0001.c.fks-fdp-galaxy.internal:50070",
      "dfs.namenode.http-address.pluto.nn2" : "fks-fdp-galaxy-pluto-nn-0002.c.fks-fdp-galaxy.internal:50070",
      "dfs.namenode.https-address.pluto.nn1" : "fks-fdp-galaxy-pluto-nn-0001.c.fks-fdp-galaxy.internal:50470",
      "dfs.namenode.https-address.pluto.nn2" : "fks-fdp-galaxy-pluto-nn-0002.c.fks-fdp-galaxy.internal:50470",
      "dfs.namenode.rpc-address.pluto.nn1" : "fks-fdp-galaxy-pluto-nn-0001.c.fks-fdp-galaxy.internal:8020",
      "dfs.namenode.rpc-address.pluto.nn2" : "fks-fdp-galaxy-pluto-nn-0002.c.fks-fdp-galaxy.internal:8020",
      "dfs.nameservices" : "pluto",
      "dfs.replication" : "3",
      "fdp.default.tier" : "Regular",
      "fdp.ironbank.url" : "http://console.fdp-ironbank-prod.fkcloud.in/",
      "fdp.orgqueue.cache.expire" : "300",
      "fdp.orgqueue.cache.size" : "100",
      "fdp.orgqueue.defaultQueue" : "adhoc",
      "fdp.orgqueue.gringotts.clientId" : "QAAS",
      "fdp.orgqueue.gringotts.clientSecret" : "*********(redacted)",
      "fdp.orgqueue.gringotts.url" : "http://gringotts.fdp-gringotts-prod.fkcloud.in/billingOrg/user",
      "fdp.orgqueue.queueNotFound.errorMessage" : "Queue mapping not found",
      "fdp.orgqueue.validInitiators" : "BADGER,QAAS,LQE,SUPERBI",
      "fdp.tier.expression" : "Regular",
      "fdp.tier.lqe.lock.wait.time.secs" : "30",
      "fdp.tier.lqe.max.sessions" : "1",
      "file.blocksize" : "67108864",
      "file.bytes-per-checksum" : "512",
      "file.client-write-packet-size" : "65536",
      "file.replication" : "1",
      "file.stream-buffer-size" : "4096",
      "fs.AbstractFileSystem.abfs.impl" : "org.apache.hadoop.fs.azurebfs.Abfs",
      "fs.AbstractFileSystem.abfss.impl" : "org.apache.hadoop.fs.azurebfs.Abfss",
      "fs.AbstractFileSystem.adl.impl" : "org.apache.hadoop.fs.adl.Adl",
      "fs.AbstractFileSystem.file.impl" : "org.apache.hadoop.fs.local.LocalFs",
      "fs.AbstractFileSystem.ftp.impl" : "org.apache.hadoop.fs.ftp.FtpFs",
      "fs.AbstractFileSystem.gs.impl" : "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS",
      "fs.AbstractFileSystem.har.impl" : "org.apache.hadoop.fs.HarFs",
      "fs.AbstractFileSystem.hdfs.impl" : "org.apache.hadoop.fs.Hdfs",
      "fs.AbstractFileSystem.s3a.impl" : "org.apache.hadoop.fs.s3a.S3A",
      "fs.AbstractFileSystem.swebhdfs.impl" : "org.apache.hadoop.fs.SWebHdfs",
      "fs.AbstractFileSystem.viewfs.impl" : "org.apache.hadoop.fs.viewfs.ViewFs",
      "fs.AbstractFileSystem.wasb.impl" : "org.apache.hadoop.fs.azure.Wasb",
      "fs.AbstractFileSystem.wasbs.impl" : "org.apache.hadoop.fs.azure.Wasbs",
      "fs.AbstractFileSystem.webhdfs.impl" : "org.apache.hadoop.fs.WebHdfs",
      "fs.abfs.impl" : "org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem",
      "fs.abfss.impl" : "org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem",
      "fs.adl.impl" : "org.apache.hadoop.fs.adl.AdlFileSystem",
      "fs.adl.oauth2.access.token.provider.type" : "*********(redacted)",
      "fs.automatic.close" : "true",
      "fs.azure.authorization" : "false",
      "fs.azure.authorization.caching.enable" : "true",
      "fs.azure.local.sas.key.mode" : "false",
      "fs.azure.sas.expiry.period" : "90d",
      "fs.azure.saskey.usecontainersaskeyforallaccess" : "true",
      "fs.azure.secure.mode" : "false",
      "fs.azure.user.agent.prefix" : "unknown",
      "fs.client.resolve.remote.symlinks" : "true",
      "fs.client.resolve.topology.enabled" : "false",
      "fs.defaultFS" : "hdfs://pluto",
      "fs.df.interval" : "60000",
      "fs.du.interval" : "600000",
      "fs.ftp.data.connection.mode" : "ACTIVE_LOCAL_DATA_CONNECTION_MODE",
      "fs.ftp.host" : "0.0.0.0",
      "fs.ftp.host.port" : "21",
      "fs.ftp.impl" : "org.apache.hadoop.fs.ftp.FTPFileSystem",
      "fs.ftp.transfer.mode" : "BLOCK_TRANSFER_MODE",
      "fs.gs.auth.service.account.enable" : "true",
      "fs.gs.batch.threads" : "60",
      "fs.gs.impl" : "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem",
      "fs.gs.max.requests.per.batch" : "300",
      "fs.gs.reported.permissions" : "777",
      "fs.har.impl.disable.cache" : "true",
      "fs.permissions.umask-mode" : "022",
      "fs.s3.useRequesterPaysHeader" : "true",
      "fs.s3a.assumed.role.credentials.provider" : "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider",
      "fs.s3a.assumed.role.session.duration" : "30m",
      "fs.s3a.assumed.role.sts.endpoint.region" : "us-west-1",
      "fs.s3a.attempts.maximum" : "20",
      "fs.s3a.block.size" : "32M",
      "fs.s3a.buffer.dir" : "${hadoop.tmp.dir}/s3a",
      "fs.s3a.change.detection.mode" : "server",
      "fs.s3a.change.detection.source" : "etag",
      "fs.s3a.change.detection.version.required" : "true",
      "fs.s3a.committer.magic.enabled" : "false",
      "fs.s3a.committer.name" : "file",
      "fs.s3a.committer.staging.abort.pending.uploads" : "true",
      "fs.s3a.committer.staging.conflict-mode" : "fail",
      "fs.s3a.committer.staging.tmp.path" : "tmp/staging",
      "fs.s3a.committer.staging.unique-filenames" : "true",
      "fs.s3a.committer.threads" : "8",
      "fs.s3a.connection.establish.timeout" : "5000",
      "fs.s3a.connection.maximum" : "15",
      "fs.s3a.connection.ssl.enabled" : "true",
      "fs.s3a.connection.timeout" : "200000",
      "fs.s3a.etag.checksum.enabled" : "false",
      "fs.s3a.fast.upload.active.blocks" : "4",
      "fs.s3a.fast.upload.buffer" : "disk",
      "fs.s3a.impl" : "org.apache.hadoop.fs.s3a.S3AFileSystem",
      "fs.s3a.list.version" : "2",
      "fs.s3a.max.total.tasks" : "5",
      "fs.s3a.metadatastore.authoritative" : "false",
      "fs.s3a.metadatastore.impl" : "org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore",
      "fs.s3a.multiobjectdelete.enable" : "true",
      "fs.s3a.multipart.purge" : "false",
      "fs.s3a.multipart.purge.age" : "86400",
      "fs.s3a.multipart.size" : "100M",
      "fs.s3a.multipart.threshold" : "2147483647",
      "fs.s3a.paging.maximum" : "5000",
      "fs.s3a.path.style.access" : "false",
      "fs.s3a.readahead.range" : "64K",
      "fs.s3a.retry.interval" : "500ms",
      "fs.s3a.retry.limit" : "${fs.s3a.attempts.maximum}",
      "fs.s3a.retry.throttle.interval" : "1000ms",
      "fs.s3a.retry.throttle.limit" : "${fs.s3a.attempts.maximum}",
      "fs.s3a.s3guard.cli.prune.age" : "86400000",
      "fs.s3a.s3guard.ddb.background.sleep" : "25ms",
      "fs.s3a.s3guard.ddb.max.retries" : "9",
      "fs.s3a.s3guard.ddb.table.capacity.read" : "500",
      "fs.s3a.s3guard.ddb.table.capacity.write" : "100",
      "fs.s3a.s3guard.ddb.table.create" : "false",
      "fs.s3a.s3guard.ddb.throttle.retry.interval" : "100ms",
      "fs.s3a.socket.recv.buffer" : "8192",
      "fs.s3a.socket.send.buffer" : "8192",
      "fs.s3a.threads.keepalivetime" : "60",
      "fs.s3a.threads.max" : "10",
      "fs.swift.impl" : "org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem",
      "fs.trash.checkpoint.interval" : "0",
      "fs.trash.interval" : "0",
      "fs.viewfs.rename.strategy" : "SAME_MOUNTPOINT",
      "fs.wasb.impl" : "org.apache.hadoop.fs.azure.NativeAzureFileSystem",
      "fs.wasbs.impl" : "org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure",
      "ftp.blocksize" : "67108864",
      "ftp.bytes-per-checksum" : "512",
      "ftp.client-write-packet-size" : "65536",
      "ftp.replication" : "3",
      "ftp.stream-buffer-size" : "4096",
      "google.cloud.auth.service.account.enable" : "true",
      "ha.failover-controller.cli-check.rpc-timeout.ms" : "20000",
      "ha.failover-controller.graceful-fence.connection.retries" : "1",
      "ha.failover-controller.graceful-fence.rpc-timeout.ms" : "5000",
      "ha.failover-controller.new-active.rpc-timeout.ms" : "60000",
      "ha.health-monitor.check-interval.ms" : "1000",
      "ha.health-monitor.connect-retry-interval.ms" : "1000",
      "ha.health-monitor.rpc-timeout.ms" : "45000",
      "ha.health-monitor.sleep-after-disconnect.ms" : "1000",
      "ha.zookeeper.acl" : "world:anyone:rwcda",
      "ha.zookeeper.parent-znode" : "/hadoop-ha",
      "ha.zookeeper.session-timeout.ms" : "10000",
      "hadoop.caller.context.enabled" : "false",
      "hadoop.caller.context.max.size" : "128",
      "hadoop.caller.context.signature.max.size" : "40",
      "hadoop.common.configuration.version" : "3.0.0",
      "hadoop.http.authentication.kerberos.keytab" : "${user.home}/hadoop.keytab",
      "hadoop.http.authentication.kerberos.principal" : "HTTP/_HOST@LOCALHOST",
      "hadoop.http.authentication.signature.secret.file" : "*********(redacted)",
      "hadoop.http.authentication.simple.anonymous.allowed" : "true",
      "hadoop.http.authentication.token.validity" : "*********(redacted)",
      "hadoop.http.authentication.type" : "simple",
      "hadoop.http.cross-origin.allowed-headers" : "X-Requested-With,Content-Type,Accept,Origin",
      "hadoop.http.cross-origin.allowed-methods" : "GET,POST,HEAD",
      "hadoop.http.cross-origin.allowed-origins" : "*",
      "hadoop.http.cross-origin.enabled" : "false",
      "hadoop.http.cross-origin.max-age" : "1800",
      "hadoop.http.filter.initializers" : "org.apache.hadoop.http.lib.StaticUserWebFilter",
      "hadoop.http.logs.enabled" : "true",
      "hadoop.http.staticuser.user" : "dr.who",
      "hadoop.jetty.logs.serve.aliases" : "true",
      "hadoop.kerberos.kinit.command" : "kinit",
      "hadoop.kerberos.min.seconds.before.relogin" : "60",
      "hadoop.proxyuser.hive.groups" : "*",
      "hadoop.proxyuser.hive.hosts" : "*",
      "hadoop.registry.jaas.context" : "Client",
      "hadoop.registry.secure" : "false",
      "hadoop.registry.system.acls" : "sasl:yarn@, sasl:mapred@, sasl:hdfs@",
      "hadoop.registry.zk.connection.timeout.ms" : "15000",
      "hadoop.registry.zk.quorum" : "localhost:2181",
      "hadoop.registry.zk.retry.ceiling.ms" : "60000",
      "hadoop.registry.zk.retry.interval.ms" : "1000",
      "hadoop.registry.zk.retry.times" : "5",
      "hadoop.registry.zk.root" : "/registry",
      "hadoop.registry.zk.session.timeout.ms" : "60000",
      "hadoop.rpc.protection" : "authentication",
      "hadoop.rpc.socket.factory.class.default" : "org.apache.hadoop.net.StandardSocketFactory",
      "hadoop.security.auth_to_local" : "DEFAULT",
      "hadoop.security.auth_to_local.mechanism" : "hadoop",
      "hadoop.security.authentication" : "simple",
      "hadoop.security.authorization" : "false",
      "hadoop.security.credential.clear-text-fallback" : "true",
      "hadoop.security.crypto.buffer.size" : "8192",
      "hadoop.security.crypto.cipher.suite" : "AES/CTR/NoPadding",
      "hadoop.security.crypto.codec.classes.aes.ctr.nopadding" : "org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec",
      "hadoop.security.dns.log-slow-lookups.enabled" : "false",
      "hadoop.security.dns.log-slow-lookups.threshold.ms" : "1000",
      "hadoop.security.group.mapping" : "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback",
      "hadoop.security.group.mapping.ldap.connection.timeout.ms" : "60000",
      "hadoop.security.group.mapping.ldap.conversion.rule" : "none",
      "hadoop.security.group.mapping.ldap.directory.search.timeout" : "10000",
      "hadoop.security.group.mapping.ldap.num.attempts" : "3",
      "hadoop.security.group.mapping.ldap.num.attempts.before.failover" : "3",
      "hadoop.security.group.mapping.ldap.posix.attr.gid.name" : "gidNumber",
      "hadoop.security.group.mapping.ldap.posix.attr.uid.name" : "uidNumber",
      "hadoop.security.group.mapping.ldap.read.timeout.ms" : "60000",
      "hadoop.security.group.mapping.ldap.search.attr.group.name" : "cn",
      "hadoop.security.group.mapping.ldap.search.attr.member" : "member",
      "hadoop.security.group.mapping.ldap.search.filter.group" : "(objectClass=group)",
      "hadoop.security.group.mapping.ldap.search.filter.user" : "(&(objectClass=user)(sAMAccountName={0}))",
      "hadoop.security.group.mapping.ldap.search.group.hierarchy.levels" : "0",
      "hadoop.security.group.mapping.ldap.ssl" : "false",
      "hadoop.security.group.mapping.providers.combined" : "true",
      "hadoop.security.groups.cache.background.reload" : "false",
      "hadoop.security.groups.cache.background.reload.threads" : "3",
      "hadoop.security.groups.cache.secs" : "300",
      "hadoop.security.groups.cache.warn.after.ms" : "5000",
      "hadoop.security.groups.negative-cache.secs" : "30",
      "hadoop.security.groups.shell.command.timeout" : "0s",
      "hadoop.security.instrumentation.requires.admin" : "false",
      "hadoop.security.java.secure.random.algorithm" : "SHA1PRNG",
      "hadoop.security.key.default.bitlength" : "128",
      "hadoop.security.key.default.cipher" : "AES/CTR/NoPadding",
      "hadoop.security.kms.client.authentication.retry-count" : "1",
      "hadoop.security.kms.client.encrypted.key.cache.expiry" : "43200000",
      "hadoop.security.kms.client.encrypted.key.cache.low-watermark" : "0.3f",
      "hadoop.security.kms.client.encrypted.key.cache.num.refill.threads" : "2",
      "hadoop.security.kms.client.encrypted.key.cache.size" : "500",
      "hadoop.security.kms.client.failover.sleep.base.millis" : "100",
      "hadoop.security.kms.client.failover.sleep.max.millis" : "2000",
      "hadoop.security.kms.client.timeout" : "60",
      "hadoop.security.random.device.file.path" : "/dev/urandom",
      "hadoop.security.sensitive-config-keys" : "*********(redacted)",
      "hadoop.security.uid.cache.secs" : "14400",
      "hadoop.service.shutdown.timeout" : "30s",
      "hadoop.shell.missing.defaultFs.warning" : "false",
      "hadoop.shell.safely.delete.limit.num.files" : "100",
      "hadoop.ssl.client.conf" : "ssl-client.xml",
      "hadoop.ssl.enabled" : "false",
      "hadoop.ssl.enabled.protocols" : "TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2",
      "hadoop.ssl.hostname.verifier" : "DEFAULT",
      "hadoop.ssl.keystores.factory.class" : "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory",
      "hadoop.ssl.require.client.cert" : "false",
      "hadoop.ssl.server.conf" : "ssl-server.xml",
      "hadoop.system.tags" : "YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL",
      "hadoop.tags.system" : "YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL",
      "hadoop.tmp.dir" : "/tmp/hadoop-${user.name}",
      "hadoop.user.group.static.mapping.overrides" : "dr.who=;",
      "hadoop.util.hash.type" : "murmur",
      "hadoop.workaround.non.threadsafe.getpwuid" : "true",
      "hadoop.zk.acl" : "world:anyone:rwcda",
      "hadoop.zk.num-retries" : "1000",
      "hadoop.zk.retry-interval-ms" : "1000",
      "hadoop.zk.timeout-ms" : "10000",
      "hbase.zookeeper.quorum" : "fks-fdp-galaxy-pluto-zkjn-0001.c.fks-fdp-galaxy.internal:2181,fks-fdp-galaxy-pluto-zkjn-0002.c.fks-fdp-galaxy.internal:2181,fks-fdp-galaxy-pluto-zkjn-0003.c.fks-fdp-galaxy.internal:2181",
      "hive.auto.convert.join" : "false",
      "hive.auto.convert.join.noconditionaltask" : "false",
      "hive.auto.convert.join.noconditionaltask.size" : "134217728",
      "hive.auto.convert.sortmerge.join" : "false",
      "hive.auto.convert.sortmerge.join.noconditionaltask" : "false",
      "hive.auto.convert.sortmerge.join.to.mapjoin" : "false",
      "hive.cbo.enable" : "true",
      "hive.cli.print.header" : "false",
      "hive.cluster.delegation.token.store.class" : "*********(redacted)",
      "hive.cluster.delegation.token.store.zookeeper.connectString" : "*********(redacted)",
      "hive.cluster.delegation.token.store.zookeeper.znode" : "*********(redacted)",
      "hive.compactor.abortedtxn.threshold" : "1000",
      "hive.compactor.check.interval" : "300L",
      "hive.compactor.delta.num.threshold" : "10",
      "hive.compactor.delta.pct.threshold" : "0.1f",
      "hive.compactor.initiator.on" : "false",
      "hive.compactor.worker.threads" : "0",
      "hive.compactor.worker.timeout" : "86400L",
      "hive.compute.query.using.stats" : "false",
      "hive.conf.restricted.list" : "hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role",
      "hive.convert.join.bucket.mapjoin.tez" : "true",
      "hive.default.fileformat.managed" : "ORC",
      "hive.driver.parallel.compilation" : "true",
      "hive.enforce.bucketing" : "true",
      "hive.enforce.sorting" : "true",
      "hive.enforce.sortmergebucketmapjoin" : "true",
      "hive.exec.compress.intermediate" : "true",
      "hive.exec.compress.output" : "false",
      "hive.exec.dynamic.partition" : "true",
      "hive.exec.dynamic.partition.mode" : "nonstrict",
      "hive.exec.failure.hooks" : "com.flipkart.fdp.hive.hooks.EnforceSingleQueryPostExecHook",
      "hive.exec.max.created.files" : "100000",
      "hive.exec.max.dynamic.partitions" : "1000000",
      "hive.exec.max.dynamic.partitions.pernode" : "1000000",
      "hive.exec.orc.compression.strategy" : "SPEED",
      "hive.exec.orc.default.compress" : "ZLIB",
      "hive.exec.orc.default.stripe.size" : "67108864",
      "hive.exec.parallel" : "true",
      "hive.exec.parallel.thread.number" : "8",
      "hive.exec.post.hooks" : "org.apache.hadoop.hive.ql.hooks.LineageLogger,com.flipkart.fdp.hive.hooks.EnforceSingleQueryPostExecHook",
      "hive.exec.pre.hooks" : "com.flipkart.fdp.hive.hooks.EnforceSingleQueryPreExecHook",
      "hive.exec.reducers.bytes.per.reducer" : "134217728",
      "hive.exec.reducers.max" : "250",
      "hive.exec.scratchdir" : "gs://stage-hive-metastore-pluto/user/hiveexternaldir",
      "hive.exec.submit.local.task.via.child" : "true",
      "hive.exec.submitviachild" : "false",
      "hive.execution.engine" : "tez",
      "hive.fetch.task.aggr" : "true",
      "hive.fetch.task.conversion" : "more",
      "hive.fetch.task.conversion.threshold" : "1073741824",
      "hive.fileformat.managed" : "ORC",
      "hive.heapsize" : "2048",
      "hive.input.format" : "org.apache.hadoop.hive.ql.io.CombineHiveInputFormat",
      "hive.limit.optimize.enable" : "true",
      "hive.limit.pushdown.memory.usage" : "0.2",
      "hive.map.aggr" : "true",
      "hive.map.aggr.hash.force.flush.memory.threshold" : "0.5",
      "hive.map.aggr.hash.min.reduction" : "0.5",
      "hive.map.aggr.hash.percentmemory" : "0.5",
      "hive.mapjoin.bucket.cache.size" : "1000",
      "hive.mapjoin.localtask.max.memory.usage" : "0.4",
      "hive.mapjoin.optimized.hashtable" : "false",
      "hive.mapred.reduce.tasks.speculative.execution" : "false",
      "hive.merge.mapfiles" : "true",
      "hive.merge.mapredfiles" : "false",
      "hive.merge.orcfile.stripe.level" : "true",
      "hive.merge.rcfile.block.level" : "true",
      "hive.merge.size.per.task" : "256000000",
      "hive.merge.smallfiles.avgsize" : "16000000",
      "hive.merge.tezfiles" : "true",
      "hive.metastore.authorization.storage.checks" : "false",
      "hive.metastore.cache.pinobjtypes" : "Table,Database,Type,FieldSchema,Order",
      "hive.metastore.client.connect.retry.delay" : "5s",
      "hive.metastore.client.scheme.handlers" : "com.flipkart.fdp.hive.metastore.ELBSchemeHandler",
      "hive.metastore.client.socket.timeout" : "1800s",
      "hive.metastore.connect.retries" : "24",
      "hive.metastore.execute.setugi" : "true",
      "hive.metastore.failure.retries" : "24",
      "hive.metastore.fshandler.threads" : "15",
      "hive.metastore.kerberos.keytab.file" : "/etc/security/keytabs/hive.service.keytab",
      "hive.metastore.kerberos.principal" : "hive/_HOST@EXAMPLE.COM",
      "hive.metastore.limit.partition.request" : "-1",
      "hive.metastore.metrics.enabled" : "true",
      "hive.metastore.pre.event.listeners" : "org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener",
      "hive.metastore.sasl.enabled" : "false",
      "hive.metastore.server.max.threads" : "100000",
      "hive.metastore.uris" : "thrift://10.116.17.2:9083",
      "hive.metastore.warehouse.dir" : "gs://stage-hive-metastore-pluto/apps/hive/warehouse",
      "hive.msck.path.validation" : "ignore",
      "hive.msck.repair.batch.size" : "0",
      "hive.optimize.bucketmapjoin" : "true",
      "hive.optimize.bucketmapjoin.sortedmerge" : "true",
      "hive.optimize.constant.propagation" : "true",
      "hive.optimize.index.filter" : "true",
      "hive.optimize.mapjoin.mapreduce" : "true",
      "hive.optimize.metadataonly" : "true",
      "hive.optimize.null.scan" : "true",
      "hive.optimize.reducededuplication" : "true",
      "hive.optimize.reducededuplication.min.reducer" : "4",
      "hive.optimize.sort.dynamic.partition" : "true",
      "hive.orc.compute.splits.num.threads" : "10",
      "hive.orc.splits.include.file.footer" : "false",
      "hive.prewarm.enabled" : "false",
      "hive.prewarm.numcontainers" : "10",
      "hive.querylog.enable.plan.progress" : "false",
      "hive.security.authenticator.manager" : "org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator",
      "hive.security.authorization.enabled" : "false",
      "hive.security.authorization.manager" : "org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory",
      "hive.security.authorization.sqlstd.confwhitelist.append" : "|initiator.*|job.*|mapred.*|badger.*|azkaban.*|tez.*|dfs.*|mapreduce.*|hive.*|hbase.*|light.*|beeline.*|orc.*|fdp.*|.*impersonation.*|fs.gs.*",
      "hive.security.metastore.authenticator.manager" : "org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator",
      "hive.security.metastore.authorization.auth.reads" : "true",
      "hive.security.metastore.authorization.manager" : "\n            org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider\n        ",
      "hive.server2.allow.user.substitution" : "true",
      "hive.server2.authentication" : "NONE",
      "hive.server2.authentication.spnego.keytab" : "HTTP/_HOST@EXAMPLE.COM",
      "hive.server2.authentication.spnego.principal" : "/etc/security/keytabs/spnego.service.keytab",
      "hive.server2.clear.dangling.scratchdir" : "true",
      "hive.server2.clear.dangling.scratchdir.interval" : "1800",
      "hive.server2.enable.doAs" : "true",
      "hive.server2.enable.impersonation" : "true",
      "hive.server2.idle.operation.timeout" : "1d",
      "hive.server2.idle.session.timeout" : "1d",
      "hive.server2.logging.operation.enabled" : "true",
      "hive.server2.logging.operation.log.location" : "${java.io.tmpdir}/${user.name}/operation_logs",
      "hive.server2.metrics.enabled" : "true",
      "hive.server2.session.check.interval" : "60m",
      "hive.server2.support.dynamic.service.discovery" : "true",
      "hive.server2.table.type.mapping" : "CLASSIC",
      "hive.server2.tez.default.queues" : "default",
      "hive.server2.tez.initialize.default.sessions" : "false",
      "hive.server2.tez.sessions.per.default.queue" : "1",
      "hive.server2.thrift.http.path" : "cliservice",
      "hive.server2.thrift.http.port" : "10001",
      "hive.server2.thrift.max.worker.threads" : "500",
      "hive.server2.thrift.sasl.qop" : "auth",
      "hive.server2.transport.mode" : "http",
      "hive.server2.use.SSL" : "false",
      "hive.server2.zookeeper.namespace" : "fks-fdp-galaxy-hive3-hs2-pluto",
      "hive.session.history.enabled" : "false",
      "hive.smbjoin.cache.rows" : "1000",
      "hive.stats.autogather" : "true",
      "hive.stats.dbclass" : "fs",
      "hive.stats.fetch.column.stats" : "false",
      "hive.stats.fetch.partition.stats" : "false",
      "hive.strict.checks.cartesian.product" : "false",
      "hive.strict.checks.type.safety" : "false",
      "hive.support.concurrency" : "false",
      "hive.support.sql11.reserved.keywords" : "true",
      "hive.tez.auto.reducer.parallelism" : "false",
      "hive.tez.container.size" : "3072",
      "hive.tez.cpu.vcores" : "-1",
      "hive.tez.dynamic.partition.pruning" : "true",
      "hive.tez.dynamic.partition.pruning.max.data.size" : "104857600",
      "hive.tez.dynamic.partition.pruning.max.event.size" : "1048576",
      "hive.tez.input.format" : "org.apache.hadoop.hive.ql.io.HiveInputFormat",
      "hive.tez.log.level" : "INFO",
      "hive.tez.max.partition.factor" : "2.0",
      "hive.tez.min.partition.factor" : "0.25",
      "hive.tez.smb.number.waves" : "0.5",
      "hive.txn.manager" : "org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager",
      "hive.txn.max.open.batch" : "1000",
      "hive.txn.timeout" : "300",
      "hive.user.install.directory" : "gs://stage-hive-metastore-pluto/user/",
      "hive.vectorized.complex.types.enabled" : "false",
      "hive.vectorized.execution.enabled" : "true",
      "hive.vectorized.execution.ptf.enabled" : "false",
      "hive.vectorized.execution.reduce.enabled" : "true",
      "hive.vectorized.groupby.checkinterval" : "4096",
      "hive.vectorized.groupby.complex.types.enabled" : "false",
      "hive.vectorized.groupby.flush.percent" : "0.1",
      "hive.vectorized.groupby.maxentries" : "10000",
      "hive.zookeeper.client.port" : "2181",
      "hive.zookeeper.namespace" : "fks-sco-hive-pluto-zookeeper-namespace",
      "hive.zookeeper.quorum" : "fks-fdp-galaxy-pluto-zkjn-0001.c.fks-fdp-galaxy.internal:2181,fks-fdp-galaxy-pluto-zkjn-0002.c.fks-fdp-galaxy.internal:2181,fks-fdp-galaxy-pluto-zkjn-0003.c.fks-fdp-galaxy.internal:2181",
      "hive.zookeeper.session.timeout" : "120s",
      "io.compression.codec.bzip2.library" : "system-native",
      "io.compression.codec.lzo.class" : "com.hadoop.compression.lzo.LzoCodec",
      "io.compression.codecs" : "org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,com.hadoop.compression.fourmc.Lz4Codec,com.hadoop.compression.fourmc.Lz4MediumCodec,com.hadoop.compression.fourmc.Lz4HighCodec,com.hadoop.compression.fourmc.Lz4UltraCodec,com.hadoop.compression.fourmc.FourMcCodec,com.hadoop.compression.fourmc.FourMcMediumCodec,com.hadoop.compression.fourmc.FourMcHighCodec,com.hadoop.compression.fourmc.FourMcUltraCodec",
      "io.erasurecode.codec.rs-legacy.rawcoders" : "rs-legacy_java",
      "io.erasurecode.codec.rs.rawcoders" : "rs_native,rs_java",
      "io.erasurecode.codec.xor.rawcoders" : "xor_native,xor_java",
      "io.file.buffer.size" : "65536",
      "io.map.index.interval" : "128",
      "io.map.index.skip" : "0",
      "io.mapfile.bloom.error.rate" : "0.005",
      "io.mapfile.bloom.size" : "1048576",
      "io.seqfile.compress.blocksize" : "1000000",
      "io.seqfile.local.dir" : "${hadoop.tmp.dir}/io/local",
      "io.serializations" : "org.apache.hadoop.io.serializer.WritableSerialization",
      "io.skip.checksum.errors" : "false",
      "ipc.client.bind.wildcard.addr" : "false",
      "ipc.client.connect.max.retries" : "50",
      "ipc.client.connect.max.retries.on.timeouts" : "45",
      "ipc.client.connect.retry.interval" : "1000",
      "ipc.client.connect.timeout" : "20000",
      "ipc.client.connection.maxidletime" : "30000",
      "ipc.client.fallback-to-simple-auth-allowed" : "false",
      "ipc.client.idlethreshold" : "8000",
      "ipc.client.kill.max" : "10",
      "ipc.client.low-latency" : "false",
      "ipc.client.ping" : "true",
      "ipc.client.rpc-timeout.ms" : "0",
      "ipc.client.tcpnodelay" : "true",
      "ipc.maximum.data.length" : "67108864",
      "ipc.maximum.response.length" : "134217728",
      "ipc.ping.interval" : "60000",
      "ipc.server.listen.queue.size" : "128",
      "ipc.server.log.slow.rpc" : "false",
      "ipc.server.max.connections" : "0",
      "javax.jdo.option.ConnectionDriverName" : "com.mysql.jdbc.Driver",
      "javax.jdo.option.ConnectionPassword" : "*********(redacted)",
      "javax.jdo.option.ConnectionURL" : "jdbc:mysql://10.117.192.58/stage_hive_metastore?createDatabaseIfNotExist=true",
      "javax.jdo.option.ConnectionUserName" : "stage_sco_rw",
      "jobname.enricher.class" : "org.apache.hadoop.hive.ql.propertymodifier.NoEnrichment",
      "map.sort.class" : "org.apache.hadoop.util.QuickSort",
      "net.topology.impl" : "org.apache.hadoop.net.NetworkTopology",
      "net.topology.node.switch.mapping.impl" : "org.apache.hadoop.net.ScriptBasedMapping",
      "net.topology.script.file.name" : "/etc/hadoop/conf/topology.py",
      "net.topology.script.number.args" : "100",
      "nfs.exports.allowed.hosts" : "* rw",
      "orc.schema.evolution.case.sensitive" : "false",
      "parser.timeoutSec" : "900",
      "queue.enforcer.class" : "com.flipkart.fdp.hive.orgqueue.OrgQueueEnforcerForInitiator",
      "rpc.metrics.quantile.enable" : "false",
      "seq.io.sort.factor" : "100",
      "seq.io.sort.mb" : "100",
      "tfile.fs.input.buffer.size" : "262144",
      "tfile.fs.output.buffer.size" : "262144",
      "tfile.io.chunk.size" : "1048576",
      "zookeeper.znode.parent" : "/hbase-unsecure"
    },
    "runtimeInfo" : {
      "javaHome" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre",
      "javaVersion" : "1.8.0_172 (Oracle Corporation)",
      "scalaVersion" : "version 2.12.10"
    },
    "sparkBuildInfo" : {
      "sparkBuildBranch" : "fdp-3.1.2-hadoop-3.2",
      "sparkBuildDate" : "2023-04-05T09:07:25Z",
      "sparkBuildRevision" : "1f03c4907e323e2f782742ceae6feff6c8ddcd12",
      "sparkBuildUser" : "somi.biswas",
      "sparkBuildVersion" : "3.1.2"
    },
    "sparkProps" : {
      "spark.app.id" : "application_1699449121496_0380",
      "spark.app.name" : "Spark shell",
      "spark.app.startTime" : "1701342693143",
      "spark.benchmarkId" : "20231130-164024-tpcds-1gb-iceberg-load",
      "spark.cleaner.ttl" : "86400",
      "spark.delta.logStore.gs.impl" : "io.delta.storage.GCSLogStore",
      "spark.driver.appUIAddress" : "http://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:4045",
      "spark.driver.cores" : "1",
      "spark.driver.extraClassPath" : "gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar",
      "spark.driver.extraJavaOptions" : "-Denv=prod -Dcom.sun.management.jmxremote.port=0 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=0 -XX:MaxDirectMemorySize=800M -XX:MaxMetaspaceSize=256M -XX:CompressedClassSpaceSize=100M -XX:+UnlockDiagnosticVMOptions -Djob.numOfRePartitions=30",
      "spark.driver.extraLibraryPath" : "/usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu",
      "spark.driver.host" : "fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal",
      "spark.driver.memory" : "5120m",
      "spark.driver.port" : "40915",
      "spark.dynamicAllocation.enabled" : "true",
      "spark.dynamicAllocation.executorIdleTimeout" : "60s",
      "spark.dynamicAllocation.maxExecutors" : "200",
      "spark.eventLog.dir" : "gs://fks-fdp-infra-job-history/pluto/spark-job-history",
      "spark.eventLog.enabled" : "true",
      "spark.executor.cores" : "1",
      "spark.executor.extraClassPath" : "gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar",
      "spark.executor.extraJavaOptions" : "-XX:MaxDirectMemorySize=8096m -Dio.netty.maxDirectMemory=8096m -XX:+UseG1GC -XX:ConcGCThreads=2",
      "spark.executor.extraLibraryPath" : "/usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu",
      "spark.executor.id" : "driver",
      "spark.executor.memory" : "10240m",
      "spark.fdp.orgqueue.cache.expire" : "300",
      "spark.fdp.orgqueue.cache.size" : "100",
      "spark.fdp.orgqueue.defaultQueue" : "adhoc",
      "spark.fdp.orgqueue.gringotts.clientId" : "QAAS",
      "spark.fdp.orgqueue.gringotts.clientSecret" : "*********(redacted)",
      "spark.fdp.orgqueue.gringotts.url" : "http://10.47.6.66/billingOrg/user",
      "spark.fdp.orgqueue.ironbank.url" : "http://10.47.4.16:/queue/",
      "spark.fdp.orgqueue.queueNotFound.errorMessage" : "Queue mapping not found",
      "spark.fdp.orgqueue.validInitiators" : "BADGER,QAAS",
      "spark.hadoop.fs.s3.useRequesterPaysHeader" : "true",
      "spark.hadoop.yarn.timeline-service.enabled" : "false",
      "spark.history.fs.cleaner.interval" : "1d",
      "spark.history.fs.cleaner.maxAge" : "60d",
      "spark.history.fs.logDirectory" : "gs://fks-fdp-infra-job-history/pluto/spark-job-history",
      "spark.history.provider" : "org.apache.spark.deploy.history.FsHistoryProvider",
      "spark.home" : "/var/lib/fk-pf-spark3",
      "spark.jars" : "",
      "spark.master" : "yarn",
      "spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS" : "fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal",
      "spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES" : "http://fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0380,http://fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088/proxy/application_1699449121496_0380",
      "spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS" : "fks-fdp-galaxy-pluto-rm-0001.c.fks-fdp-galaxy.internal:8088,fks-fdp-galaxy-pluto-rm-0002.c.fks-fdp-galaxy.internal:8088",
      "spark.queue.enforcer.class" : "com.flipkart.fdp.orgqueue.OrgQueueEnforcerForInitiator",
      "spark.repl.class.outputDir" : "/grid/1/spark3/tmp/spark-e9ee4777-da8d-4630-91ac-406365aca7f2/repl-7d088c05-0c57-4fc5-8d02-18931c4f778e",
      "spark.repl.class.uri" : "spark://fdp-stage-azk-scheduled-executor-b5cff3b1-nftj.c.fks-sco-azkaban.internal:40915/classes",
      "spark.repl.local.jars" : "file:///home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar",
      "spark.scheduler.mode" : "FIFO",
      "spark.shuffle.service.enabled" : "true",
      "spark.shuffle.useOldFetchProtocol" : "true",
      "spark.sql.catalog.hive_pluto" : "org.apache.iceberg.spark.SparkCatalog",
      "spark.sql.catalog.hive_pluto.type" : "hive",
      "spark.sql.catalog.hive_pluto.uri" : "thrift://10.116.17.2:9083",
      "spark.sql.catalogImplementation" : "hive",
      "spark.sql.extensions" : "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions",
      "spark.sql.sources.partitionOverwriteMode" : "dynamic",
      "spark.streaming.concurrentJobs" : "4",
      "spark.submit.deployMode" : "client",
      "spark.submit.pyFiles" : "",
      "spark.ui.filters" : "org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter",
      "spark.ui.showConsoleProgress" : "true",
      "spark.yarn.dist.jars" : "gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/hadoop-lzo-0.6.0.2.4.0.0-169.jar,file:/usr/share/fk-bigfoot-4mc/lib/hadoop-4mc-1.1.0.jar,gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,gs://fksdp-mhosy-3nug-2a5d-systemlibs/libraries/hive/jars/dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,file:///home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,file:///var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar",
      "spark.yarn.driver.memoryOverhead" : "4096",
      "spark.yarn.executor.memoryOverhead" : "4096",
      "spark.yarn.historyServer.address" : "http://fks-fdp-galaxy-pluto-hs-0001-m.c.fks-fdp-galaxy.internal:18080",
      "spark.yarn.jars" : "",
      "spark.yarn.queue" : "de_adhoc",
      "spark.yarn.report.interval" : "60s",
      "spark.yarn.secondary.jars" : "hadoop-lzo-0.6.0.2.4.0.0-169.jar,hadoop-4mc-1.1.0.jar,json-serde-1.3-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,dimlookup-hive-udf-1.0-SNAPSHOT-jar-with-dependencies-jackson-shaded.jar,20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar,iceberg-hive-runtime-1.2.0.jar,iceberg-spark-runtime-3.1_2.12-1.2.0.jar"
    },
    "systemProps" : {
      "SPARK_SUBMIT" : "true",
      "awt.toolkit" : "sun.awt.X11.XToolkit",
      "com.sun.management.jmxremote.authenticate" : "false",
      "com.sun.management.jmxremote.port" : "0",
      "com.sun.management.jmxremote.ssl" : "false",
      "env" : "prod",
      "file.encoding" : "ANSI_X3.4-1968",
      "file.encoding.pkg" : "sun.io",
      "file.separator" : "/",
      "java.awt.graphicsenv" : "sun.awt.X11GraphicsEnvironment",
      "java.awt.printerjob" : "sun.print.PSPrinterJob",
      "java.class.version" : "52.0",
      "java.endorsed.dirs" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/endorsed",
      "java.ext.dirs" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext",
      "java.home" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre",
      "java.io.tmpdir" : "/tmp",
      "java.library.path" : "/usr/flipkart/3.2.1-1/hadoop-hdfs/lib:/usr/flipkart/3.2.1-1/hadoop-hdfs/lib/native:/usr/lib/hadoop/lib:/usr/lib/hadoop/lib/native:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/lib/x86_64-linux-gnu:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib",
      "java.rmi.server.randomIDs" : "true",
      "java.runtime.name" : "Java(TM) SE Runtime Environment",
      "java.runtime.version" : "1.8.0_172-b11",
      "java.specification.name" : "Java Platform API Specification",
      "java.specification.vendor" : "Oracle Corporation",
      "java.specification.version" : "1.8",
      "java.vendor" : "Oracle Corporation",
      "java.vendor.url" : "http://java.oracle.com/",
      "java.vendor.url.bug" : "http://bugreport.sun.com/bugreport/",
      "java.version" : "1.8.0_172",
      "java.vm.info" : "mixed mode",
      "java.vm.name" : "Java HotSpot(TM) 64-Bit Server VM",
      "java.vm.specification.name" : "Java Virtual Machine Specification",
      "java.vm.specification.vendor" : "Oracle Corporation",
      "java.vm.specification.version" : "1.8",
      "java.vm.vendor" : "Oracle Corporation",
      "java.vm.version" : "25.172-b11",
      "jetty.git.hash" : "b881a572662e1943a14ae12e7e1207989f218b74",
      "job.numOfRePartitions" : "30",
      "line.separator" : "\n",
      "os.arch" : "amd64",
      "os.name" : "Linux",
      "os.version" : "4.19.0-19-cloud-amd64",
      "path.separator" : ":",
      "scala.usejavacp" : "true",
      "sun.arch.data.model" : "64",
      "sun.boot.class.path" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/oracle-java8-jdk-amd64/jre/classes",
      "sun.boot.library.path" : "/usr/lib/jvm/oracle-java8-jdk-amd64/jre/lib/amd64",
      "sun.cpu.endian" : "little",
      "sun.cpu.isalist" : "",
      "sun.io.unicode.encoding" : "UnicodeLittle",
      "sun.java.command" : "org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.sql.sources.partitionOverwriteMode=dynamic --conf spark.executor.memory=10240m --conf spark.sql.catalog.hive_pluto=org.apache.iceberg.spark.SparkCatalog --conf spark.driver.memory=5120m --conf spark.sql.catalog.hive_pluto.uri=thrift://10.116.17.2:9083 --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.hive_pluto.type=hive --conf spark.benchmarkId=20231130-164024-tpcds-1gb-iceberg-load --conf spark.executor.extraJavaOptions=-XX:MaxDirectMemorySize=8096m -Dio.netty.maxDirectMemory=8096m -XX:+UseG1GC -XX:ConcGCThreads=2 --conf spark.hadoop.fs.s3.useRequesterPaysHeader=true --conf spark.delta.logStore.gs.impl=io.delta.storage.GCSLogStore --class org.apache.spark.repl.Main --name Spark shell --queue de_adhoc --jars /home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-benchmarks.jar,/var/lib/fk-pf-spark3/jars/iceberg-hive-runtime-1.2.0.jar,/var/lib/fk-pf-spark3/jars/iceberg-spark-runtime-3.1_2.12-1.2.0.jar spark-shell -I 20231130-164024-tpcds-1gb-iceberg-load_shell_init.scala",
      "sun.java.launcher" : "SUN_STANDARD",
      "sun.jnu.encoding" : "ANSI_X3.4-1968",
      "sun.management.compiler" : "HotSpot 64-Bit Tiered Compilers",
      "sun.nio.ch.bugLevel" : "",
      "sun.os.patch.level" : "unknown",
      "user.country" : "US",
      "user.dir" : "/home/vanshika.yadav",
      "user.home" : "/home/vanshika.yadav",
      "user.language" : "en",
      "user.name" : "vanshika.yadav",
      "user.timezone" : "Asia/Kolkata"
    }
  }
}
Copying file:///home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-report.json [Content-Type=application/json]...
/ [0 files][    0.0 B/ 65.8 KiB]                                                / [1 files][ 65.8 KiB/ 65.8 KiB]                                                
Operation completed over 1 objects/65.8 KiB.                                     
FILE UPLOAD: Uploaded /home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-report.json to gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/reports/json/
Copying file:///home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-report.csv [Content-Type=text/csv]...
/ [0 files][    0.0 B/  1.5 KiB]                                                / [1 files][  1.5 KiB/  1.5 KiB]                                                
Operation completed over 1 objects/1.5 KiB.                                      
FILE UPLOAD: Uploaded /home/vanshika.yadav/20231130-164024-tpcds-1gb-iceberg-load-report.csv to gs://fksdp-mhora-zrwe-0f09-discoverycontentimpression/benchmarking/iceberg-benchmarking/reports/csv/
SUCCESS
